{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d00737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"/home/xhnfly/Cosmic_rays_X/XRL/\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0874f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim import RMSprop\n",
    "import XRL_main\n",
    "import gym\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "import neptune.new as neptune\n",
    "import datetime\n",
    "\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a752628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/xhnfirst/DDPG-mian-test1/e/DDPGMIAN-86\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "nep_log = neptune.init(\n",
    "    project=\"xhnfirst/DDPG-mian-test1\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NTg5MDI2OS01MTVmLTQ2YjUtODA1Yy02ZWQyNDgxZDcwN2UifQ==\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32990c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "from time import strftime\n",
    "from time import gmtime\n",
    "\n",
    "class view_bar:\n",
    "    def __init__(self, message, num, total, value_name, value_data, start_time_rec, r_true, reward_ctrl, reward_dist, total_main):\n",
    "        self.message = message\n",
    "        self.num = num\n",
    "        self.total = total\n",
    "        self.message2 = \"True time of r = \"\n",
    "        self.r_true = r_true\n",
    "        self.message3 = \"time cost = \"\n",
    "        rate = self.num  / self.total\n",
    "        rate_num = int(rate * 40)\n",
    "        rate_nums = math.ceil(rate * 100)\n",
    "        time_rec = datetime.datetime.now()\n",
    "        execution_time = time_rec - start_time_rec\n",
    "        self.message4 = \"{reward_ctrl: \"\n",
    "        self.reward_ctrl = reward_ctrl\n",
    "        self.message5 = \"reward_dist: \"\n",
    "        self.reward_dist = reward_dist\n",
    "        self.message6 = \"Total Reward Main: \"\n",
    "        self.total_main = total_main\n",
    "        self.message8 = \" }\"\n",
    "\n",
    "\n",
    "\n",
    "        r = '\\r%s:[%s%s]%d%%\\t%d/%d\\t%s%f\\t%s%s\\t%s%s\\t\\t\\t\\t%s%.4f\\t%s%.4f\\t%s%.4f\\t%s' % (self.message, \"=\" * rate_num,\n",
    "                                        \" \" * (40 - rate_num), rate_nums, self.num , self.total, value_name, value_data, \n",
    "                                        self.message3, execution_time, self.message2, str(self.r_true), str(self.message4), self.reward_ctrl,\n",
    "                                        str(self.message5), self.reward_dist, str(self.message6), self.total_main, \n",
    "                                         str(self.message8)\n",
    "                                        )\n",
    "\n",
    "\n",
    "        sys.stdout.write(r)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "# a =10\n",
    "# for i in range(60000):\n",
    "#     view_bar(\"epoch \", i+1, 60000, 'a = ', float(a))\n",
    "#     a += 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05909c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Reacher-v2')\n",
    "test_env = gym.make('Reacher-v2')\n",
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a57f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class MLPActor(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation, act_limit):\n",
    "        super().__init__()\n",
    "        pi_sizes = [obs_dim] + list(hidden_sizes) + [act_dim]\n",
    "        self.pi = mlp(pi_sizes, activation, nn.Tanh)\n",
    "        self.act_limit = act_limit\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Return output from network scaled to action space limits.\n",
    "        return self.act_limit * self.pi(obs)\n",
    "\n",
    "class MLPQFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        q = self.q(torch.cat([obs, act], dim=-1))\n",
    "        return torch.squeeze(q, -1) # Critical to ensure q has right shape.\n",
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, observation_space, action_space, hidden_sizes=(256,256),\n",
    "                 activation=nn.ReLU, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        obs_dim = observation_space.shape[0]\n",
    "        act_dim = action_space.shape[0]\n",
    "        act_limit = action_space.high[0]\n",
    "\n",
    "        # build policy and value functions\n",
    "        self.pi = MLPActor(obs_dim, act_dim, hidden_sizes, activation, act_limit).to(device)\n",
    "        self.q = MLPQFunction(obs_dim, act_dim, hidden_sizes, activation).to(device)\n",
    "\n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            return self.pi(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f6e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('obs', 'act', 'rew', 'next_obs', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c45766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"hid\": 64,\n",
    "    \"l\": 3,\n",
    "    \"seed\": 0,\n",
    "    \"steps_per_epoch\": 3000,\n",
    "    \"epochs\": 100,\n",
    "    \"replay_size\": int(1e6),\n",
    "    \"gamma\": 0.99,\n",
    "    \"polyak\": 0.995,\n",
    "    \"pi_lr\": 1e-4,\n",
    "    \"q_lr\": 1e-4,\n",
    "    \"batch_size\": 500,\n",
    "    \"start_steps\": 10000, \n",
    "    \"update_after\": 1000,\n",
    "    \"update_every\": 50,\n",
    "    \"act_noise\": 0.01,\n",
    "    \"num_test_episodes\": 10,\n",
    "    \"max_ep_len\": 1000\n",
    "}\n",
    "\n",
    "\n",
    "ac_kwargs=dict(hidden_sizes=[params[\"hid\"]]*params[\"l\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef79a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim =  11\n",
      "act_dim =  2\n",
      "act_limit =  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3054/2016876372.py:156: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  o = torch.tensor([o], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: :[                                        ]1%\t2950/300000\tmain of rewards = -0.014855\ttime cost = 0:00:12.772520\tTrue time of r = 483\t\t\t\t{reward_ctrl: -0.1154\treward_dist: -0.1239\tTotal Reward Main: -0.2498\t }Creating window glfw\n",
      "steps: :[=                                       ]4%\t10050/300000\tmain of rewards = -0.011407\ttime cost = 0:01:01.304341\tTrue time of r = 1637\t\t\t\t{reward_ctrl: -1.9587\treward_dist: -0.3088\tTotal Reward Main: -0.3341\t }"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3054/2016876372.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = ac.act(torch.tensor(o, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: :[======================================= ]100%\t299950/300000\tmain of rewards = 0.000111\ttime cost = 0:45:06.964054\tTrue time of r = 125022\t\t\t\t{reward_ctrl: -1.3163\treward_dist: -0.1447\tTotal Reward Main: 3.3620\t }}"
     ]
    }
   ],
   "source": [
    "nep_log[\"parameters\"] = params\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "np.random.seed(params[\"seed\"])\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "print('obs_dim = ', obs_dim)\n",
    "act_dim = env.action_space.shape[0]\n",
    "print('act_dim = ', act_dim)\n",
    "# Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "act_limit = env.action_space.high[0]\n",
    "print('act_limit = ', act_limit)\n",
    "# Create actor-critic module and target networks\n",
    "ac = MLPActorCritic(env.observation_space, env.action_space, **ac_kwargs)\n",
    "ac_targ = deepcopy(ac)\n",
    "\n",
    "# Freeze target networks with respect to optimizers (only update via polyak averaging)\n",
    "for p in ac_targ.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "memory = ReplayMemory(params[\"replay_size\"])\n",
    "\n",
    "\n",
    "# Set up function for computing DDPG Q-loss\n",
    "def compute_loss_q(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "    a = torch.cat(data.act).float()\n",
    "    r = torch.cat(data.rew).float()\n",
    "    o2 =torch.cat(data.next_obs).float()\n",
    "    d = torch.cat(data.done).float()\n",
    "\n",
    "    q = ac.q(o,a)\n",
    "\n",
    "\n",
    "    # Bellman backup for Q function\n",
    "    with torch.no_grad():\n",
    "        q_pi_targ = ac_targ.q(o2, ac_targ.pi(o2))\n",
    "        backup = r + params[\"gamma\"] * (1 - d) * q_pi_targ\n",
    "\n",
    "    # MSE loss against Bellman backup\n",
    "    loss_q = ((q - backup)**2).mean()\n",
    "\n",
    "    return loss_q\n",
    "\n",
    "# Set up function for computing DDPG pi loss\n",
    "def compute_loss_pi(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "\n",
    "    q_pi = ac.q(o, ac.pi(o))\n",
    "\n",
    "    return -q_pi.mean()\n",
    "\n",
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "def update(data):\n",
    "    # First run one gradient descent step for Q.\n",
    "\n",
    "\n",
    "    q_optimizer.zero_grad()\n",
    "    loss_q = compute_loss_q(data)\n",
    "\n",
    "    loss_q.backward()\n",
    "\n",
    "    q_optimizer.step()\n",
    "\n",
    "\n",
    "    # Freeze Q-network so you don't waste computational effort \n",
    "    # computing gradients for it during the policy learning step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Next run one gradient descent step for pi.\n",
    "    pi_optimizer.zero_grad()\n",
    "    loss_pi = compute_loss_pi(data)\n",
    "    loss_pi.backward()\n",
    "    pi_optimizer.step()\n",
    "\n",
    "    # Unfreeze Q-network so you can optimize it at next DDPG step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "    # Finally, update target networks by polyak averaging.\n",
    "    with torch.no_grad():\n",
    "        for p, p_targ in zip(ac.parameters(), ac_targ.parameters()):\n",
    "            # NB: We use an in-place operations \"mul_\", \"add_\" to update target\n",
    "            # params, as opposed to \"mul\" and \"add\", which would make new tensors.\n",
    "            p_targ.data.mul_(params[\"polyak\"])\n",
    "            p_targ.data.add_((1 - params[\"polyak\"]) * p.data)\n",
    "\n",
    "\n",
    "def get_action(o, noise_scale):\n",
    "    a = ac.act(torch.tensor(o, dtype=torch.float32, device=device))\n",
    "    a += noise_scale * torch.randn(act_dim).to(device)\n",
    "    return torch.clip(a, -act_limit, act_limit)\n",
    "\n",
    "def test_agent():\n",
    "    for j in range(params[\"num_test_episodes\"]):\n",
    "        o, d, ep_ret, ep_len = test_env.reset(), False, 0, 0\n",
    "        if j == 9:\n",
    "            test_env.render()\n",
    "            time.sleep(0.02)\n",
    "        while not(d or (ep_len == params[\"max_ep_len\"])):\n",
    "            # Take deterministic actions at test time (noise_scale=0)\n",
    "            a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "            # a = get_action(o, 0)\n",
    "            if j == 9:\n",
    "                test_env.render()\n",
    "                time.sleep(0.02)\n",
    "            o, r, d, _ = test_env.step(a_cpu)\n",
    "            if d == True:\n",
    "                r += 10\n",
    "            else:\n",
    "                r += -1\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "        \n",
    "        nep_log[\"test/reward\"].log(ep_ret/ep_len)\n",
    "        \n",
    "\n",
    "\n",
    "# Prepare for interaction with environment\n",
    "total_steps = params[\"steps_per_epoch\"] * params[\"epochs\"]\n",
    "start_time = time.time()\n",
    "o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "o = torch.tensor([o], device=device)\n",
    "\n",
    "start_time_rec = datetime.datetime.now()\n",
    "# Main loop: collect experience in env and update/log each epoch\n",
    "r_true = 0\n",
    "total_main = 0\n",
    "reward_dict={}\n",
    "ep_times = 0\n",
    "for t in range(total_steps):\n",
    "    \n",
    "    # Until start_steps have elapsed, randomly sample actions\n",
    "    # from a uniform distribution for better exploration. Afterwards, \n",
    "    # use the learned policy (with some noise, via act_noise). \n",
    "    if t > params[\"start_steps\"]:\n",
    "        a = get_action(o, params[\"act_noise\"])\n",
    "        # a_cpu = a\n",
    "        a_cpu = a.cpu().data.numpy()\n",
    "        \n",
    "    else:\n",
    "        a = env.action_space.sample()\n",
    "        a_cpu = a\n",
    "        a = torch.tensor([a], device=device)\n",
    "    \n",
    "\n",
    "    # Step the env\n",
    "    o2, r, d, reward_dict= env.step(a_cpu)\n",
    "\n",
    "    nep_log[\"testreward/dist\"].log(reward_dict[\"reward_dist\"])\n",
    "    nep_log[\"testreward/ctrl\"].log(reward_dict[\"reward_ctrl\"])\n",
    "        \n",
    "\n",
    "\n",
    "    if np.abs(reward_dict[\"reward_dist\"]) < 0.1 and np.abs(reward_dict[\"reward_ctrl\"]) < 1.5:\n",
    "        r += 2\n",
    "        if np.abs(reward_dict[\"reward_dist\"]) < 0.05 and np.abs(reward_dict[\"reward_ctrl\"]) < 1:\n",
    "            r += 4\n",
    "            if np.abs(reward_dict[\"reward_dist\"]) < 0.03 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.7:\n",
    "                r += 8\n",
    "                if np.abs(reward_dict[\"reward_dist\"]) < 0.02 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.4:\n",
    "                    r += 16\n",
    "                    if np.abs(reward_dict[\"reward_dist\"]) < 0.01 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.2:\n",
    "                        r += 32\n",
    "                        if np.abs(reward_dict[\"reward_dist\"]) < 0.005 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.05:\n",
    "                            r += 64\n",
    "                            if np.abs(reward_dict[\"reward_dist\"]) < 0.001 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.01:\n",
    "                                r += 128\n",
    "                                if np.abs(reward_dict[\"reward_dist\"]) < 0.0001 and np.abs(reward_dict[\"reward_ctrl\"]) < 0.001:\n",
    "                                    r += 256\n",
    "        r_true += 1\n",
    "    else:\n",
    "        r += -0.1\n",
    "\n",
    "\n",
    "    \n",
    "    ep_len += 1\n",
    "    total_main += r\n",
    "\n",
    "\n",
    "    # Ignore the \"done\" signal if it comes from hitting the time\n",
    "    # horizon (that is, when it's an artificial terminal signal\n",
    "    # that isn't based on the agent's state)\n",
    "    d = False if ep_len==params[\"max_ep_len\"] else d\n",
    "\n",
    "    # a = torch.tensor([a], device=device)\n",
    "    o2 = torch.tensor([o2], device=device)\n",
    "    r = torch.tensor([r], device=device)\n",
    "    d = torch.tensor([d], device=device)\n",
    "\n",
    "    # Store experience to replay buffer\n",
    "    memory.push(o, a, r, o2, d)\n",
    "    # Super critical, easy to overlook step: make sure to update \n",
    "    # most recent observation!\n",
    "    o=o2\n",
    "\n",
    "    # End of trajectory handling\n",
    "    if d or (ep_len == params[\"max_ep_len\"]):\n",
    "        o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "        ep_times += 1\n",
    "        ep_ret += r\n",
    "        ep_ret_main = ep_ret/ep_times\n",
    "        o = torch.tensor([o], device=device)\n",
    "\n",
    "\n",
    "    # Update handling\n",
    "    if t >= params[\"update_after\"] and t % params[\"update_every\"] == 0:\n",
    "        view_bar(\"steps: \", t, total_steps, 'main of rewards = ', float(ep_ret_main), start_time_rec, \n",
    "                r_true, reward_dict[\"reward_ctrl\"], reward_dict[\"reward_dist\"], total_main/t)\n",
    "        \n",
    "        nep_log[\"train/reward\"].log(ep_ret_main)\n",
    "        for i in range(params[\"update_every\"]):\n",
    "\n",
    "            transitions = memory.sample(params[\"batch_size\"])\n",
    "            # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "            # detailed explanation). This converts batch-array of Transitions\n",
    "            # to Transition of batch-arrays.\n",
    "            batch = Transition(*zip(*transitions))\n",
    "\n",
    "            # print('batch = ', str(batch))\n",
    "            update(data=batch)\n",
    "\n",
    "    # End of epoch handling\n",
    "    if (t+1) % params[\"steps_per_epoch\"] == 0:\n",
    "        epoch = (t+1) // params[\"steps_per_epoch\"]\n",
    "\n",
    "        # Test the performance of the deterministic version of the agent.\n",
    "        test_agent()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35465c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 11 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 11 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "nep_log.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eca5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "q.0.weight \t torch.Size([64, 13])\n",
      "q.0.bias \t torch.Size([64])\n",
      "q.2.weight \t torch.Size([64, 64])\n",
      "q.2.bias \t torch.Size([64])\n",
      "q.4.weight \t torch.Size([64, 64])\n",
      "q.4.bias \t torch.Size([64])\n",
      "q.6.weight \t torch.Size([1, 64])\n",
      "q.6.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "model = ac.q\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d12f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "pi.0.weight \t torch.Size([64, 11])\n",
      "pi.0.bias \t torch.Size([64])\n",
      "pi.2.weight \t torch.Size([64, 64])\n",
      "pi.2.bias \t torch.Size([64])\n",
      "pi.4.weight \t torch.Size([64, 64])\n",
      "pi.4.bias \t torch.Size([64])\n",
      "pi.6.weight \t torch.Size([2, 64])\n",
      "pi.6.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "model = ac.pi\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58034b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 299000, 'square_avg': tensor([[4.0154e+04, 1.1398e+04, 1.9016e+04, 4.6284e+04, 2.8081e+02, 1.0971e+03,\n",
      "         2.0036e+05, 2.8146e+05, 1.8131e+02, 1.0009e+02, 0.0000e+00, 3.9916e+03,\n",
      "         5.3032e+03],\n",
      "        [1.9227e+04, 8.7835e+03, 9.0269e+03, 2.2230e+04, 2.4469e+02, 5.8056e+02,\n",
      "         2.6806e+05, 3.4891e+05, 1.1042e+02, 9.7425e+01, 0.0000e+00, 4.4064e+03,\n",
      "         4.4301e+03],\n",
      "        [4.9201e+04, 5.8895e+03, 2.8196e+04, 6.9876e+04, 2.6348e+02, 2.2326e+03,\n",
      "         1.2111e+05, 1.3530e+05, 5.2330e+01, 8.1701e+01, 0.0000e+00, 4.0982e+03,\n",
      "         2.1896e+03],\n",
      "        [2.6618e+04, 1.3230e+04, 2.1352e+04, 3.2111e+04, 3.8194e+02, 1.0718e+03,\n",
      "         4.1354e+05, 3.6512e+05, 1.3061e+02, 2.5285e+02, 0.0000e+00, 5.2890e+03,\n",
      "         4.9570e+03],\n",
      "        [1.4808e+04, 5.8238e+03, 9.3255e+03, 1.7588e+04, 1.3935e+02, 5.6243e+02,\n",
      "         1.8936e+05, 1.8219e+05, 1.0091e+02, 7.9645e+01, 0.0000e+00, 2.4438e+03,\n",
      "         3.0534e+03],\n",
      "        [1.5161e+06, 5.1488e+05, 6.6974e+05, 1.5682e+06, 1.4346e+04, 3.8628e+04,\n",
      "         7.8628e+06, 1.0434e+07, 6.0158e+03, 2.9897e+03, 0.0000e+00, 1.5230e+05,\n",
      "         1.9211e+05],\n",
      "        [6.2626e+03, 1.2360e+03, 8.5837e+03, 1.4679e+04, 3.9638e+01, 4.0679e+02,\n",
      "         2.3170e+05, 1.2326e+05, 3.7012e+01, 3.7400e+01, 0.0000e+00, 1.9708e+03,\n",
      "         1.4297e+03],\n",
      "        [1.2429e+04, 3.9246e+03, 6.9335e+03, 1.4337e+04, 1.2310e+02, 3.9423e+02,\n",
      "         9.2215e+04, 9.9369e+04, 5.6198e+01, 3.8076e+01, 0.0000e+00, 1.8541e+03,\n",
      "         2.1467e+03],\n",
      "        [3.2963e+03, 1.3826e+03, 3.3776e+03, 5.9499e+03, 3.2687e+01, 1.7473e+02,\n",
      "         1.0431e+05, 5.0205e+04, 3.3425e+01, 2.4199e+01, 0.0000e+00, 8.4644e+02,\n",
      "         7.2918e+02],\n",
      "        [4.0375e+05, 1.6737e+05, 1.6169e+05, 3.6363e+05, 3.7432e+03, 9.0332e+03,\n",
      "         1.9932e+06, 2.7758e+06, 1.9768e+03, 1.0058e+03, 0.0000e+00, 3.7651e+04,\n",
      "         4.9779e+04],\n",
      "        [2.9028e+06, 1.4676e+06, 8.1234e+05, 1.9839e+06, 4.8056e+04, 5.7787e+04,\n",
      "         9.8755e+06, 2.1944e+07, 9.5370e+03, 6.1637e+03, 0.0000e+00, 2.7167e+05,\n",
      "         4.5236e+05],\n",
      "        [2.3687e+04, 1.0769e+04, 5.4195e+03, 1.6711e+04, 3.0797e+02, 3.9698e+02,\n",
      "         7.5976e+04, 1.2914e+05, 9.3097e+01, 5.2903e+01, 0.0000e+00, 2.0169e+03,\n",
      "         2.3599e+03],\n",
      "        [1.6324e+04, 4.4176e+03, 8.4128e+03, 2.0345e+04, 1.2877e+02, 5.7960e+02,\n",
      "         1.3718e+05, 1.2528e+05, 7.1825e+01, 6.2297e+01, 0.0000e+00, 1.9151e+03,\n",
      "         2.2246e+03],\n",
      "        [3.6942e+04, 7.4030e+03, 1.8477e+04, 4.7698e+04, 4.9481e+02, 1.1917e+03,\n",
      "         1.8523e+05, 3.4912e+05, 9.0979e+01, 6.6837e+01, 0.0000e+00, 5.9439e+03,\n",
      "         6.3865e+03],\n",
      "        [1.3413e+04, 7.3775e+03, 2.2589e+03, 7.5625e+03, 2.4153e+02, 1.5923e+02,\n",
      "         4.2252e+04, 6.6301e+04, 4.9097e+01, 2.3269e+01, 0.0000e+00, 1.0539e+03,\n",
      "         1.4150e+03],\n",
      "        [4.7117e+04, 1.6211e+04, 2.1396e+04, 5.4079e+04, 3.5097e+02, 1.4742e+03,\n",
      "         2.7226e+05, 3.2432e+05, 2.4208e+02, 2.5070e+02, 0.0000e+00, 5.5848e+03,\n",
      "         6.2942e+03],\n",
      "        [4.1376e+05, 1.2316e+05, 1.9300e+05, 4.9427e+05, 4.4930e+03, 1.3518e+04,\n",
      "         2.2363e+06, 3.4076e+06, 1.2913e+03, 9.7910e+02, 0.0000e+00, 4.7225e+04,\n",
      "         5.9974e+04],\n",
      "        [7.2377e+04, 2.7616e+04, 2.4879e+04, 6.5117e+04, 6.4559e+02, 1.6110e+03,\n",
      "         3.1615e+05, 5.1084e+05, 3.7591e+02, 2.1458e+02, 0.0000e+00, 6.5017e+03,\n",
      "         9.1497e+03],\n",
      "        [3.1579e+05, 1.2407e+05, 9.0878e+04, 2.6138e+05, 6.6781e+03, 3.5823e+03,\n",
      "         1.1818e+06, 1.6757e+06, 1.2133e+03, 7.6052e+02, 0.0000e+00, 3.1091e+04,\n",
      "         4.6414e+04],\n",
      "        [1.1461e+06, 4.3283e+05, 1.6795e+05, 6.4205e+05, 1.3679e+04, 1.5579e+04,\n",
      "         5.5549e+06, 6.7332e+06, 5.3336e+03, 3.1591e+03, 0.0000e+00, 9.3961e+04,\n",
      "         1.0423e+05],\n",
      "        [2.4185e+04, 1.0279e+04, 8.5806e+03, 2.1698e+04, 2.8238e+02, 5.9642e+02,\n",
      "         2.7918e+05, 2.4761e+05, 1.8126e+02, 1.3154e+02, 0.0000e+00, 3.2586e+03,\n",
      "         3.2958e+03],\n",
      "        [2.7188e+03, 1.5593e+03, 3.8637e+03, 5.9112e+03, 4.1508e+01, 1.3840e+02,\n",
      "         1.6595e+05, 1.0565e+05, 3.6286e+01, 5.8340e+01, 0.0000e+00, 1.1243e+03,\n",
      "         1.8948e+03],\n",
      "        [4.4576e+03, 1.3914e+03, 1.5453e+03, 4.0548e+03, 6.2829e+01, 9.0862e+01,\n",
      "         4.2383e+04, 4.4117e+04, 1.9474e+01, 1.4702e+01, 0.0000e+00, 5.7031e+02,\n",
      "         9.0197e+02],\n",
      "        [1.6406e+05, 5.4631e+04, 7.0926e+04, 1.7911e+05, 1.7469e+03, 4.0828e+03,\n",
      "         1.1091e+06, 1.0672e+06, 4.0372e+02, 4.3084e+02, 0.0000e+00, 2.0671e+04,\n",
      "         2.6637e+04],\n",
      "        [8.2522e+04, 4.7790e+04, 1.7419e+04, 4.4175e+04, 1.4231e+03, 1.0079e+03,\n",
      "         4.2516e+05, 7.2675e+05, 5.2618e+02, 3.8146e+02, 0.0000e+00, 8.3914e+03,\n",
      "         1.3180e+04],\n",
      "        [4.1932e+05, 2.2244e+05, 8.3426e+04, 2.5620e+05, 9.3419e+03, 5.0721e+03,\n",
      "         1.5207e+06, 3.6740e+06, 1.0181e+03, 1.1955e+03, 0.0000e+00, 3.7624e+04,\n",
      "         6.8086e+04],\n",
      "        [2.6925e+04, 1.0849e+04, 7.6624e+03, 2.0135e+04, 4.5879e+02, 5.0838e+02,\n",
      "         1.6523e+05, 1.6207e+05, 6.5174e+01, 7.7110e+01, 0.0000e+00, 2.9174e+03,\n",
      "         3.6900e+03],\n",
      "        [3.9276e+03, 2.9357e+03, 9.9450e+03, 1.0105e+04, 9.2227e+01, 2.8557e+02,\n",
      "         5.6089e+05, 8.9406e+04, 5.9989e+01, 9.7659e+01, 0.0000e+00, 3.7817e+03,\n",
      "         3.1270e+03],\n",
      "        [1.9550e+05, 7.6250e+04, 4.5931e+04, 1.3702e+05, 2.1062e+03, 2.5648e+03,\n",
      "         7.0833e+05, 1.1591e+06, 9.2725e+02, 3.3549e+02, 0.0000e+00, 1.6891e+04,\n",
      "         2.1843e+04],\n",
      "        [1.6633e+06, 6.9400e+05, 5.5974e+05, 1.4402e+06, 2.1149e+04, 3.4012e+04,\n",
      "         1.1344e+07, 1.2871e+07, 7.0108e+03, 6.8804e+03, 0.0000e+00, 1.7022e+05,\n",
      "         2.0260e+05],\n",
      "        [6.2449e+03, 1.2620e+03, 3.9756e+03, 8.6751e+03, 3.5966e+01, 2.8869e+02,\n",
      "         5.1905e+04, 3.9661e+04, 2.1670e+01, 2.6188e+01, 0.0000e+00, 7.6255e+02,\n",
      "         6.0516e+02],\n",
      "        [3.6923e+05, 1.1786e+05, 1.1297e+05, 3.4666e+05, 4.7361e+03, 6.5604e+03,\n",
      "         1.8001e+06, 2.8945e+06, 1.1078e+03, 5.9861e+02, 0.0000e+00, 4.1036e+04,\n",
      "         5.7601e+04],\n",
      "        [1.0287e+06, 3.6903e+05, 4.6469e+05, 1.1491e+06, 1.0169e+04, 2.8533e+04,\n",
      "         8.4491e+06, 9.4700e+06, 5.8824e+03, 3.7554e+03, 0.0000e+00, 1.4568e+05,\n",
      "         1.6672e+05],\n",
      "        [3.5103e+04, 2.6991e+04, 4.3318e+03, 1.0874e+04, 5.9802e+02, 2.5263e+02,\n",
      "         2.6608e+05, 2.1351e+05, 2.2423e+02, 1.4677e+02, 0.0000e+00, 2.7577e+03,\n",
      "         3.9070e+03],\n",
      "        [1.1163e+05, 3.5461e+04, 8.2789e+04, 1.5705e+05, 9.0237e+02, 4.4098e+03,\n",
      "         9.2306e+05, 8.4904e+05, 4.4636e+02, 4.2968e+02, 0.0000e+00, 1.4746e+04,\n",
      "         1.4992e+04],\n",
      "        [1.0072e+05, 5.5939e+04, 1.1743e+04, 4.1207e+04, 1.0603e+03, 8.0756e+02,\n",
      "         3.3105e+05, 5.9386e+05, 7.7698e+02, 2.6188e+02, 0.0000e+00, 8.1051e+03,\n",
      "         1.0259e+04],\n",
      "        [2.2398e+05, 6.8189e+04, 1.5190e+05, 3.0953e+05, 1.5901e+03, 9.1331e+03,\n",
      "         1.8087e+06, 1.7131e+06, 1.0576e+03, 8.6285e+02, 0.0000e+00, 2.7390e+04,\n",
      "         3.1886e+04],\n",
      "        [5.7274e+04, 1.3337e+04, 1.5747e+04, 5.8664e+04, 6.3404e+02, 1.3823e+03,\n",
      "         2.1841e+05, 2.3521e+05, 1.0753e+02, 1.9879e+02, 0.0000e+00, 5.9336e+03,\n",
      "         4.5672e+03],\n",
      "        [8.6083e+03, 2.6978e+03, 3.7906e+03, 9.4448e+03, 8.2204e+01, 2.7228e+02,\n",
      "         5.9839e+04, 4.3808e+04, 4.3490e+01, 3.6161e+01, 0.0000e+00, 9.5669e+02,\n",
      "         7.5551e+02],\n",
      "        [9.0905e+05, 2.4339e+05, 7.4334e+05, 1.4517e+06, 4.8296e+03, 3.9074e+04,\n",
      "         5.6287e+06, 6.4273e+06, 3.7041e+03, 1.7356e+03, 0.0000e+00, 1.0677e+05,\n",
      "         1.3280e+05],\n",
      "        [5.2322e+03, 1.1616e+03, 2.1913e+03, 6.5051e+03, 5.8263e+01, 1.5957e+02,\n",
      "         5.9362e+04, 4.6353e+04, 1.2570e+01, 1.7585e+01, 0.0000e+00, 8.4404e+02,\n",
      "         8.7723e+02],\n",
      "        [4.2498e+03, 2.3274e+03, 7.9111e+03, 8.9665e+03, 3.2558e+01, 3.0519e+02,\n",
      "         1.1223e+05, 7.5531e+04, 5.4374e+01, 6.2586e+01, 0.0000e+00, 1.5636e+03,\n",
      "         1.2495e+03],\n",
      "        [1.3119e+03, 5.0412e+02, 4.2740e+02, 1.2628e+03, 1.1672e+01, 2.7240e+01,\n",
      "         1.2059e+05, 3.1536e+04, 2.4244e+01, 1.7712e+01, 0.0000e+00, 4.3130e+02,\n",
      "         3.0680e+02],\n",
      "        [3.6500e+04, 1.2216e+04, 1.4985e+04, 3.9716e+04, 2.5160e+02, 1.1687e+03,\n",
      "         2.7452e+05, 3.2831e+05, 2.6453e+02, 1.4718e+02, 0.0000e+00, 4.3898e+03,\n",
      "         5.6756e+03],\n",
      "        [3.3392e+04, 1.1431e+04, 4.7477e+03, 2.3449e+04, 5.9033e+02, 4.2401e+02,\n",
      "         1.6453e+05, 1.7817e+05, 7.9302e+01, 7.1739e+01, 0.0000e+00, 2.7796e+03,\n",
      "         3.4627e+03],\n",
      "        [2.1774e+04, 3.1529e+03, 2.1784e+04, 4.1498e+04, 1.3148e+02, 1.2234e+03,\n",
      "         2.1933e+05, 1.4945e+05, 8.1085e+01, 7.9574e+01, 0.0000e+00, 3.7607e+03,\n",
      "         2.6461e+03],\n",
      "        [3.2772e+04, 1.0885e+04, 2.0983e+04, 4.2736e+04, 3.2501e+02, 1.2627e+03,\n",
      "         1.4826e+05, 2.0708e+05, 1.1821e+02, 1.4236e+02, 0.0000e+00, 3.2775e+03,\n",
      "         3.4799e+03],\n",
      "        [3.5815e+06, 7.8174e+05, 1.8936e+06, 4.5912e+06, 4.9574e+04, 9.1639e+04,\n",
      "         1.7798e+07, 2.4036e+07, 7.7275e+03, 6.2521e+03, 0.0000e+00, 4.2220e+05,\n",
      "         6.8986e+05],\n",
      "        [5.7883e+04, 1.6661e+04, 2.7890e+04, 7.0842e+04, 5.9713e+02, 1.6460e+03,\n",
      "         3.6280e+05, 4.6139e+05, 2.0846e+02, 1.6770e+02, 0.0000e+00, 5.6476e+03,\n",
      "         7.8728e+03],\n",
      "        [2.2157e+04, 1.0323e+04, 6.8509e+03, 1.8469e+04, 2.3528e+02, 5.3095e+02,\n",
      "         1.7834e+05, 2.0332e+05, 1.9060e+02, 1.4002e+02, 0.0000e+00, 2.8077e+03,\n",
      "         3.6484e+03],\n",
      "        [8.5936e+03, 6.6705e+03, 4.7135e+03, 5.8431e+03, 1.7505e+02, 1.7246e+02,\n",
      "         3.5001e+05, 1.1665e+05, 1.2983e+02, 1.3888e+02, 0.0000e+00, 2.0096e+03,\n",
      "         1.5878e+03],\n",
      "        [5.1354e+03, 1.5252e+03, 2.9978e+03, 6.9189e+03, 5.2060e+01, 1.9956e+02,\n",
      "         7.6747e+04, 5.1693e+04, 1.4245e+01, 2.3165e+01, 0.0000e+00, 9.6122e+02,\n",
      "         8.9416e+02],\n",
      "        [5.1140e+05, 2.2728e+05, 1.7302e+05, 4.3033e+05, 6.7725e+03, 1.0856e+04,\n",
      "         3.7937e+06, 4.8523e+06, 3.2794e+03, 2.3478e+03, 0.0000e+00, 6.3128e+04,\n",
      "         6.6241e+04],\n",
      "        [1.4487e+05, 8.8863e+04, 3.5464e+04, 8.1738e+04, 1.5316e+03, 1.8989e+03,\n",
      "         7.4549e+05, 9.9682e+05, 1.1590e+03, 4.1814e+02, 0.0000e+00, 1.2789e+04,\n",
      "         1.7304e+04],\n",
      "        [2.2287e+04, 1.5351e+04, 1.8295e+04, 2.4275e+04, 4.1558e+02, 5.9425e+02,\n",
      "         3.8952e+05, 3.3321e+05, 1.9079e+02, 1.0816e+02, 0.0000e+00, 4.1862e+03,\n",
      "         4.1159e+03],\n",
      "        [2.8447e+04, 1.4695e+04, 6.9768e+03, 1.6241e+04, 3.5312e+02, 4.7690e+02,\n",
      "         1.9493e+05, 2.4209e+05, 2.0837e+02, 1.4727e+02, 0.0000e+00, 3.1152e+03,\n",
      "         3.8320e+03],\n",
      "        [1.9137e+05, 6.8173e+04, 4.4939e+04, 1.7107e+05, 2.4470e+03, 2.8073e+03,\n",
      "         1.1826e+06, 1.5768e+06, 9.0183e+02, 4.1728e+02, 0.0000e+00, 2.2215e+04,\n",
      "         2.3493e+04],\n",
      "        [3.9670e+04, 1.2093e+04, 1.5013e+04, 4.1136e+04, 5.2941e+02, 9.7041e+02,\n",
      "         1.7499e+05, 2.2781e+05, 7.0023e+01, 6.1684e+01, 0.0000e+00, 4.5496e+03,\n",
      "         6.8668e+03],\n",
      "        [1.8854e+06, 9.3441e+05, 3.7374e+05, 1.0585e+06, 4.0380e+04, 2.3101e+04,\n",
      "         3.8059e+06, 1.0150e+07, 3.4890e+03, 2.6243e+03, 0.0000e+00, 1.2564e+05,\n",
      "         2.4965e+05],\n",
      "        [4.9703e+04, 1.3347e+04, 5.4514e+04, 9.1578e+04, 6.7311e+02, 2.0639e+03,\n",
      "         8.0919e+05, 6.2711e+05, 2.3850e+02, 2.6521e+02, 0.0000e+00, 1.0232e+04,\n",
      "         1.0891e+04],\n",
      "        [2.5302e+05, 1.0986e+05, 7.9980e+04, 1.9269e+05, 2.6933e+03, 4.7650e+03,\n",
      "         1.1552e+06, 1.5156e+06, 1.2345e+03, 5.5019e+02, 0.0000e+00, 2.4155e+04,\n",
      "         2.6101e+04],\n",
      "        [4.0609e+03, 1.9946e+03, 4.2320e+03, 6.7929e+03, 6.1145e+01, 2.2913e+02,\n",
      "         1.4884e+05, 1.0906e+05, 3.8213e+01, 9.3731e+01, 0.0000e+00, 2.0711e+03,\n",
      "         1.4275e+03],\n",
      "        [1.0539e+04, 6.6758e+03, 3.0928e+03, 7.1439e+03, 1.9859e+02, 1.7671e+02,\n",
      "         5.6248e+04, 1.0138e+05, 6.3740e+01, 6.2524e+01, 0.0000e+00, 1.1059e+03,\n",
      "         1.8007e+03],\n",
      "        [5.6196e+03, 1.8353e+03, 2.1087e+03, 5.4658e+03, 5.6107e+01, 1.3969e+02,\n",
      "         3.3287e+04, 3.9776e+04, 2.4825e+01, 2.1343e+01, 0.0000e+00, 7.0897e+02,\n",
      "         9.4487e+02]], device='cuda:0')}, 1: {'step': 299000, 'square_avg': tensor([6.5458e+04, 3.4092e+04, 7.4695e+04, 5.8132e+04, 2.4792e+04, 2.4773e+06,\n",
      "        1.6291e+04, 1.9729e+04, 6.9116e+03, 6.6584e+05, 3.8891e+06, 3.0791e+04,\n",
      "        2.5785e+04, 5.5398e+04, 1.6420e+04, 7.6933e+04, 6.3954e+05, 1.1098e+05,\n",
      "        4.3636e+05, 1.3625e+06, 3.4191e+04, 7.5843e+03, 6.0735e+03, 2.6114e+05,\n",
      "        1.0480e+05, 5.2033e+05, 3.6040e+04, 1.5477e+04, 2.6602e+05, 2.6652e+06,\n",
      "        1.0297e+04, 4.9788e+05, 1.6143e+06, 4.0127e+04, 2.2469e+05, 1.2820e+05,\n",
      "        4.1535e+05, 7.3674e+04, 1.3178e+04, 1.7692e+06, 7.0798e+03, 1.2089e+04,\n",
      "        1.9142e+03, 5.2399e+04, 3.9126e+04, 4.4264e+04, 5.4727e+04, 5.8490e+06,\n",
      "        9.0235e+04, 3.1266e+04, 1.3055e+04, 7.9962e+03, 7.4111e+05, 2.2088e+05,\n",
      "        4.9852e+04, 3.7024e+04, 2.6079e+05, 5.6981e+04, 2.3022e+06, 1.1071e+05,\n",
      "        3.8882e+05, 1.0009e+04, 1.3701e+04, 7.8907e+03], device='cuda:0')}, 2: {'step': 299000, 'square_avg': tensor([[1.9078e+04, 5.9722e+03, 2.1669e+03,  ..., 6.6541e+02, 5.5724e+02,\n",
      "         1.5708e+04],\n",
      "        [2.3583e+04, 3.6856e+03, 1.6858e+03,  ..., 3.8376e+02, 9.3593e+02,\n",
      "         1.6960e+04],\n",
      "        [1.3769e+04, 2.3633e+03, 1.5312e+03,  ..., 4.2444e+02, 3.0271e+02,\n",
      "         1.5875e+04],\n",
      "        ...,\n",
      "        [2.9147e+04, 3.6945e+03, 2.4994e+03,  ..., 1.4217e+02, 8.1325e+02,\n",
      "         1.9650e+04],\n",
      "        [5.1502e+04, 2.8652e+04, 6.5018e+03,  ..., 6.4392e+03, 9.5254e+02,\n",
      "         1.1494e+05],\n",
      "        [1.5121e+03, 4.1257e+02, 1.5398e+02,  ..., 4.2633e+01, 3.2242e+01,\n",
      "         1.6405e+03]], device='cuda:0')}, 3: {'step': 299000, 'square_avg': tensor([1.5500e+04, 1.5678e+04, 1.2361e+04, 1.1254e+03, 3.1872e+04, 1.1027e+03,\n",
      "        3.8804e+02, 1.0789e+04, 7.7536e+02, 6.1891e+04, 5.4245e+04, 2.2509e+04,\n",
      "        1.5054e+04, 1.8965e+03, 2.4786e+02, 1.3538e+02, 6.5417e+03, 2.1147e+02,\n",
      "        6.2636e+02, 1.1261e+02, 6.0813e+04, 2.0347e+04, 1.4763e+03, 3.4104e+05,\n",
      "        1.6734e+04, 3.0096e+04, 1.2030e+02, 9.9972e+04, 2.4559e+04, 3.1546e+04,\n",
      "        1.6607e+01, 2.2901e+04, 4.0584e+01, 3.1826e+03, 1.8628e+04, 1.1064e+04,\n",
      "        6.9458e+02, 3.4372e+04, 1.6058e+04, 1.6610e+04, 1.2082e+03, 4.0685e+04,\n",
      "        5.5076e+04, 3.8687e+04, 5.5519e+03, 3.1230e+03, 3.0508e+03, 2.5887e+03,\n",
      "        5.6200e+01, 1.8112e+03, 3.7195e+04, 5.0983e+05, 1.0782e+02, 1.5522e+02,\n",
      "        1.4650e+04, 6.0273e+04, 4.1210e+02, 1.5487e+04, 1.6952e+02, 2.3357e+03,\n",
      "        7.8461e+04, 1.9525e+04, 6.8744e+04, 1.4104e+03], device='cuda:0')}, 4: {'step': 299000, 'square_avg': tensor([[7.4827e+01, 1.2255e+00, 5.0957e+02,  ..., 2.1215e+01, 4.2773e+00,\n",
      "         1.9496e+03],\n",
      "        [8.1747e+01, 1.3403e+00, 5.6466e+02,  ..., 2.3194e+01, 4.6584e+00,\n",
      "         2.1593e+03],\n",
      "        [6.3173e+01, 1.0363e+00, 4.3470e+02,  ..., 1.7908e+01, 3.5622e+00,\n",
      "         1.6555e+03],\n",
      "        ...,\n",
      "        [2.6850e+01, 4.4126e-01, 1.9162e+02,  ..., 7.6178e+00, 1.5199e+00,\n",
      "         7.2528e+02],\n",
      "        [2.4588e+01, 4.0408e-01, 1.7547e+02,  ..., 6.9758e+00, 1.3919e+00,\n",
      "         6.6416e+02],\n",
      "        [7.8739e+01, 1.3003e+00, 5.4346e+02,  ..., 2.2330e+01, 4.4443e+00,\n",
      "         2.0653e+03]], device='cuda:0')}, 5: {'step': 299000, 'square_avg': tensor([8.2927e+01, 9.1741e+01, 7.0412e+01, 3.1000e+01, 2.7439e+01, 7.0065e-44,\n",
      "        8.6401e+01, 8.2500e+01, 2.6984e+01, 7.6867e+01, 3.3883e+01, 9.3967e+01,\n",
      "        9.0383e+01, 9.5697e+01, 7.3559e+01, 2.6331e+01, 8.3619e+01, 8.8384e+01,\n",
      "        7.1995e+01, 7.0065e-44, 9.9367e+01, 7.8363e+01, 8.7806e+01, 8.6337e+01,\n",
      "        8.3209e+01, 7.8071e+01, 9.8761e+01, 2.6858e+01, 3.4247e+01, 2.0206e+01,\n",
      "        7.1373e+01, 2.5660e+01, 3.1734e+01, 2.4766e+01, 7.8721e+01, 7.7226e+01,\n",
      "        8.0941e+01, 8.5630e+01, 7.3686e+01, 0.0000e+00, 2.7420e+01, 7.7684e+01,\n",
      "        2.3635e+01, 2.9639e+01, 9.0815e+01, 8.4018e+01, 9.3797e+01, 8.0910e+01,\n",
      "        3.2129e+01, 3.1537e+01, 3.4837e+01, 8.0871e+01, 9.0110e+01, 8.6022e+01,\n",
      "        8.7897e+01, 2.5169e+01, 4.5034e+01, 4.1152e+01, 8.8810e+01, 2.3188e+01,\n",
      "        7.6735e+01, 3.0512e+01, 2.7941e+01, 8.7802e+01], device='cuda:0')}, 6: {'step': 299000, 'square_avg': tensor([[5.9524e+03, 5.7923e+03, 6.3202e+03, 2.5525e+05, 2.6913e+05, 7.0065e-44,\n",
      "         6.1863e+03, 5.6552e+03, 2.6616e+05, 6.0277e+03, 2.1805e+05, 5.9885e+03,\n",
      "         6.3633e+03, 5.4734e+03, 5.5861e+03, 2.8132e+05, 5.1715e+03, 5.4614e+03,\n",
      "         5.9116e+03, 7.0065e-44, 5.8100e+03, 5.7270e+03, 6.1942e+03, 6.1777e+03,\n",
      "         5.8034e+03, 6.1520e+03, 5.0849e+03, 2.9711e+05, 1.2105e+05, 2.5237e+05,\n",
      "         6.1814e+03, 2.5902e+05, 2.6021e+05, 2.4666e+05, 6.2845e+03, 6.8203e+03,\n",
      "         6.0699e+03, 6.1044e+03, 5.8152e+03, 0.0000e+00, 2.3148e+05, 6.2476e+03,\n",
      "         2.7683e+05, 2.0480e+05, 5.9893e+03, 5.2628e+03, 5.7502e+03, 5.6241e+03,\n",
      "         2.4985e+05, 1.9726e+05, 2.2570e+05, 5.8278e+03, 6.2144e+03, 6.0266e+03,\n",
      "         5.7597e+03, 2.9398e+05, 2.8317e+03, 1.6381e+05, 5.6973e+03, 2.4505e+05,\n",
      "         6.1483e+03, 2.6423e+05, 2.8378e+05, 6.1438e+03]], device='cuda:0')}, 7: {'step': 299000, 'square_avg': tensor([60.1590], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"q_optimizer's state_dict:\")\n",
    "for var_name in q_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", q_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9087ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_optimizer's state_dict:\n",
      "state \t {0: {'step': 299000, 'square_avg': tensor([[8.6105e-01, 4.9790e-01, 1.8904e-01, 5.4539e-01, 1.1169e-02, 9.4090e-03,\n",
      "         9.5097e+00, 1.5327e+01, 1.5116e-02, 8.9920e-03, 0.0000e+00],\n",
      "        [1.4412e+00, 6.7878e-01, 2.6247e-01, 9.7308e-01, 1.9922e-02, 2.0455e-02,\n",
      "         4.6969e+00, 9.8027e+00, 7.5594e-03, 4.6400e-03, 0.0000e+00],\n",
      "        [1.4291e+00, 7.7289e-01, 2.2776e-01, 9.4793e-01, 1.6435e-02, 2.0465e-02,\n",
      "         6.4613e+00, 9.6408e+00, 9.9954e-03, 7.9790e-03, 0.0000e+00],\n",
      "        [1.4412e-01, 6.4755e-02, 3.0563e-01, 4.5285e-01, 3.6344e-03, 7.4650e-03,\n",
      "         6.7360e+00, 4.1453e+00, 1.6342e-03, 2.7985e-03, 0.0000e+00],\n",
      "        [8.4601e-02, 3.6184e-02, 2.1278e-02, 7.0556e-02, 1.1436e-03, 1.3483e-03,\n",
      "         7.9308e-01, 1.0898e+00, 6.9021e-04, 5.5292e-04, 0.0000e+00],\n",
      "        [1.2071e+00, 3.8491e-01, 2.7472e-01, 1.0457e+00, 1.0691e-02, 2.4897e-02,\n",
      "         5.6090e+00, 5.4176e+00, 7.7108e-03, 3.1993e-03, 0.0000e+00],\n",
      "        [5.3873e-01, 3.6728e-01, 1.0218e-01, 2.2618e-01, 4.6825e-03, 4.4916e-03,\n",
      "         4.1880e+00, 5.5369e+00, 7.2064e-03, 3.3484e-03, 0.0000e+00],\n",
      "        [2.5695e-02, 2.0149e-02, 5.8434e-02, 6.4128e-02, 5.5184e-04, 1.4119e-03,\n",
      "         1.6785e+00, 8.6297e-01, 6.0470e-04, 7.7081e-04, 0.0000e+00],\n",
      "        [1.5600e-01, 6.1479e-02, 7.0495e-02, 1.7696e-01, 1.8868e-03, 3.2403e-03,\n",
      "         1.1164e+00, 1.7040e+00, 1.0749e-03, 5.4256e-04, 0.0000e+00],\n",
      "        [1.4768e+00, 7.8557e-01, 2.7854e-01, 1.0277e+00, 1.8986e-02, 2.1491e-02,\n",
      "         8.3005e+00, 8.9181e+00, 1.5829e-02, 6.5766e-03, 0.0000e+00],\n",
      "        [1.2554e+00, 6.5498e-01, 3.8652e-01, 8.5529e-01, 9.5642e-03, 1.6208e-02,\n",
      "         8.1371e+00, 9.7838e+00, 1.2703e-02, 8.0632e-03, 0.0000e+00],\n",
      "        [7.1996e-01, 2.9761e-01, 3.4196e-01, 7.5500e-01, 9.4003e-03, 1.3590e-02,\n",
      "         1.1046e+01, 8.0575e+00, 8.9112e-03, 6.6647e-03, 0.0000e+00],\n",
      "        [6.6450e-01, 5.1241e-01, 1.0973e-01, 2.0137e-01, 6.4608e-03, 4.9487e-03,\n",
      "         4.1755e+00, 6.0565e+00, 1.6362e-02, 5.7290e-03, 0.0000e+00],\n",
      "        [7.7140e-02, 3.8687e-02, 4.3541e-02, 8.3944e-02, 9.7751e-04, 1.5072e-03,\n",
      "         8.6310e-01, 1.2481e+00, 1.0264e-03, 4.7454e-04, 0.0000e+00],\n",
      "        [1.5228e+00, 6.1495e-01, 3.0893e-01, 1.2006e+00, 1.7120e-02, 2.2361e-02,\n",
      "         6.0345e+00, 1.1001e+01, 7.3894e-03, 4.5801e-03, 0.0000e+00],\n",
      "        [6.7070e-01, 4.4887e-01, 1.4015e-01, 3.0406e-01, 8.0920e-03, 8.6536e-03,\n",
      "         6.2165e+00, 6.6876e+00, 1.4316e-02, 4.5411e-03, 0.0000e+00],\n",
      "        [8.0311e-01, 2.6155e-01, 1.7116e-01, 4.9597e-01, 8.7027e-03, 1.1399e-02,\n",
      "         3.0017e+00, 3.8122e+00, 4.6250e-03, 3.2333e-03, 0.0000e+00],\n",
      "        [7.6655e-02, 3.4744e-02, 5.1758e-02, 9.6073e-02, 8.0185e-04, 1.7961e-03,\n",
      "         2.5264e+00, 1.4200e+00, 6.1707e-04, 9.1413e-04, 0.0000e+00],\n",
      "        [3.6717e-01, 1.8997e-01, 1.0914e-01, 2.6864e-01, 3.7440e-03, 6.2203e-03,\n",
      "         3.0636e+00, 3.6938e+00, 4.8664e-03, 2.0562e-03, 0.0000e+00],\n",
      "        [1.4658e-01, 8.5053e-02, 1.1323e-01, 2.1977e-01, 3.2415e-03, 3.5031e-03,\n",
      "         2.0188e+00, 1.7073e+00, 1.6710e-03, 1.9261e-03, 0.0000e+00],\n",
      "        [3.9134e-01, 2.0305e-01, 1.0554e-01, 3.0962e-01, 4.9620e-03, 6.8406e-03,\n",
      "         3.2411e+00, 2.7370e+00, 3.8971e-03, 1.6442e-03, 0.0000e+00],\n",
      "        [2.3247e-01, 1.6604e-01, 8.5619e-02, 1.6706e-01, 2.6757e-03, 3.6913e-03,\n",
      "         3.2253e+00, 2.7606e+00, 6.9306e-03, 2.6251e-03, 0.0000e+00],\n",
      "        [2.6413e+00, 9.3759e-01, 8.2393e-01, 1.8107e+00, 3.2219e-02, 3.7910e-02,\n",
      "         2.4802e+01, 2.3856e+01, 1.9095e-02, 1.5760e-02, 0.0000e+00],\n",
      "        [9.8718e-02, 2.5904e-02, 1.2794e-01, 2.1801e-01, 1.4179e-03, 4.4217e-03,\n",
      "         2.2615e+00, 1.8245e+00, 1.4524e-03, 1.3178e-03, 0.0000e+00],\n",
      "        [3.6342e+00, 1.4419e+00, 4.9628e-01, 1.9780e+00, 3.3187e-02, 4.6871e-02,\n",
      "         9.4360e+00, 1.4949e+01, 2.1392e-02, 1.2222e-02, 0.0000e+00],\n",
      "        [3.3990e-01, 1.9388e-01, 1.1674e-01, 2.5697e-01, 1.0312e-02, 2.8659e-03,\n",
      "         4.1686e+00, 4.8186e+00, 6.2037e-03, 3.2484e-03, 0.0000e+00],\n",
      "        [2.0278e+00, 8.1168e-01, 7.1794e-01, 1.7122e+00, 1.6425e-02, 4.0693e-02,\n",
      "         1.0375e+01, 1.3779e+01, 2.0619e-02, 8.2568e-03, 0.0000e+00],\n",
      "        [2.7845e-01, 9.6993e-02, 3.8358e-01, 6.1504e-01, 2.1472e-03, 1.9055e-02,\n",
      "         5.4877e+00, 4.9311e+00, 2.5389e-03, 2.7492e-03, 0.0000e+00],\n",
      "        [1.0907e+00, 5.6581e-01, 2.4046e-01, 7.2098e-01, 1.0660e-02, 1.6966e-02,\n",
      "         4.5407e+00, 8.4693e+00, 6.2204e-03, 4.3268e-03, 0.0000e+00],\n",
      "        [2.5235e-01, 9.9779e-02, 7.3429e-02, 2.2029e-01, 3.1867e-03, 4.5444e-03,\n",
      "         1.6702e+00, 1.9749e+00, 1.2249e-03, 1.5485e-03, 0.0000e+00],\n",
      "        [6.5462e-02, 7.3356e-02, 6.3351e-02, 6.2737e-02, 1.1901e-03, 1.4164e-03,\n",
      "         3.8493e+00, 2.6032e+00, 3.7593e-03, 2.3714e-03, 0.0000e+00],\n",
      "        [3.5423e-01, 1.7372e-01, 7.8142e-02, 2.1605e-01, 4.1013e-03, 3.9220e-03,\n",
      "         1.9015e+00, 2.4733e+00, 3.5913e-03, 1.6292e-03, 0.0000e+00],\n",
      "        [9.3575e-01, 4.9163e-01, 2.0427e-01, 6.0002e-01, 9.0966e-03, 9.8634e-03,\n",
      "         6.3344e+00, 9.5938e+00, 1.2272e-02, 6.0837e-03, 0.0000e+00],\n",
      "        [2.0694e+00, 7.4279e-01, 1.9706e-01, 7.3012e-01, 2.0989e-02, 1.6545e-02,\n",
      "         4.6284e+00, 8.0233e+00, 1.2058e-02, 6.2350e-03, 0.0000e+00],\n",
      "        [1.1834e-02, 1.3302e-02, 3.3809e-02, 3.1787e-02, 4.6709e-04, 3.4878e-04,\n",
      "         1.5205e+00, 7.5811e-01, 4.6879e-04, 6.5463e-04, 0.0000e+00],\n",
      "        [6.3940e+00, 2.6851e+00, 4.1415e-01, 1.5715e+00, 6.4699e-02, 3.7248e-02,\n",
      "         1.1604e+01, 1.8170e+01, 2.6967e-02, 1.0163e-02, 0.0000e+00],\n",
      "        [5.9633e-01, 2.7458e-01, 2.2376e-01, 5.0368e-01, 4.9466e-03, 1.6467e-02,\n",
      "         4.0805e+00, 4.4741e+00, 5.9490e-03, 3.6659e-03, 0.0000e+00],\n",
      "        [1.2275e-01, 4.4391e-02, 4.8629e-02, 1.4800e-01, 1.4633e-03, 3.3079e-03,\n",
      "         9.0151e-01, 1.0586e+00, 8.7173e-04, 4.6937e-04, 0.0000e+00],\n",
      "        [8.9274e-01, 3.4136e-01, 1.7866e-01, 6.0874e-01, 8.6513e-03, 8.8559e-03,\n",
      "         4.8009e+00, 6.6697e+00, 6.3947e-03, 4.3219e-03, 0.0000e+00],\n",
      "        [1.3064e+00, 3.3026e-01, 5.5143e-01, 1.5663e+00, 1.6403e-02, 3.6089e-02,\n",
      "         1.3745e+01, 1.0492e+01, 1.0285e-02, 7.4436e-03, 0.0000e+00],\n",
      "        [1.1637e-02, 1.9385e-02, 3.5437e-02, 2.3609e-02, 4.5148e-04, 5.8048e-04,\n",
      "         2.1967e+00, 1.3731e+00, 6.1176e-04, 6.4109e-04, 0.0000e+00],\n",
      "        [2.8457e-01, 1.2672e-01, 6.6994e-02, 1.9928e-01, 2.8997e-03, 4.2563e-03,\n",
      "         1.4158e+00, 1.8994e+00, 2.2879e-03, 9.5556e-04, 0.0000e+00],\n",
      "        [1.5170e-01, 3.0228e-02, 6.1486e-02, 1.4408e-01, 1.8393e-03, 2.2725e-03,\n",
      "         2.1636e+00, 1.7679e+00, 1.0342e-03, 9.3272e-04, 0.0000e+00],\n",
      "        [4.2203e-01, 1.8057e-01, 8.6534e-02, 3.4579e-01, 3.6094e-03, 6.9661e-03,\n",
      "         1.3235e+00, 2.3087e+00, 3.8829e-03, 8.5946e-04, 0.0000e+00],\n",
      "        [2.5659e+00, 1.2517e+00, 3.7773e-01, 1.1997e+00, 2.3345e-02, 2.4058e-02,\n",
      "         5.5507e+00, 1.5045e+01, 1.8871e-02, 9.6069e-03, 0.0000e+00],\n",
      "        [2.8141e+00, 5.4360e-01, 5.7006e-01, 3.1397e+00, 3.2943e-02, 5.1653e-02,\n",
      "         6.3134e+00, 9.9818e+00, 2.3128e-03, 5.2852e-03, 0.0000e+00],\n",
      "        [2.1258e+00, 8.8738e-01, 6.5041e-01, 2.0153e+00, 2.3587e-02, 4.7769e-02,\n",
      "         1.4989e+01, 1.8126e+01, 1.7597e-02, 9.9559e-03, 0.0000e+00],\n",
      "        [4.5387e-01, 1.5983e-01, 1.2365e-01, 4.1074e-01, 4.6591e-03, 8.5327e-03,\n",
      "         3.4673e+00, 3.4110e+00, 1.8670e-03, 1.1799e-03, 0.0000e+00],\n",
      "        [6.5139e-01, 3.1452e-01, 2.4758e-01, 4.9302e-01, 5.3329e-03, 9.3035e-03,\n",
      "         6.6901e+00, 8.0500e+00, 1.2497e-02, 1.0081e-02, 0.0000e+00],\n",
      "        [1.2228e-01, 6.6571e-02, 3.2496e-02, 7.3830e-02, 1.4432e-03, 1.7643e-03,\n",
      "         6.7805e-01, 9.4910e-01, 9.5725e-04, 8.2939e-04, 0.0000e+00],\n",
      "        [1.0038e+00, 6.4769e-01, 2.2563e-01, 4.8173e-01, 1.0196e-02, 1.3354e-02,\n",
      "         6.7202e+00, 1.2279e+01, 1.9231e-02, 1.0342e-02, 0.0000e+00],\n",
      "        [3.1538e+00, 1.1992e+00, 3.1595e-01, 1.1134e+00, 3.0657e-02, 2.2035e-02,\n",
      "         1.3103e+01, 1.4520e+01, 2.1999e-02, 8.9324e-03, 0.0000e+00],\n",
      "        [1.3143e+00, 9.3791e-01, 2.2951e-01, 4.6502e-01, 7.1405e-03, 1.1373e-02,\n",
      "         5.3454e+00, 1.0032e+01, 2.9493e-02, 1.1580e-02, 0.0000e+00],\n",
      "        [4.8282e-01, 2.5850e-01, 2.2279e-01, 4.2201e-01, 4.8129e-03, 1.0345e-02,\n",
      "         7.7163e+00, 6.5891e+00, 5.7726e-03, 4.1213e-03, 0.0000e+00],\n",
      "        [2.0788e-01, 1.3493e-01, 3.7518e-02, 8.7527e-02, 2.4770e-03, 1.6652e-03,\n",
      "         8.9586e-01, 1.3140e+00, 2.7051e-03, 1.8261e-03, 0.0000e+00],\n",
      "        [1.3511e-01, 8.6334e-02, 2.6068e-02, 7.8046e-02, 2.0872e-03, 1.3435e-03,\n",
      "         1.8601e+00, 1.7721e+00, 2.2026e-03, 1.6337e-03, 0.0000e+00],\n",
      "        [9.3155e-01, 3.8142e-01, 2.1197e-01, 6.2172e-01, 9.1980e-03, 1.2282e-02,\n",
      "         3.4775e+00, 4.6903e+00, 7.2127e-03, 2.5407e-03, 0.0000e+00],\n",
      "        [7.5909e-01, 4.4657e-01, 4.2803e-01, 7.1422e-01, 7.6079e-03, 1.8257e-02,\n",
      "         8.9686e+00, 8.6959e+00, 1.2751e-02, 7.5031e-03, 0.0000e+00],\n",
      "        [8.3210e-02, 5.0196e-02, 4.2892e-02, 6.4672e-02, 7.9530e-04, 1.3731e-03,\n",
      "         1.2827e+00, 1.4301e+00, 1.6323e-03, 1.3347e-03, 0.0000e+00],\n",
      "        [1.6665e-01, 1.0289e-01, 6.6826e-02, 1.0954e-01, 2.5632e-03, 1.8997e-03,\n",
      "         3.9629e+00, 2.3239e+00, 3.3851e-03, 1.7690e-03, 0.0000e+00],\n",
      "        [1.6812e+00, 6.3013e-01, 4.2156e-01, 1.2686e+00, 1.7347e-02, 3.3285e-02,\n",
      "         6.4700e+00, 9.4232e+00, 5.7444e-03, 3.6890e-03, 0.0000e+00],\n",
      "        [6.3025e-01, 3.4621e-01, 1.7317e-01, 4.4585e-01, 8.0500e-03, 9.9098e-03,\n",
      "         4.2208e+00, 6.9479e+00, 6.6636e-03, 5.3899e-03, 0.0000e+00],\n",
      "        [3.2157e-01, 2.2644e-01, 6.3341e-02, 1.2930e-01, 3.5883e-03, 2.2403e-03,\n",
      "         2.9245e+00, 4.8737e+00, 7.1781e-03, 4.1831e-03, 0.0000e+00],\n",
      "        [3.0045e-01, 1.0731e-01, 1.2139e-01, 2.9912e-01, 3.0450e-03, 4.8805e-03,\n",
      "         3.2737e+00, 3.2041e+00, 1.8451e-03, 1.8079e-03, 0.0000e+00]],\n",
      "       device='cuda:0')}, 1: {'step': 299000, 'square_avg': tensor([1.0015, 1.7494, 1.8640, 0.5148, 0.1041, 1.6809, 0.7474, 0.0923, 0.2340,\n",
      "        1.9425, 1.8378, 1.1256, 0.7852, 0.1246, 1.9048, 0.7784, 1.0454, 0.1258,\n",
      "        0.4852, 0.2319, 0.4970, 0.3184, 3.4175, 0.2467, 4.6663, 0.4634, 3.0548,\n",
      "        0.6739, 1.4091, 0.3323, 0.1132, 0.4399, 1.2243, 2.4205, 0.0441, 7.9583,\n",
      "        0.8794, 0.1628, 1.1463, 1.9457, 0.0379, 0.3742, 0.2133, 0.5695, 3.1193,\n",
      "        3.6000, 2.9994, 0.6656, 0.8504, 0.1738, 1.1045, 3.7386, 1.6488, 0.7334,\n",
      "        0.2516, 0.1567, 1.2447, 1.0772, 0.1211, 0.2267, 2.1655, 0.7820, 0.4184,\n",
      "        0.4428], device='cuda:0')}, 2: {'step': 299000, 'square_avg': tensor([[1.0750, 0.5678, 1.5206,  ..., 1.1211, 1.3254, 0.1599],\n",
      "        [0.1269, 0.0777, 0.1617,  ..., 0.2091, 0.2590, 0.0388],\n",
      "        [0.1687, 0.0880, 0.1948,  ..., 0.1973, 0.2531, 0.0290],\n",
      "        ...,\n",
      "        [0.3334, 0.1468, 0.3789,  ..., 0.2271, 0.3640, 0.0423],\n",
      "        [0.0529, 0.0373, 0.0710,  ..., 0.0608, 0.0745, 0.0124],\n",
      "        [0.8480, 0.3567, 1.1796,  ..., 0.4106, 0.4571, 0.0804]],\n",
      "       device='cuda:0')}, 3: {'step': 299000, 'square_avg': tensor([3.1895e+00, 5.2434e-01, 5.0296e-01, 2.3938e-01, 3.4301e-01, 1.1364e+00,\n",
      "        7.0065e-44, 1.2309e+00, 4.6850e+00, 1.5790e-01, 2.9735e-01, 2.7623e-01,\n",
      "        6.4482e-01, 4.9145e-01, 1.5722e+00, 8.3578e-01, 6.1562e-01, 1.4553e+00,\n",
      "        2.7113e+00, 2.7234e-01, 1.2900e+00, 1.3346e+00, 5.5408e-01, 4.6035e+00,\n",
      "        4.7761e-01, 2.9026e+00, 2.1883e+00, 3.2919e-01, 5.7573e-01, 1.2672e+00,\n",
      "        2.3465e+00, 1.7535e+00, 6.2400e+00, 1.2021e+00, 2.0952e+00, 2.3993e+00,\n",
      "        4.2552e-01, 1.5420e+00, 2.4077e-01, 3.8176e+00, 5.1684e-01, 1.2857e-01,\n",
      "        3.1301e-01, 1.0151e+00, 9.3160e-01, 5.1838e+00, 2.3380e+00, 8.6278e-01,\n",
      "        5.5322e+00, 8.8383e-01, 9.9537e-01, 2.2475e+00, 1.4909e-01, 1.8508e+00,\n",
      "        6.0013e-01, 2.3774e-01, 2.6644e+00, 2.5668e+00, 1.5965e-01, 3.1297e-01,\n",
      "        4.8434e-01, 6.3295e-01, 2.3115e-01, 2.0178e+00], device='cuda:0')}, 4: {'step': 299000, 'square_avg': tensor([[0.1053, 0.0585, 0.1909,  ..., 0.1359, 0.3877, 0.0517],\n",
      "        [0.0203, 0.0446, 0.0675,  ..., 0.0481, 0.0976, 0.0246],\n",
      "        [0.0136, 0.0275, 0.0436,  ..., 0.0314, 0.0665, 0.0160],\n",
      "        ...,\n",
      "        [0.0426, 0.1372, 0.1585,  ..., 0.1174, 0.2076, 0.0634],\n",
      "        [0.0064, 0.0217, 0.0241,  ..., 0.0206, 0.0519, 0.0141],\n",
      "        [0.0517, 0.0818, 0.1393,  ..., 0.1170, 0.3222, 0.0366]],\n",
      "       device='cuda:0')}, 5: {'step': 299000, 'square_avg': tensor([0.2250, 0.1371, 0.0877, 0.0291, 0.3219, 0.0192, 0.0265, 0.1111, 0.0721,\n",
      "        0.3654, 0.0422, 0.0395, 0.0953, 0.0982, 0.0524, 1.1461, 0.0548, 0.0344,\n",
      "        0.7573, 0.2740, 0.1323, 0.1478, 0.0092, 0.6552, 0.5659, 0.4317, 2.4614,\n",
      "        0.0620, 0.2010, 0.0896, 0.0603, 0.4007, 0.0510, 0.0449, 0.1896, 0.3625,\n",
      "        0.1096, 0.0811, 0.0645, 0.0404, 0.0857, 0.1707, 0.0145, 0.0574, 0.1486,\n",
      "        0.1125, 0.2601, 0.4300, 0.0810, 0.3137, 0.1212, 0.1451, 0.3035, 0.2958,\n",
      "        0.0304, 0.2136, 0.0615, 0.2145, 0.0845, 0.0591, 0.3258, 0.3446, 0.0514,\n",
      "        0.2376], device='cuda:0')}, 6: {'step': 299000, 'square_avg': tensor([[1.9224e-03, 4.5509e-01, 7.3553e-01, 7.1204e-04, 2.3535e-01, 3.3627e-01,\n",
      "         4.3406e-01, 3.7879e-01, 1.8200e-01, 2.3148e-01, 2.3310e-01, 2.2864e-01,\n",
      "         1.6446e-01, 4.3540e-01, 3.8214e-01, 2.3969e-02, 1.4387e-02, 6.0346e-01,\n",
      "         2.5183e-02, 2.2247e-02, 3.6838e-01, 3.5356e-01, 1.5669e-01, 2.7921e-01,\n",
      "         1.6856e-01, 1.1358e-03, 1.3547e-02, 1.5994e-01, 3.2697e-01, 2.4400e-01,\n",
      "         2.9597e-01, 4.5365e-01, 2.4211e-01, 1.4697e-01, 2.2987e-01, 2.6189e-03,\n",
      "         6.9346e-01, 5.1969e-01, 1.3403e-02, 2.4396e-01, 2.1228e-01, 5.7950e-02,\n",
      "         1.6121e-03, 2.8529e-01, 7.1153e-02, 5.9023e-01, 2.1060e-01, 4.2966e-01,\n",
      "         6.1384e-01, 3.3086e-03, 7.8530e-02, 9.7835e-01, 2.3660e-01, 5.5337e-01,\n",
      "         1.1208e-01, 3.5262e-04, 1.0994e-01, 2.2553e-01, 2.8644e-01, 2.0261e-01,\n",
      "         7.6261e-03, 2.7459e-01, 1.8586e-01, 5.1333e-02],\n",
      "        [2.6125e-03, 1.6780e+00, 2.7906e+00, 5.8776e-04, 1.0501e+00, 1.3280e+00,\n",
      "         1.6630e+00, 1.5221e+00, 6.8648e-01, 9.9061e-01, 8.7053e-01, 9.8757e-01,\n",
      "         5.3849e-01, 1.5467e+00, 1.5748e+00, 1.0246e-01, 2.3420e-02, 2.3779e+00,\n",
      "         8.7857e-02, 1.2924e-01, 1.4129e+00, 1.4668e+00, 6.3836e-01, 6.3535e-01,\n",
      "         6.9630e-01, 1.5576e-03, 5.0495e-02, 6.8084e-01, 1.1398e+00, 1.0436e+00,\n",
      "         1.2413e+00, 1.9053e+00, 1.0338e+00, 6.6864e-01, 7.8786e-01, 7.2276e-03,\n",
      "         2.7432e+00, 1.9451e+00, 2.7478e-02, 7.2858e-01, 8.6844e-01, 1.7758e-01,\n",
      "         2.0539e-03, 9.7667e-01, 2.7610e-01, 2.0307e+00, 8.8230e-01, 1.7806e+00,\n",
      "         2.2026e+00, 9.8589e-03, 3.3628e-01, 3.9042e+00, 9.5842e-01, 1.8025e+00,\n",
      "         4.1610e-01, 7.4002e-04, 3.1468e-01, 1.1025e+00, 1.1132e+00, 6.9447e-01,\n",
      "         1.3206e-02, 9.8419e-01, 6.6680e-01, 1.8215e-01]], device='cuda:0')}, 7: {'step': 299000, 'square_avg': tensor([0.5322, 2.1757], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"pi_optimizer's state_dict:\")\n",
    "for var_name in pi_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", pi_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "868bdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model of ac.q': ac.q.state_dict(),\n",
    "            'model of ac.pi': ac.pi.state_dict(),\n",
    "            'q_optimizer_state_dict': q_optimizer.state_dict(),\n",
    "            'pi_optimizer_state_dict': pi_optimizer.state_dict(),\n",
    "            \n",
    "            }, \"model_nn/model_nn2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d000090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = MLPActorCritic(env.observation_space, env.action_space, **ac_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554d36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_q = ac.q\n",
    "model_pi = ac.pi\n",
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"model_nn/model_nn2.pt\")\n",
    "model_q.load_state_dict(checkpoint['model of ac.q'])\n",
    "model_pi.load_state_dict(checkpoint['model of ac.pi'])\n",
    "q_optimizer.load_state_dict(checkpoint['q_optimizer_state_dict'])\n",
    "pi_optimizer.load_state_dict(checkpoint['pi_optimizer_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693748d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "q.0.weight \t torch.Size([64, 13])\n",
      "q.0.bias \t torch.Size([64])\n",
      "q.2.weight \t torch.Size([64, 64])\n",
      "q.2.bias \t torch.Size([64])\n",
      "q.4.weight \t torch.Size([64, 64])\n",
      "q.4.bias \t torch.Size([64])\n",
      "q.6.weight \t torch.Size([1, 64])\n",
      "q.6.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "model = ac.q\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf96dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "pi.0.weight \t torch.Size([64, 11])\n",
      "pi.0.bias \t torch.Size([64])\n",
      "pi.2.weight \t torch.Size([64, 64])\n",
      "pi.2.bias \t torch.Size([64])\n",
      "pi.4.weight \t torch.Size([64, 64])\n",
      "pi.4.bias \t torch.Size([64])\n",
      "pi.6.weight \t torch.Size([2, 64])\n",
      "pi.6.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "model = ac.pi\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78dce761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_optimizer's state_dict:\n",
      "state \t {0: {'step': 299000, 'square_avg': tensor([[4.0154e+04, 1.1398e+04, 1.9016e+04, 4.6284e+04, 2.8081e+02, 1.0971e+03,\n",
      "         2.0036e+05, 2.8146e+05, 1.8131e+02, 1.0009e+02, 0.0000e+00, 3.9916e+03,\n",
      "         5.3032e+03],\n",
      "        [1.9227e+04, 8.7835e+03, 9.0269e+03, 2.2230e+04, 2.4469e+02, 5.8056e+02,\n",
      "         2.6806e+05, 3.4891e+05, 1.1042e+02, 9.7425e+01, 0.0000e+00, 4.4064e+03,\n",
      "         4.4301e+03],\n",
      "        [4.9201e+04, 5.8895e+03, 2.8196e+04, 6.9876e+04, 2.6348e+02, 2.2326e+03,\n",
      "         1.2111e+05, 1.3530e+05, 5.2330e+01, 8.1701e+01, 0.0000e+00, 4.0982e+03,\n",
      "         2.1896e+03],\n",
      "        [2.6618e+04, 1.3230e+04, 2.1352e+04, 3.2111e+04, 3.8194e+02, 1.0718e+03,\n",
      "         4.1354e+05, 3.6512e+05, 1.3061e+02, 2.5285e+02, 0.0000e+00, 5.2890e+03,\n",
      "         4.9570e+03],\n",
      "        [1.4808e+04, 5.8238e+03, 9.3255e+03, 1.7588e+04, 1.3935e+02, 5.6243e+02,\n",
      "         1.8936e+05, 1.8219e+05, 1.0091e+02, 7.9645e+01, 0.0000e+00, 2.4438e+03,\n",
      "         3.0534e+03],\n",
      "        [1.5161e+06, 5.1488e+05, 6.6974e+05, 1.5682e+06, 1.4346e+04, 3.8628e+04,\n",
      "         7.8628e+06, 1.0434e+07, 6.0158e+03, 2.9897e+03, 0.0000e+00, 1.5230e+05,\n",
      "         1.9211e+05],\n",
      "        [6.2626e+03, 1.2360e+03, 8.5837e+03, 1.4679e+04, 3.9638e+01, 4.0679e+02,\n",
      "         2.3170e+05, 1.2326e+05, 3.7012e+01, 3.7400e+01, 0.0000e+00, 1.9708e+03,\n",
      "         1.4297e+03],\n",
      "        [1.2429e+04, 3.9246e+03, 6.9335e+03, 1.4337e+04, 1.2310e+02, 3.9423e+02,\n",
      "         9.2215e+04, 9.9369e+04, 5.6198e+01, 3.8076e+01, 0.0000e+00, 1.8541e+03,\n",
      "         2.1467e+03],\n",
      "        [3.2963e+03, 1.3826e+03, 3.3776e+03, 5.9499e+03, 3.2687e+01, 1.7473e+02,\n",
      "         1.0431e+05, 5.0205e+04, 3.3425e+01, 2.4199e+01, 0.0000e+00, 8.4644e+02,\n",
      "         7.2918e+02],\n",
      "        [4.0375e+05, 1.6737e+05, 1.6169e+05, 3.6363e+05, 3.7432e+03, 9.0332e+03,\n",
      "         1.9932e+06, 2.7758e+06, 1.9768e+03, 1.0058e+03, 0.0000e+00, 3.7651e+04,\n",
      "         4.9779e+04],\n",
      "        [2.9028e+06, 1.4676e+06, 8.1234e+05, 1.9839e+06, 4.8056e+04, 5.7787e+04,\n",
      "         9.8755e+06, 2.1944e+07, 9.5370e+03, 6.1637e+03, 0.0000e+00, 2.7167e+05,\n",
      "         4.5236e+05],\n",
      "        [2.3687e+04, 1.0769e+04, 5.4195e+03, 1.6711e+04, 3.0797e+02, 3.9698e+02,\n",
      "         7.5976e+04, 1.2914e+05, 9.3097e+01, 5.2903e+01, 0.0000e+00, 2.0169e+03,\n",
      "         2.3599e+03],\n",
      "        [1.6324e+04, 4.4176e+03, 8.4128e+03, 2.0345e+04, 1.2877e+02, 5.7960e+02,\n",
      "         1.3718e+05, 1.2528e+05, 7.1825e+01, 6.2297e+01, 0.0000e+00, 1.9151e+03,\n",
      "         2.2246e+03],\n",
      "        [3.6942e+04, 7.4030e+03, 1.8477e+04, 4.7698e+04, 4.9481e+02, 1.1917e+03,\n",
      "         1.8523e+05, 3.4912e+05, 9.0979e+01, 6.6837e+01, 0.0000e+00, 5.9439e+03,\n",
      "         6.3865e+03],\n",
      "        [1.3413e+04, 7.3775e+03, 2.2589e+03, 7.5625e+03, 2.4153e+02, 1.5923e+02,\n",
      "         4.2252e+04, 6.6301e+04, 4.9097e+01, 2.3269e+01, 0.0000e+00, 1.0539e+03,\n",
      "         1.4150e+03],\n",
      "        [4.7117e+04, 1.6211e+04, 2.1396e+04, 5.4079e+04, 3.5097e+02, 1.4742e+03,\n",
      "         2.7226e+05, 3.2432e+05, 2.4208e+02, 2.5070e+02, 0.0000e+00, 5.5848e+03,\n",
      "         6.2942e+03],\n",
      "        [4.1376e+05, 1.2316e+05, 1.9300e+05, 4.9427e+05, 4.4930e+03, 1.3518e+04,\n",
      "         2.2363e+06, 3.4076e+06, 1.2913e+03, 9.7910e+02, 0.0000e+00, 4.7225e+04,\n",
      "         5.9974e+04],\n",
      "        [7.2377e+04, 2.7616e+04, 2.4879e+04, 6.5117e+04, 6.4559e+02, 1.6110e+03,\n",
      "         3.1615e+05, 5.1084e+05, 3.7591e+02, 2.1458e+02, 0.0000e+00, 6.5017e+03,\n",
      "         9.1497e+03],\n",
      "        [3.1579e+05, 1.2407e+05, 9.0878e+04, 2.6138e+05, 6.6781e+03, 3.5823e+03,\n",
      "         1.1818e+06, 1.6757e+06, 1.2133e+03, 7.6052e+02, 0.0000e+00, 3.1091e+04,\n",
      "         4.6414e+04],\n",
      "        [1.1461e+06, 4.3283e+05, 1.6795e+05, 6.4205e+05, 1.3679e+04, 1.5579e+04,\n",
      "         5.5549e+06, 6.7332e+06, 5.3336e+03, 3.1591e+03, 0.0000e+00, 9.3961e+04,\n",
      "         1.0423e+05],\n",
      "        [2.4185e+04, 1.0279e+04, 8.5806e+03, 2.1698e+04, 2.8238e+02, 5.9642e+02,\n",
      "         2.7918e+05, 2.4761e+05, 1.8126e+02, 1.3154e+02, 0.0000e+00, 3.2586e+03,\n",
      "         3.2958e+03],\n",
      "        [2.7188e+03, 1.5593e+03, 3.8637e+03, 5.9112e+03, 4.1508e+01, 1.3840e+02,\n",
      "         1.6595e+05, 1.0565e+05, 3.6286e+01, 5.8340e+01, 0.0000e+00, 1.1243e+03,\n",
      "         1.8948e+03],\n",
      "        [4.4576e+03, 1.3914e+03, 1.5453e+03, 4.0548e+03, 6.2829e+01, 9.0862e+01,\n",
      "         4.2383e+04, 4.4117e+04, 1.9474e+01, 1.4702e+01, 0.0000e+00, 5.7031e+02,\n",
      "         9.0197e+02],\n",
      "        [1.6406e+05, 5.4631e+04, 7.0926e+04, 1.7911e+05, 1.7469e+03, 4.0828e+03,\n",
      "         1.1091e+06, 1.0672e+06, 4.0372e+02, 4.3084e+02, 0.0000e+00, 2.0671e+04,\n",
      "         2.6637e+04],\n",
      "        [8.2522e+04, 4.7790e+04, 1.7419e+04, 4.4175e+04, 1.4231e+03, 1.0079e+03,\n",
      "         4.2516e+05, 7.2675e+05, 5.2618e+02, 3.8146e+02, 0.0000e+00, 8.3914e+03,\n",
      "         1.3180e+04],\n",
      "        [4.1932e+05, 2.2244e+05, 8.3426e+04, 2.5620e+05, 9.3419e+03, 5.0721e+03,\n",
      "         1.5207e+06, 3.6740e+06, 1.0181e+03, 1.1955e+03, 0.0000e+00, 3.7624e+04,\n",
      "         6.8086e+04],\n",
      "        [2.6925e+04, 1.0849e+04, 7.6624e+03, 2.0135e+04, 4.5879e+02, 5.0838e+02,\n",
      "         1.6523e+05, 1.6207e+05, 6.5174e+01, 7.7110e+01, 0.0000e+00, 2.9174e+03,\n",
      "         3.6900e+03],\n",
      "        [3.9276e+03, 2.9357e+03, 9.9450e+03, 1.0105e+04, 9.2227e+01, 2.8557e+02,\n",
      "         5.6089e+05, 8.9406e+04, 5.9989e+01, 9.7659e+01, 0.0000e+00, 3.7817e+03,\n",
      "         3.1270e+03],\n",
      "        [1.9550e+05, 7.6250e+04, 4.5931e+04, 1.3702e+05, 2.1062e+03, 2.5648e+03,\n",
      "         7.0833e+05, 1.1591e+06, 9.2725e+02, 3.3549e+02, 0.0000e+00, 1.6891e+04,\n",
      "         2.1843e+04],\n",
      "        [1.6633e+06, 6.9400e+05, 5.5974e+05, 1.4402e+06, 2.1149e+04, 3.4012e+04,\n",
      "         1.1344e+07, 1.2871e+07, 7.0108e+03, 6.8804e+03, 0.0000e+00, 1.7022e+05,\n",
      "         2.0260e+05],\n",
      "        [6.2449e+03, 1.2620e+03, 3.9756e+03, 8.6751e+03, 3.5966e+01, 2.8869e+02,\n",
      "         5.1905e+04, 3.9661e+04, 2.1670e+01, 2.6188e+01, 0.0000e+00, 7.6255e+02,\n",
      "         6.0516e+02],\n",
      "        [3.6923e+05, 1.1786e+05, 1.1297e+05, 3.4666e+05, 4.7361e+03, 6.5604e+03,\n",
      "         1.8001e+06, 2.8945e+06, 1.1078e+03, 5.9861e+02, 0.0000e+00, 4.1036e+04,\n",
      "         5.7601e+04],\n",
      "        [1.0287e+06, 3.6903e+05, 4.6469e+05, 1.1491e+06, 1.0169e+04, 2.8533e+04,\n",
      "         8.4491e+06, 9.4700e+06, 5.8824e+03, 3.7554e+03, 0.0000e+00, 1.4568e+05,\n",
      "         1.6672e+05],\n",
      "        [3.5103e+04, 2.6991e+04, 4.3318e+03, 1.0874e+04, 5.9802e+02, 2.5263e+02,\n",
      "         2.6608e+05, 2.1351e+05, 2.2423e+02, 1.4677e+02, 0.0000e+00, 2.7577e+03,\n",
      "         3.9070e+03],\n",
      "        [1.1163e+05, 3.5461e+04, 8.2789e+04, 1.5705e+05, 9.0237e+02, 4.4098e+03,\n",
      "         9.2306e+05, 8.4904e+05, 4.4636e+02, 4.2968e+02, 0.0000e+00, 1.4746e+04,\n",
      "         1.4992e+04],\n",
      "        [1.0072e+05, 5.5939e+04, 1.1743e+04, 4.1207e+04, 1.0603e+03, 8.0756e+02,\n",
      "         3.3105e+05, 5.9386e+05, 7.7698e+02, 2.6188e+02, 0.0000e+00, 8.1051e+03,\n",
      "         1.0259e+04],\n",
      "        [2.2398e+05, 6.8189e+04, 1.5190e+05, 3.0953e+05, 1.5901e+03, 9.1331e+03,\n",
      "         1.8087e+06, 1.7131e+06, 1.0576e+03, 8.6285e+02, 0.0000e+00, 2.7390e+04,\n",
      "         3.1886e+04],\n",
      "        [5.7274e+04, 1.3337e+04, 1.5747e+04, 5.8664e+04, 6.3404e+02, 1.3823e+03,\n",
      "         2.1841e+05, 2.3521e+05, 1.0753e+02, 1.9879e+02, 0.0000e+00, 5.9336e+03,\n",
      "         4.5672e+03],\n",
      "        [8.6083e+03, 2.6978e+03, 3.7906e+03, 9.4448e+03, 8.2204e+01, 2.7228e+02,\n",
      "         5.9839e+04, 4.3808e+04, 4.3490e+01, 3.6161e+01, 0.0000e+00, 9.5669e+02,\n",
      "         7.5551e+02],\n",
      "        [9.0905e+05, 2.4339e+05, 7.4334e+05, 1.4517e+06, 4.8296e+03, 3.9074e+04,\n",
      "         5.6287e+06, 6.4273e+06, 3.7041e+03, 1.7356e+03, 0.0000e+00, 1.0677e+05,\n",
      "         1.3280e+05],\n",
      "        [5.2322e+03, 1.1616e+03, 2.1913e+03, 6.5051e+03, 5.8263e+01, 1.5957e+02,\n",
      "         5.9362e+04, 4.6353e+04, 1.2570e+01, 1.7585e+01, 0.0000e+00, 8.4404e+02,\n",
      "         8.7723e+02],\n",
      "        [4.2498e+03, 2.3274e+03, 7.9111e+03, 8.9665e+03, 3.2558e+01, 3.0519e+02,\n",
      "         1.1223e+05, 7.5531e+04, 5.4374e+01, 6.2586e+01, 0.0000e+00, 1.5636e+03,\n",
      "         1.2495e+03],\n",
      "        [1.3119e+03, 5.0412e+02, 4.2740e+02, 1.2628e+03, 1.1672e+01, 2.7240e+01,\n",
      "         1.2059e+05, 3.1536e+04, 2.4244e+01, 1.7712e+01, 0.0000e+00, 4.3130e+02,\n",
      "         3.0680e+02],\n",
      "        [3.6500e+04, 1.2216e+04, 1.4985e+04, 3.9716e+04, 2.5160e+02, 1.1687e+03,\n",
      "         2.7452e+05, 3.2831e+05, 2.6453e+02, 1.4718e+02, 0.0000e+00, 4.3898e+03,\n",
      "         5.6756e+03],\n",
      "        [3.3392e+04, 1.1431e+04, 4.7477e+03, 2.3449e+04, 5.9033e+02, 4.2401e+02,\n",
      "         1.6453e+05, 1.7817e+05, 7.9302e+01, 7.1739e+01, 0.0000e+00, 2.7796e+03,\n",
      "         3.4627e+03],\n",
      "        [2.1774e+04, 3.1529e+03, 2.1784e+04, 4.1498e+04, 1.3148e+02, 1.2234e+03,\n",
      "         2.1933e+05, 1.4945e+05, 8.1085e+01, 7.9574e+01, 0.0000e+00, 3.7607e+03,\n",
      "         2.6461e+03],\n",
      "        [3.2772e+04, 1.0885e+04, 2.0983e+04, 4.2736e+04, 3.2501e+02, 1.2627e+03,\n",
      "         1.4826e+05, 2.0708e+05, 1.1821e+02, 1.4236e+02, 0.0000e+00, 3.2775e+03,\n",
      "         3.4799e+03],\n",
      "        [3.5815e+06, 7.8174e+05, 1.8936e+06, 4.5912e+06, 4.9574e+04, 9.1639e+04,\n",
      "         1.7798e+07, 2.4036e+07, 7.7275e+03, 6.2521e+03, 0.0000e+00, 4.2220e+05,\n",
      "         6.8986e+05],\n",
      "        [5.7883e+04, 1.6661e+04, 2.7890e+04, 7.0842e+04, 5.9713e+02, 1.6460e+03,\n",
      "         3.6280e+05, 4.6139e+05, 2.0846e+02, 1.6770e+02, 0.0000e+00, 5.6476e+03,\n",
      "         7.8728e+03],\n",
      "        [2.2157e+04, 1.0323e+04, 6.8509e+03, 1.8469e+04, 2.3528e+02, 5.3095e+02,\n",
      "         1.7834e+05, 2.0332e+05, 1.9060e+02, 1.4002e+02, 0.0000e+00, 2.8077e+03,\n",
      "         3.6484e+03],\n",
      "        [8.5936e+03, 6.6705e+03, 4.7135e+03, 5.8431e+03, 1.7505e+02, 1.7246e+02,\n",
      "         3.5001e+05, 1.1665e+05, 1.2983e+02, 1.3888e+02, 0.0000e+00, 2.0096e+03,\n",
      "         1.5878e+03],\n",
      "        [5.1354e+03, 1.5252e+03, 2.9978e+03, 6.9189e+03, 5.2060e+01, 1.9956e+02,\n",
      "         7.6747e+04, 5.1693e+04, 1.4245e+01, 2.3165e+01, 0.0000e+00, 9.6122e+02,\n",
      "         8.9416e+02],\n",
      "        [5.1140e+05, 2.2728e+05, 1.7302e+05, 4.3033e+05, 6.7725e+03, 1.0856e+04,\n",
      "         3.7937e+06, 4.8523e+06, 3.2794e+03, 2.3478e+03, 0.0000e+00, 6.3128e+04,\n",
      "         6.6241e+04],\n",
      "        [1.4487e+05, 8.8863e+04, 3.5464e+04, 8.1738e+04, 1.5316e+03, 1.8989e+03,\n",
      "         7.4549e+05, 9.9682e+05, 1.1590e+03, 4.1814e+02, 0.0000e+00, 1.2789e+04,\n",
      "         1.7304e+04],\n",
      "        [2.2287e+04, 1.5351e+04, 1.8295e+04, 2.4275e+04, 4.1558e+02, 5.9425e+02,\n",
      "         3.8952e+05, 3.3321e+05, 1.9079e+02, 1.0816e+02, 0.0000e+00, 4.1862e+03,\n",
      "         4.1159e+03],\n",
      "        [2.8447e+04, 1.4695e+04, 6.9768e+03, 1.6241e+04, 3.5312e+02, 4.7690e+02,\n",
      "         1.9493e+05, 2.4209e+05, 2.0837e+02, 1.4727e+02, 0.0000e+00, 3.1152e+03,\n",
      "         3.8320e+03],\n",
      "        [1.9137e+05, 6.8173e+04, 4.4939e+04, 1.7107e+05, 2.4470e+03, 2.8073e+03,\n",
      "         1.1826e+06, 1.5768e+06, 9.0183e+02, 4.1728e+02, 0.0000e+00, 2.2215e+04,\n",
      "         2.3493e+04],\n",
      "        [3.9670e+04, 1.2093e+04, 1.5013e+04, 4.1136e+04, 5.2941e+02, 9.7041e+02,\n",
      "         1.7499e+05, 2.2781e+05, 7.0023e+01, 6.1684e+01, 0.0000e+00, 4.5496e+03,\n",
      "         6.8668e+03],\n",
      "        [1.8854e+06, 9.3441e+05, 3.7374e+05, 1.0585e+06, 4.0380e+04, 2.3101e+04,\n",
      "         3.8059e+06, 1.0150e+07, 3.4890e+03, 2.6243e+03, 0.0000e+00, 1.2564e+05,\n",
      "         2.4965e+05],\n",
      "        [4.9703e+04, 1.3347e+04, 5.4514e+04, 9.1578e+04, 6.7311e+02, 2.0639e+03,\n",
      "         8.0919e+05, 6.2711e+05, 2.3850e+02, 2.6521e+02, 0.0000e+00, 1.0232e+04,\n",
      "         1.0891e+04],\n",
      "        [2.5302e+05, 1.0986e+05, 7.9980e+04, 1.9269e+05, 2.6933e+03, 4.7650e+03,\n",
      "         1.1552e+06, 1.5156e+06, 1.2345e+03, 5.5019e+02, 0.0000e+00, 2.4155e+04,\n",
      "         2.6101e+04],\n",
      "        [4.0609e+03, 1.9946e+03, 4.2320e+03, 6.7929e+03, 6.1145e+01, 2.2913e+02,\n",
      "         1.4884e+05, 1.0906e+05, 3.8213e+01, 9.3731e+01, 0.0000e+00, 2.0711e+03,\n",
      "         1.4275e+03],\n",
      "        [1.0539e+04, 6.6758e+03, 3.0928e+03, 7.1439e+03, 1.9859e+02, 1.7671e+02,\n",
      "         5.6248e+04, 1.0138e+05, 6.3740e+01, 6.2524e+01, 0.0000e+00, 1.1059e+03,\n",
      "         1.8007e+03],\n",
      "        [5.6196e+03, 1.8353e+03, 2.1087e+03, 5.4658e+03, 5.6107e+01, 1.3969e+02,\n",
      "         3.3287e+04, 3.9776e+04, 2.4825e+01, 2.1343e+01, 0.0000e+00, 7.0897e+02,\n",
      "         9.4487e+02]], device='cuda:0')}, 1: {'step': 299000, 'square_avg': tensor([6.5458e+04, 3.4092e+04, 7.4695e+04, 5.8132e+04, 2.4792e+04, 2.4773e+06,\n",
      "        1.6291e+04, 1.9729e+04, 6.9116e+03, 6.6584e+05, 3.8891e+06, 3.0791e+04,\n",
      "        2.5785e+04, 5.5398e+04, 1.6420e+04, 7.6933e+04, 6.3954e+05, 1.1098e+05,\n",
      "        4.3636e+05, 1.3625e+06, 3.4191e+04, 7.5843e+03, 6.0735e+03, 2.6114e+05,\n",
      "        1.0480e+05, 5.2033e+05, 3.6040e+04, 1.5477e+04, 2.6602e+05, 2.6652e+06,\n",
      "        1.0297e+04, 4.9788e+05, 1.6143e+06, 4.0127e+04, 2.2469e+05, 1.2820e+05,\n",
      "        4.1535e+05, 7.3674e+04, 1.3178e+04, 1.7692e+06, 7.0798e+03, 1.2089e+04,\n",
      "        1.9142e+03, 5.2399e+04, 3.9126e+04, 4.4264e+04, 5.4727e+04, 5.8490e+06,\n",
      "        9.0235e+04, 3.1266e+04, 1.3055e+04, 7.9962e+03, 7.4111e+05, 2.2088e+05,\n",
      "        4.9852e+04, 3.7024e+04, 2.6079e+05, 5.6981e+04, 2.3022e+06, 1.1071e+05,\n",
      "        3.8882e+05, 1.0009e+04, 1.3701e+04, 7.8907e+03], device='cuda:0')}, 2: {'step': 299000, 'square_avg': tensor([[1.9078e+04, 5.9722e+03, 2.1669e+03,  ..., 6.6541e+02, 5.5724e+02,\n",
      "         1.5708e+04],\n",
      "        [2.3583e+04, 3.6856e+03, 1.6858e+03,  ..., 3.8376e+02, 9.3593e+02,\n",
      "         1.6960e+04],\n",
      "        [1.3769e+04, 2.3633e+03, 1.5312e+03,  ..., 4.2444e+02, 3.0271e+02,\n",
      "         1.5875e+04],\n",
      "        ...,\n",
      "        [2.9147e+04, 3.6945e+03, 2.4994e+03,  ..., 1.4217e+02, 8.1325e+02,\n",
      "         1.9650e+04],\n",
      "        [5.1502e+04, 2.8652e+04, 6.5018e+03,  ..., 6.4392e+03, 9.5254e+02,\n",
      "         1.1494e+05],\n",
      "        [1.5121e+03, 4.1257e+02, 1.5398e+02,  ..., 4.2633e+01, 3.2242e+01,\n",
      "         1.6405e+03]], device='cuda:0')}, 3: {'step': 299000, 'square_avg': tensor([1.5500e+04, 1.5678e+04, 1.2361e+04, 1.1254e+03, 3.1872e+04, 1.1027e+03,\n",
      "        3.8804e+02, 1.0789e+04, 7.7536e+02, 6.1891e+04, 5.4245e+04, 2.2509e+04,\n",
      "        1.5054e+04, 1.8965e+03, 2.4786e+02, 1.3538e+02, 6.5417e+03, 2.1147e+02,\n",
      "        6.2636e+02, 1.1261e+02, 6.0813e+04, 2.0347e+04, 1.4763e+03, 3.4104e+05,\n",
      "        1.6734e+04, 3.0096e+04, 1.2030e+02, 9.9972e+04, 2.4559e+04, 3.1546e+04,\n",
      "        1.6607e+01, 2.2901e+04, 4.0584e+01, 3.1826e+03, 1.8628e+04, 1.1064e+04,\n",
      "        6.9458e+02, 3.4372e+04, 1.6058e+04, 1.6610e+04, 1.2082e+03, 4.0685e+04,\n",
      "        5.5076e+04, 3.8687e+04, 5.5519e+03, 3.1230e+03, 3.0508e+03, 2.5887e+03,\n",
      "        5.6200e+01, 1.8112e+03, 3.7195e+04, 5.0983e+05, 1.0782e+02, 1.5522e+02,\n",
      "        1.4650e+04, 6.0273e+04, 4.1210e+02, 1.5487e+04, 1.6952e+02, 2.3357e+03,\n",
      "        7.8461e+04, 1.9525e+04, 6.8744e+04, 1.4104e+03], device='cuda:0')}, 4: {'step': 299000, 'square_avg': tensor([[7.4827e+01, 1.2255e+00, 5.0957e+02,  ..., 2.1215e+01, 4.2773e+00,\n",
      "         1.9496e+03],\n",
      "        [8.1747e+01, 1.3403e+00, 5.6466e+02,  ..., 2.3194e+01, 4.6584e+00,\n",
      "         2.1593e+03],\n",
      "        [6.3173e+01, 1.0363e+00, 4.3470e+02,  ..., 1.7908e+01, 3.5622e+00,\n",
      "         1.6555e+03],\n",
      "        ...,\n",
      "        [2.6850e+01, 4.4126e-01, 1.9162e+02,  ..., 7.6178e+00, 1.5199e+00,\n",
      "         7.2528e+02],\n",
      "        [2.4588e+01, 4.0408e-01, 1.7547e+02,  ..., 6.9758e+00, 1.3919e+00,\n",
      "         6.6416e+02],\n",
      "        [7.8739e+01, 1.3003e+00, 5.4346e+02,  ..., 2.2330e+01, 4.4443e+00,\n",
      "         2.0653e+03]], device='cuda:0')}, 5: {'step': 299000, 'square_avg': tensor([8.2927e+01, 9.1741e+01, 7.0412e+01, 3.1000e+01, 2.7439e+01, 7.0065e-44,\n",
      "        8.6401e+01, 8.2500e+01, 2.6984e+01, 7.6867e+01, 3.3883e+01, 9.3967e+01,\n",
      "        9.0383e+01, 9.5697e+01, 7.3559e+01, 2.6331e+01, 8.3619e+01, 8.8384e+01,\n",
      "        7.1995e+01, 7.0065e-44, 9.9367e+01, 7.8363e+01, 8.7806e+01, 8.6337e+01,\n",
      "        8.3209e+01, 7.8071e+01, 9.8761e+01, 2.6858e+01, 3.4247e+01, 2.0206e+01,\n",
      "        7.1373e+01, 2.5660e+01, 3.1734e+01, 2.4766e+01, 7.8721e+01, 7.7226e+01,\n",
      "        8.0941e+01, 8.5630e+01, 7.3686e+01, 0.0000e+00, 2.7420e+01, 7.7684e+01,\n",
      "        2.3635e+01, 2.9639e+01, 9.0815e+01, 8.4018e+01, 9.3797e+01, 8.0910e+01,\n",
      "        3.2129e+01, 3.1537e+01, 3.4837e+01, 8.0871e+01, 9.0110e+01, 8.6022e+01,\n",
      "        8.7897e+01, 2.5169e+01, 4.5034e+01, 4.1152e+01, 8.8810e+01, 2.3188e+01,\n",
      "        7.6735e+01, 3.0512e+01, 2.7941e+01, 8.7802e+01], device='cuda:0')}, 6: {'step': 299000, 'square_avg': tensor([[5.9524e+03, 5.7923e+03, 6.3202e+03, 2.5525e+05, 2.6913e+05, 7.0065e-44,\n",
      "         6.1863e+03, 5.6552e+03, 2.6616e+05, 6.0277e+03, 2.1805e+05, 5.9885e+03,\n",
      "         6.3633e+03, 5.4734e+03, 5.5861e+03, 2.8132e+05, 5.1715e+03, 5.4614e+03,\n",
      "         5.9116e+03, 7.0065e-44, 5.8100e+03, 5.7270e+03, 6.1942e+03, 6.1777e+03,\n",
      "         5.8034e+03, 6.1520e+03, 5.0849e+03, 2.9711e+05, 1.2105e+05, 2.5237e+05,\n",
      "         6.1814e+03, 2.5902e+05, 2.6021e+05, 2.4666e+05, 6.2845e+03, 6.8203e+03,\n",
      "         6.0699e+03, 6.1044e+03, 5.8152e+03, 0.0000e+00, 2.3148e+05, 6.2476e+03,\n",
      "         2.7683e+05, 2.0480e+05, 5.9893e+03, 5.2628e+03, 5.7502e+03, 5.6241e+03,\n",
      "         2.4985e+05, 1.9726e+05, 2.2570e+05, 5.8278e+03, 6.2144e+03, 6.0266e+03,\n",
      "         5.7597e+03, 2.9398e+05, 2.8317e+03, 1.6381e+05, 5.6973e+03, 2.4505e+05,\n",
      "         6.1483e+03, 2.6423e+05, 2.8378e+05, 6.1438e+03]], device='cuda:0')}, 7: {'step': 299000, 'square_avg': tensor([60.1590], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"q_optimizer's state_dict:\")\n",
    "for var_name in q_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", q_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd337c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_optimizer's state_dict:\n",
      "state \t {0: {'step': 299000, 'square_avg': tensor([[8.6105e-01, 4.9790e-01, 1.8904e-01, 5.4539e-01, 1.1169e-02, 9.4090e-03,\n",
      "         9.5097e+00, 1.5327e+01, 1.5116e-02, 8.9920e-03, 0.0000e+00],\n",
      "        [1.4412e+00, 6.7878e-01, 2.6247e-01, 9.7308e-01, 1.9922e-02, 2.0455e-02,\n",
      "         4.6969e+00, 9.8027e+00, 7.5594e-03, 4.6400e-03, 0.0000e+00],\n",
      "        [1.4291e+00, 7.7289e-01, 2.2776e-01, 9.4793e-01, 1.6435e-02, 2.0465e-02,\n",
      "         6.4613e+00, 9.6408e+00, 9.9954e-03, 7.9790e-03, 0.0000e+00],\n",
      "        [1.4412e-01, 6.4755e-02, 3.0563e-01, 4.5285e-01, 3.6344e-03, 7.4650e-03,\n",
      "         6.7360e+00, 4.1453e+00, 1.6342e-03, 2.7985e-03, 0.0000e+00],\n",
      "        [8.4601e-02, 3.6184e-02, 2.1278e-02, 7.0556e-02, 1.1436e-03, 1.3483e-03,\n",
      "         7.9308e-01, 1.0898e+00, 6.9021e-04, 5.5292e-04, 0.0000e+00],\n",
      "        [1.2071e+00, 3.8491e-01, 2.7472e-01, 1.0457e+00, 1.0691e-02, 2.4897e-02,\n",
      "         5.6090e+00, 5.4176e+00, 7.7108e-03, 3.1993e-03, 0.0000e+00],\n",
      "        [5.3873e-01, 3.6728e-01, 1.0218e-01, 2.2618e-01, 4.6825e-03, 4.4916e-03,\n",
      "         4.1880e+00, 5.5369e+00, 7.2064e-03, 3.3484e-03, 0.0000e+00],\n",
      "        [2.5695e-02, 2.0149e-02, 5.8434e-02, 6.4128e-02, 5.5184e-04, 1.4119e-03,\n",
      "         1.6785e+00, 8.6297e-01, 6.0470e-04, 7.7081e-04, 0.0000e+00],\n",
      "        [1.5600e-01, 6.1479e-02, 7.0495e-02, 1.7696e-01, 1.8868e-03, 3.2403e-03,\n",
      "         1.1164e+00, 1.7040e+00, 1.0749e-03, 5.4256e-04, 0.0000e+00],\n",
      "        [1.4768e+00, 7.8557e-01, 2.7854e-01, 1.0277e+00, 1.8986e-02, 2.1491e-02,\n",
      "         8.3005e+00, 8.9181e+00, 1.5829e-02, 6.5766e-03, 0.0000e+00],\n",
      "        [1.2554e+00, 6.5498e-01, 3.8652e-01, 8.5529e-01, 9.5642e-03, 1.6208e-02,\n",
      "         8.1371e+00, 9.7838e+00, 1.2703e-02, 8.0632e-03, 0.0000e+00],\n",
      "        [7.1996e-01, 2.9761e-01, 3.4196e-01, 7.5500e-01, 9.4003e-03, 1.3590e-02,\n",
      "         1.1046e+01, 8.0575e+00, 8.9112e-03, 6.6647e-03, 0.0000e+00],\n",
      "        [6.6450e-01, 5.1241e-01, 1.0973e-01, 2.0137e-01, 6.4608e-03, 4.9487e-03,\n",
      "         4.1755e+00, 6.0565e+00, 1.6362e-02, 5.7290e-03, 0.0000e+00],\n",
      "        [7.7140e-02, 3.8687e-02, 4.3541e-02, 8.3944e-02, 9.7751e-04, 1.5072e-03,\n",
      "         8.6310e-01, 1.2481e+00, 1.0264e-03, 4.7454e-04, 0.0000e+00],\n",
      "        [1.5228e+00, 6.1495e-01, 3.0893e-01, 1.2006e+00, 1.7120e-02, 2.2361e-02,\n",
      "         6.0345e+00, 1.1001e+01, 7.3894e-03, 4.5801e-03, 0.0000e+00],\n",
      "        [6.7070e-01, 4.4887e-01, 1.4015e-01, 3.0406e-01, 8.0920e-03, 8.6536e-03,\n",
      "         6.2165e+00, 6.6876e+00, 1.4316e-02, 4.5411e-03, 0.0000e+00],\n",
      "        [8.0311e-01, 2.6155e-01, 1.7116e-01, 4.9597e-01, 8.7027e-03, 1.1399e-02,\n",
      "         3.0017e+00, 3.8122e+00, 4.6250e-03, 3.2333e-03, 0.0000e+00],\n",
      "        [7.6655e-02, 3.4744e-02, 5.1758e-02, 9.6073e-02, 8.0185e-04, 1.7961e-03,\n",
      "         2.5264e+00, 1.4200e+00, 6.1707e-04, 9.1413e-04, 0.0000e+00],\n",
      "        [3.6717e-01, 1.8997e-01, 1.0914e-01, 2.6864e-01, 3.7440e-03, 6.2203e-03,\n",
      "         3.0636e+00, 3.6938e+00, 4.8664e-03, 2.0562e-03, 0.0000e+00],\n",
      "        [1.4658e-01, 8.5053e-02, 1.1323e-01, 2.1977e-01, 3.2415e-03, 3.5031e-03,\n",
      "         2.0188e+00, 1.7073e+00, 1.6710e-03, 1.9261e-03, 0.0000e+00],\n",
      "        [3.9134e-01, 2.0305e-01, 1.0554e-01, 3.0962e-01, 4.9620e-03, 6.8406e-03,\n",
      "         3.2411e+00, 2.7370e+00, 3.8971e-03, 1.6442e-03, 0.0000e+00],\n",
      "        [2.3247e-01, 1.6604e-01, 8.5619e-02, 1.6706e-01, 2.6757e-03, 3.6913e-03,\n",
      "         3.2253e+00, 2.7606e+00, 6.9306e-03, 2.6251e-03, 0.0000e+00],\n",
      "        [2.6413e+00, 9.3759e-01, 8.2393e-01, 1.8107e+00, 3.2219e-02, 3.7910e-02,\n",
      "         2.4802e+01, 2.3856e+01, 1.9095e-02, 1.5760e-02, 0.0000e+00],\n",
      "        [9.8718e-02, 2.5904e-02, 1.2794e-01, 2.1801e-01, 1.4179e-03, 4.4217e-03,\n",
      "         2.2615e+00, 1.8245e+00, 1.4524e-03, 1.3178e-03, 0.0000e+00],\n",
      "        [3.6342e+00, 1.4419e+00, 4.9628e-01, 1.9780e+00, 3.3187e-02, 4.6871e-02,\n",
      "         9.4360e+00, 1.4949e+01, 2.1392e-02, 1.2222e-02, 0.0000e+00],\n",
      "        [3.3990e-01, 1.9388e-01, 1.1674e-01, 2.5697e-01, 1.0312e-02, 2.8659e-03,\n",
      "         4.1686e+00, 4.8186e+00, 6.2037e-03, 3.2484e-03, 0.0000e+00],\n",
      "        [2.0278e+00, 8.1168e-01, 7.1794e-01, 1.7122e+00, 1.6425e-02, 4.0693e-02,\n",
      "         1.0375e+01, 1.3779e+01, 2.0619e-02, 8.2568e-03, 0.0000e+00],\n",
      "        [2.7845e-01, 9.6993e-02, 3.8358e-01, 6.1504e-01, 2.1472e-03, 1.9055e-02,\n",
      "         5.4877e+00, 4.9311e+00, 2.5389e-03, 2.7492e-03, 0.0000e+00],\n",
      "        [1.0907e+00, 5.6581e-01, 2.4046e-01, 7.2098e-01, 1.0660e-02, 1.6966e-02,\n",
      "         4.5407e+00, 8.4693e+00, 6.2204e-03, 4.3268e-03, 0.0000e+00],\n",
      "        [2.5235e-01, 9.9779e-02, 7.3429e-02, 2.2029e-01, 3.1867e-03, 4.5444e-03,\n",
      "         1.6702e+00, 1.9749e+00, 1.2249e-03, 1.5485e-03, 0.0000e+00],\n",
      "        [6.5462e-02, 7.3356e-02, 6.3351e-02, 6.2737e-02, 1.1901e-03, 1.4164e-03,\n",
      "         3.8493e+00, 2.6032e+00, 3.7593e-03, 2.3714e-03, 0.0000e+00],\n",
      "        [3.5423e-01, 1.7372e-01, 7.8142e-02, 2.1605e-01, 4.1013e-03, 3.9220e-03,\n",
      "         1.9015e+00, 2.4733e+00, 3.5913e-03, 1.6292e-03, 0.0000e+00],\n",
      "        [9.3575e-01, 4.9163e-01, 2.0427e-01, 6.0002e-01, 9.0966e-03, 9.8634e-03,\n",
      "         6.3344e+00, 9.5938e+00, 1.2272e-02, 6.0837e-03, 0.0000e+00],\n",
      "        [2.0694e+00, 7.4279e-01, 1.9706e-01, 7.3012e-01, 2.0989e-02, 1.6545e-02,\n",
      "         4.6284e+00, 8.0233e+00, 1.2058e-02, 6.2350e-03, 0.0000e+00],\n",
      "        [1.1834e-02, 1.3302e-02, 3.3809e-02, 3.1787e-02, 4.6709e-04, 3.4878e-04,\n",
      "         1.5205e+00, 7.5811e-01, 4.6879e-04, 6.5463e-04, 0.0000e+00],\n",
      "        [6.3940e+00, 2.6851e+00, 4.1415e-01, 1.5715e+00, 6.4699e-02, 3.7248e-02,\n",
      "         1.1604e+01, 1.8170e+01, 2.6967e-02, 1.0163e-02, 0.0000e+00],\n",
      "        [5.9633e-01, 2.7458e-01, 2.2376e-01, 5.0368e-01, 4.9466e-03, 1.6467e-02,\n",
      "         4.0805e+00, 4.4741e+00, 5.9490e-03, 3.6659e-03, 0.0000e+00],\n",
      "        [1.2275e-01, 4.4391e-02, 4.8629e-02, 1.4800e-01, 1.4633e-03, 3.3079e-03,\n",
      "         9.0151e-01, 1.0586e+00, 8.7173e-04, 4.6937e-04, 0.0000e+00],\n",
      "        [8.9274e-01, 3.4136e-01, 1.7866e-01, 6.0874e-01, 8.6513e-03, 8.8559e-03,\n",
      "         4.8009e+00, 6.6697e+00, 6.3947e-03, 4.3219e-03, 0.0000e+00],\n",
      "        [1.3064e+00, 3.3026e-01, 5.5143e-01, 1.5663e+00, 1.6403e-02, 3.6089e-02,\n",
      "         1.3745e+01, 1.0492e+01, 1.0285e-02, 7.4436e-03, 0.0000e+00],\n",
      "        [1.1637e-02, 1.9385e-02, 3.5437e-02, 2.3609e-02, 4.5148e-04, 5.8048e-04,\n",
      "         2.1967e+00, 1.3731e+00, 6.1176e-04, 6.4109e-04, 0.0000e+00],\n",
      "        [2.8457e-01, 1.2672e-01, 6.6994e-02, 1.9928e-01, 2.8997e-03, 4.2563e-03,\n",
      "         1.4158e+00, 1.8994e+00, 2.2879e-03, 9.5556e-04, 0.0000e+00],\n",
      "        [1.5170e-01, 3.0228e-02, 6.1486e-02, 1.4408e-01, 1.8393e-03, 2.2725e-03,\n",
      "         2.1636e+00, 1.7679e+00, 1.0342e-03, 9.3272e-04, 0.0000e+00],\n",
      "        [4.2203e-01, 1.8057e-01, 8.6534e-02, 3.4579e-01, 3.6094e-03, 6.9661e-03,\n",
      "         1.3235e+00, 2.3087e+00, 3.8829e-03, 8.5946e-04, 0.0000e+00],\n",
      "        [2.5659e+00, 1.2517e+00, 3.7773e-01, 1.1997e+00, 2.3345e-02, 2.4058e-02,\n",
      "         5.5507e+00, 1.5045e+01, 1.8871e-02, 9.6069e-03, 0.0000e+00],\n",
      "        [2.8141e+00, 5.4360e-01, 5.7006e-01, 3.1397e+00, 3.2943e-02, 5.1653e-02,\n",
      "         6.3134e+00, 9.9818e+00, 2.3128e-03, 5.2852e-03, 0.0000e+00],\n",
      "        [2.1258e+00, 8.8738e-01, 6.5041e-01, 2.0153e+00, 2.3587e-02, 4.7769e-02,\n",
      "         1.4989e+01, 1.8126e+01, 1.7597e-02, 9.9559e-03, 0.0000e+00],\n",
      "        [4.5387e-01, 1.5983e-01, 1.2365e-01, 4.1074e-01, 4.6591e-03, 8.5327e-03,\n",
      "         3.4673e+00, 3.4110e+00, 1.8670e-03, 1.1799e-03, 0.0000e+00],\n",
      "        [6.5139e-01, 3.1452e-01, 2.4758e-01, 4.9302e-01, 5.3329e-03, 9.3035e-03,\n",
      "         6.6901e+00, 8.0500e+00, 1.2497e-02, 1.0081e-02, 0.0000e+00],\n",
      "        [1.2228e-01, 6.6571e-02, 3.2496e-02, 7.3830e-02, 1.4432e-03, 1.7643e-03,\n",
      "         6.7805e-01, 9.4910e-01, 9.5725e-04, 8.2939e-04, 0.0000e+00],\n",
      "        [1.0038e+00, 6.4769e-01, 2.2563e-01, 4.8173e-01, 1.0196e-02, 1.3354e-02,\n",
      "         6.7202e+00, 1.2279e+01, 1.9231e-02, 1.0342e-02, 0.0000e+00],\n",
      "        [3.1538e+00, 1.1992e+00, 3.1595e-01, 1.1134e+00, 3.0657e-02, 2.2035e-02,\n",
      "         1.3103e+01, 1.4520e+01, 2.1999e-02, 8.9324e-03, 0.0000e+00],\n",
      "        [1.3143e+00, 9.3791e-01, 2.2951e-01, 4.6502e-01, 7.1405e-03, 1.1373e-02,\n",
      "         5.3454e+00, 1.0032e+01, 2.9493e-02, 1.1580e-02, 0.0000e+00],\n",
      "        [4.8282e-01, 2.5850e-01, 2.2279e-01, 4.2201e-01, 4.8129e-03, 1.0345e-02,\n",
      "         7.7163e+00, 6.5891e+00, 5.7726e-03, 4.1213e-03, 0.0000e+00],\n",
      "        [2.0788e-01, 1.3493e-01, 3.7518e-02, 8.7527e-02, 2.4770e-03, 1.6652e-03,\n",
      "         8.9586e-01, 1.3140e+00, 2.7051e-03, 1.8261e-03, 0.0000e+00],\n",
      "        [1.3511e-01, 8.6334e-02, 2.6068e-02, 7.8046e-02, 2.0872e-03, 1.3435e-03,\n",
      "         1.8601e+00, 1.7721e+00, 2.2026e-03, 1.6337e-03, 0.0000e+00],\n",
      "        [9.3155e-01, 3.8142e-01, 2.1197e-01, 6.2172e-01, 9.1980e-03, 1.2282e-02,\n",
      "         3.4775e+00, 4.6903e+00, 7.2127e-03, 2.5407e-03, 0.0000e+00],\n",
      "        [7.5909e-01, 4.4657e-01, 4.2803e-01, 7.1422e-01, 7.6079e-03, 1.8257e-02,\n",
      "         8.9686e+00, 8.6959e+00, 1.2751e-02, 7.5031e-03, 0.0000e+00],\n",
      "        [8.3210e-02, 5.0196e-02, 4.2892e-02, 6.4672e-02, 7.9530e-04, 1.3731e-03,\n",
      "         1.2827e+00, 1.4301e+00, 1.6323e-03, 1.3347e-03, 0.0000e+00],\n",
      "        [1.6665e-01, 1.0289e-01, 6.6826e-02, 1.0954e-01, 2.5632e-03, 1.8997e-03,\n",
      "         3.9629e+00, 2.3239e+00, 3.3851e-03, 1.7690e-03, 0.0000e+00],\n",
      "        [1.6812e+00, 6.3013e-01, 4.2156e-01, 1.2686e+00, 1.7347e-02, 3.3285e-02,\n",
      "         6.4700e+00, 9.4232e+00, 5.7444e-03, 3.6890e-03, 0.0000e+00],\n",
      "        [6.3025e-01, 3.4621e-01, 1.7317e-01, 4.4585e-01, 8.0500e-03, 9.9098e-03,\n",
      "         4.2208e+00, 6.9479e+00, 6.6636e-03, 5.3899e-03, 0.0000e+00],\n",
      "        [3.2157e-01, 2.2644e-01, 6.3341e-02, 1.2930e-01, 3.5883e-03, 2.2403e-03,\n",
      "         2.9245e+00, 4.8737e+00, 7.1781e-03, 4.1831e-03, 0.0000e+00],\n",
      "        [3.0045e-01, 1.0731e-01, 1.2139e-01, 2.9912e-01, 3.0450e-03, 4.8805e-03,\n",
      "         3.2737e+00, 3.2041e+00, 1.8451e-03, 1.8079e-03, 0.0000e+00]],\n",
      "       device='cuda:0')}, 1: {'step': 299000, 'square_avg': tensor([1.0015, 1.7494, 1.8640, 0.5148, 0.1041, 1.6809, 0.7474, 0.0923, 0.2340,\n",
      "        1.9425, 1.8378, 1.1256, 0.7852, 0.1246, 1.9048, 0.7784, 1.0454, 0.1258,\n",
      "        0.4852, 0.2319, 0.4970, 0.3184, 3.4175, 0.2467, 4.6663, 0.4634, 3.0548,\n",
      "        0.6739, 1.4091, 0.3323, 0.1132, 0.4399, 1.2243, 2.4205, 0.0441, 7.9583,\n",
      "        0.8794, 0.1628, 1.1463, 1.9457, 0.0379, 0.3742, 0.2133, 0.5695, 3.1193,\n",
      "        3.6000, 2.9994, 0.6656, 0.8504, 0.1738, 1.1045, 3.7386, 1.6488, 0.7334,\n",
      "        0.2516, 0.1567, 1.2447, 1.0772, 0.1211, 0.2267, 2.1655, 0.7820, 0.4184,\n",
      "        0.4428], device='cuda:0')}, 2: {'step': 299000, 'square_avg': tensor([[1.0750, 0.5678, 1.5206,  ..., 1.1211, 1.3254, 0.1599],\n",
      "        [0.1269, 0.0777, 0.1617,  ..., 0.2091, 0.2590, 0.0388],\n",
      "        [0.1687, 0.0880, 0.1948,  ..., 0.1973, 0.2531, 0.0290],\n",
      "        ...,\n",
      "        [0.3334, 0.1468, 0.3789,  ..., 0.2271, 0.3640, 0.0423],\n",
      "        [0.0529, 0.0373, 0.0710,  ..., 0.0608, 0.0745, 0.0124],\n",
      "        [0.8480, 0.3567, 1.1796,  ..., 0.4106, 0.4571, 0.0804]],\n",
      "       device='cuda:0')}, 3: {'step': 299000, 'square_avg': tensor([3.1895e+00, 5.2434e-01, 5.0296e-01, 2.3938e-01, 3.4301e-01, 1.1364e+00,\n",
      "        7.0065e-44, 1.2309e+00, 4.6850e+00, 1.5790e-01, 2.9735e-01, 2.7623e-01,\n",
      "        6.4482e-01, 4.9145e-01, 1.5722e+00, 8.3578e-01, 6.1562e-01, 1.4553e+00,\n",
      "        2.7113e+00, 2.7234e-01, 1.2900e+00, 1.3346e+00, 5.5408e-01, 4.6035e+00,\n",
      "        4.7761e-01, 2.9026e+00, 2.1883e+00, 3.2919e-01, 5.7573e-01, 1.2672e+00,\n",
      "        2.3465e+00, 1.7535e+00, 6.2400e+00, 1.2021e+00, 2.0952e+00, 2.3993e+00,\n",
      "        4.2552e-01, 1.5420e+00, 2.4077e-01, 3.8176e+00, 5.1684e-01, 1.2857e-01,\n",
      "        3.1301e-01, 1.0151e+00, 9.3160e-01, 5.1838e+00, 2.3380e+00, 8.6278e-01,\n",
      "        5.5322e+00, 8.8383e-01, 9.9537e-01, 2.2475e+00, 1.4909e-01, 1.8508e+00,\n",
      "        6.0013e-01, 2.3774e-01, 2.6644e+00, 2.5668e+00, 1.5965e-01, 3.1297e-01,\n",
      "        4.8434e-01, 6.3295e-01, 2.3115e-01, 2.0178e+00], device='cuda:0')}, 4: {'step': 299000, 'square_avg': tensor([[0.1053, 0.0585, 0.1909,  ..., 0.1359, 0.3877, 0.0517],\n",
      "        [0.0203, 0.0446, 0.0675,  ..., 0.0481, 0.0976, 0.0246],\n",
      "        [0.0136, 0.0275, 0.0436,  ..., 0.0314, 0.0665, 0.0160],\n",
      "        ...,\n",
      "        [0.0426, 0.1372, 0.1585,  ..., 0.1174, 0.2076, 0.0634],\n",
      "        [0.0064, 0.0217, 0.0241,  ..., 0.0206, 0.0519, 0.0141],\n",
      "        [0.0517, 0.0818, 0.1393,  ..., 0.1170, 0.3222, 0.0366]],\n",
      "       device='cuda:0')}, 5: {'step': 299000, 'square_avg': tensor([0.2250, 0.1371, 0.0877, 0.0291, 0.3219, 0.0192, 0.0265, 0.1111, 0.0721,\n",
      "        0.3654, 0.0422, 0.0395, 0.0953, 0.0982, 0.0524, 1.1461, 0.0548, 0.0344,\n",
      "        0.7573, 0.2740, 0.1323, 0.1478, 0.0092, 0.6552, 0.5659, 0.4317, 2.4614,\n",
      "        0.0620, 0.2010, 0.0896, 0.0603, 0.4007, 0.0510, 0.0449, 0.1896, 0.3625,\n",
      "        0.1096, 0.0811, 0.0645, 0.0404, 0.0857, 0.1707, 0.0145, 0.0574, 0.1486,\n",
      "        0.1125, 0.2601, 0.4300, 0.0810, 0.3137, 0.1212, 0.1451, 0.3035, 0.2958,\n",
      "        0.0304, 0.2136, 0.0615, 0.2145, 0.0845, 0.0591, 0.3258, 0.3446, 0.0514,\n",
      "        0.2376], device='cuda:0')}, 6: {'step': 299000, 'square_avg': tensor([[1.9224e-03, 4.5509e-01, 7.3553e-01, 7.1204e-04, 2.3535e-01, 3.3627e-01,\n",
      "         4.3406e-01, 3.7879e-01, 1.8200e-01, 2.3148e-01, 2.3310e-01, 2.2864e-01,\n",
      "         1.6446e-01, 4.3540e-01, 3.8214e-01, 2.3969e-02, 1.4387e-02, 6.0346e-01,\n",
      "         2.5183e-02, 2.2247e-02, 3.6838e-01, 3.5356e-01, 1.5669e-01, 2.7921e-01,\n",
      "         1.6856e-01, 1.1358e-03, 1.3547e-02, 1.5994e-01, 3.2697e-01, 2.4400e-01,\n",
      "         2.9597e-01, 4.5365e-01, 2.4211e-01, 1.4697e-01, 2.2987e-01, 2.6189e-03,\n",
      "         6.9346e-01, 5.1969e-01, 1.3403e-02, 2.4396e-01, 2.1228e-01, 5.7950e-02,\n",
      "         1.6121e-03, 2.8529e-01, 7.1153e-02, 5.9023e-01, 2.1060e-01, 4.2966e-01,\n",
      "         6.1384e-01, 3.3086e-03, 7.8530e-02, 9.7835e-01, 2.3660e-01, 5.5337e-01,\n",
      "         1.1208e-01, 3.5262e-04, 1.0994e-01, 2.2553e-01, 2.8644e-01, 2.0261e-01,\n",
      "         7.6261e-03, 2.7459e-01, 1.8586e-01, 5.1333e-02],\n",
      "        [2.6125e-03, 1.6780e+00, 2.7906e+00, 5.8776e-04, 1.0501e+00, 1.3280e+00,\n",
      "         1.6630e+00, 1.5221e+00, 6.8648e-01, 9.9061e-01, 8.7053e-01, 9.8757e-01,\n",
      "         5.3849e-01, 1.5467e+00, 1.5748e+00, 1.0246e-01, 2.3420e-02, 2.3779e+00,\n",
      "         8.7857e-02, 1.2924e-01, 1.4129e+00, 1.4668e+00, 6.3836e-01, 6.3535e-01,\n",
      "         6.9630e-01, 1.5576e-03, 5.0495e-02, 6.8084e-01, 1.1398e+00, 1.0436e+00,\n",
      "         1.2413e+00, 1.9053e+00, 1.0338e+00, 6.6864e-01, 7.8786e-01, 7.2276e-03,\n",
      "         2.7432e+00, 1.9451e+00, 2.7478e-02, 7.2858e-01, 8.6844e-01, 1.7758e-01,\n",
      "         2.0539e-03, 9.7667e-01, 2.7610e-01, 2.0307e+00, 8.8230e-01, 1.7806e+00,\n",
      "         2.2026e+00, 9.8589e-03, 3.3628e-01, 3.9042e+00, 9.5842e-01, 1.8025e+00,\n",
      "         4.1610e-01, 7.4002e-04, 3.1468e-01, 1.1025e+00, 1.1132e+00, 6.9447e-01,\n",
      "         1.3206e-02, 9.8419e-01, 6.6680e-01, 1.8215e-01]], device='cuda:0')}, 7: {'step': 299000, 'square_avg': tensor([0.5322, 2.1757], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"pi_optimizer's state_dict:\")\n",
    "for var_name in pi_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", pi_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8ae61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a48a149bc7a8dee0435672efcae6f64e48d62311a35302b209b3ac517d7f9c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cosmic_rays_x_py38_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
