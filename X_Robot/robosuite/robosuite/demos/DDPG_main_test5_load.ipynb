{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import gym\n",
    "from PIL import Image\n",
    "# from pyvirtualdisplay import Display\n",
    "# Display().start()\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim import RMSprop\n",
    "import gym\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# # sys.path.append('set PATH=C:/Users/c3296143/.mujoco/mujoco200/bin;%PATH%')\n",
    "# # sys.path.append('set PATH=C://Users//c3296143//.mujoco//mujoco200//bin;%PATH%')\n",
    "# # sys.path.append('C:/Users/c3296143/.mujoco/mujoco200/bin')\n",
    "# # sys.path.append('C://Users//c3296143//.mujoco//mujoco200//bin')\n",
    "# # os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + 'C:/Users/c3296143/root/.mujoco/mujoco200/bin'\n",
    "# # old = os.environ.get(\"LD_LIBRARY_PATH\")\n",
    "# old = os.environ.get(\"PATH\")\n",
    "# # os.environ[\"PATH\"] = 'C:\\> set PATH=%PATH%;C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# # os.environ[\"PATH\"] = 'set PATH=C:/Users/c3296143/.mujoco/mujoco200/bin;%PATH%'\n",
    "\n",
    "# if old:\n",
    "#     os.environ[\"PATH\"] = old + \";\" +'C:\\\\Users\\\\c3296143\\\\.mujoco\\\\mujoco200\\\\bin'\n",
    "# #     os.environ[\"LD_LIBRARY_PATH\"] = old + \":\" + 'C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# # else:\n",
    "# #     os.environ[\"LD_LIBRARY_PATH\"] = 'C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# else:\n",
    "#     os.environ[\"PATH\"] = 'C:\\\\Users\\\\c3296143\\\\.mujoco\\\\mujoco200\\\\bin'\n",
    "\n",
    "# print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.controllers import load_controller_config\n",
    "from robosuite.controllers.controller_factory import reset_controllers\n",
    "from robosuite.utils import observables\n",
    "from robosuite.utils.input_utils import *\n",
    "from robosuite.robots import Bimanual\n",
    "import imageio\n",
    "import numpy as np\n",
    "import robosuite.utils.macros as macros\n",
    "macros.IMAGE_CONVENTION = \"opencv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'env_name': 'EElab_test6',\n",
    "    \"robots\": \"UR5e\"\n",
    "}\n",
    "controller_name = \"JOINT_VELOCITY\"\n",
    "options[\"controller_configs\"] = suite.load_controller_config(default_controller=controller_name)\n",
    "\n",
    "env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=False,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types=None,\n",
    "    renderer = 'mujoco',\n",
    "\n",
    ")\n",
    "\n",
    "test_env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=True,\n",
    "    has_offscreen_renderer=False,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types=None,\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "\n",
    "video_env = suite.make(\n",
    "    **options,\n",
    "    gripper_types=None,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=True,\n",
    "    use_object_obs=True, \n",
    "    camera_names='Labviewer',\n",
    "    camera_heights=512,\n",
    "    camera_widths=512,\n",
    "    # control_freq=200,\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "frame = []\n",
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class MLPActor(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation, act_limit):\n",
    "        super().__init__()\n",
    "        pi_sizes = [obs_dim] + list(hidden_sizes) + [act_dim]\n",
    "        self.pi = mlp(pi_sizes, activation, nn.Tanh)\n",
    "        self.act_limit = act_limit\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Return output from network scaled to action space limits.\n",
    "        return self.act_limit * self.pi(obs)\n",
    "\n",
    "class MLPQFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        q = self.q(torch.cat([obs, act], dim=-1))\n",
    "        return torch.squeeze(q, -1) # Critical to ensure q has right shape.\n",
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_sizes=(256,256),\n",
    "                 activation=nn.ReLU, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        obs_dim = 35\n",
    "        act_dim = 6\n",
    "        act_limit = 1\n",
    "\n",
    "        # build policy and value functions\n",
    "        self.pi = MLPActor(obs_dim, act_dim, hidden_sizes, activation, act_limit).to(device)\n",
    "        self.q = MLPQFunction(obs_dim, act_dim, hidden_sizes, activation).to(device)\n",
    "\n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            return self.pi(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('obs', 'act', 'rew', 'next_obs', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"hid\": 256,\n",
    "    \"l\": 3,\n",
    "    \"seed\": 0,\n",
    "    \"steps_per_epoch\": 3000,\n",
    "    \"steps_video\": 30000,\n",
    "    \"epochs\": 1000,\n",
    "    \"replay_size\": int(1e8),\n",
    "    \"gamma\": 0.99,\n",
    "    \"polyak\": 0.995,\n",
    "    \"pi_lr\": 1e-4,\n",
    "    \"q_lr\": 1e-4,\n",
    "    \"batch_size\": 1000,\n",
    "    \"start_steps\": 10000, \n",
    "    \"update_after\": 5000,\n",
    "    \"update_every\": 100,\n",
    "    \"act_noise\": 0.01,\n",
    "    \"num_test_episodes\": 1,\n",
    "    \"max_ep_len\": 300,\n",
    "    \"max_video_len\": 300,\n",
    "    \"save_model_len\": 10000,\n",
    "    # \"obs_dim\": 47,\n",
    "    # \"act_dim\": 7,\n",
    "    # \"act_limit\": 1\n",
    "}\n",
    "\n",
    "ac_kwargs=dict(hidden_sizes=[params[\"hid\"]]*params[\"l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim =  35\n",
      "act_dim =  6\n",
      "act_limit =  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "np.random.seed(params[\"seed\"])\n",
    "\n",
    "obs_dim = 35\n",
    "print('obs_dim = ', obs_dim)\n",
    "act_dim = 6\n",
    "print('act_dim = ', act_dim)\n",
    "# Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "act_limit = 1\n",
    "print('act_limit = ', act_limit)\n",
    "# Create actor-critic module and target networks\n",
    "ac = MLPActorCritic(**ac_kwargs)\n",
    "ac_targ = deepcopy(ac)\n",
    "\n",
    "# Freeze target networks with respect to optimizers (only update via polyak averaging)\n",
    "for p in ac_targ.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "memory = ReplayMemory(params[\"replay_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function for computing DDPG Q-loss\n",
    "def compute_loss_q(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "    a = torch.cat(data.act).float()\n",
    "    r = torch.cat(data.rew).float()\n",
    "    o2 =torch.cat(data.next_obs).float()\n",
    "    d = torch.cat(data.done).float()\n",
    "\n",
    "    q = ac.q(o,a)\n",
    "\n",
    "\n",
    "    # Bellman backup for Q function\n",
    "    with torch.no_grad():\n",
    "        q_pi_targ = ac_targ.q(o2, ac_targ.pi(o2))\n",
    "        backup = r + params[\"gamma\"] * (1 - d) * q_pi_targ\n",
    "\n",
    "    # MSE loss against Bellman backup\n",
    "    loss_q = ((q - backup)**2).mean()\n",
    "\n",
    "    return loss_q\n",
    "\n",
    "# Set up function for computing DDPG pi loss\n",
    "def compute_loss_pi(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "\n",
    "    q_pi = ac.q(o, ac.pi(o))\n",
    "\n",
    "    return -q_pi.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "def update(data):\n",
    "    # First run one gradient descent step for Q.\n",
    "\n",
    "\n",
    "    q_optimizer.zero_grad()\n",
    "    loss_q = compute_loss_q(data)\n",
    "\n",
    "    loss_q.backward()\n",
    "\n",
    "    q_optimizer.step()\n",
    "\n",
    "\n",
    "    # Freeze Q-network so you don't waste computational effort \n",
    "    # computing gradients for it during the policy learning step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Next run one gradient descent step for pi.\n",
    "    pi_optimizer.zero_grad()\n",
    "    loss_pi = compute_loss_pi(data)\n",
    "    loss_pi.backward()\n",
    "    pi_optimizer.step()\n",
    "\n",
    "    # Unfreeze Q-network so you can optimize it at next DDPG step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "    # Finally, update target networks by polyak averaging.\n",
    "    with torch.no_grad():\n",
    "        for p, p_targ in zip(ac.parameters(), ac_targ.parameters()):\n",
    "            # NB: We use an in-place operations \"mul_\", \"add_\" to update target\n",
    "            # params, as opposed to \"mul\" and \"add\", which would make new tensors.\n",
    "            p_targ.data.mul_(params[\"polyak\"])\n",
    "            p_targ.data.add_((1 - params[\"polyak\"]) * p.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_action(o, noise_scale):\n",
    "    a = ac.act(torch.as_tensor(o, dtype=torch.float32))\n",
    "    a += noise_scale * torch.randn(act_dim).to(device)\n",
    "    return torch.clip(a, -act_limit, act_limit)\n",
    "\n",
    "def test_agent(epoch):\n",
    "    test_main = 0\n",
    "    test_step = 0\n",
    "\n",
    "    for j in range(params[\"num_test_episodes\"]):\n",
    "        obs, d, test_ep_ret, test_ep_len = test_env.reset(), False, 0, 0\n",
    "        env.render()\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        while not(d or (test_ep_len == params[\"max_ep_len\"])):\n",
    "            a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "            obs, r, d, _ = test_env.step(a_cpu[0])\n",
    "            env.render()\n",
    "            o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "            o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "            test_ep_ret += r\n",
    "            test_ep_len += 1\n",
    "        test_ep_main = test_ep_ret/test_ep_len\n",
    "        test_step +=1\n",
    "        test_main += test_ep_main\n",
    "    print('test_rew_main = ', float(test_main/test_step))\n",
    "\n",
    "    \n",
    "def video_agent(epoch):\n",
    "    obs, d, test_ep_len = video_env.reset(), False, 0\n",
    "    o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "    o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "    now = datetime.now()\n",
    "    current_time = str(now.isoformat())\n",
    "    writer = imageio.get_writer(\n",
    "        \"/home/xhnfly/Cosmic_rays_X/X_Robot/robosuite/robosuite/demos/video/DDPG_292/DDPG_UR5_%s_ep_%d.mp4\" % (current_time, epoch), fps=100)\n",
    "    frame = obs[\"Labviewer_image\"]\n",
    "    writer.append_data(frame)\n",
    "\n",
    "    while not(d or (test_ep_len == params[\"max_video_len\"])):\n",
    "        a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "        obs, _, d, _ = video_env.step(a_cpu[0])\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        frame = obs[\"Labviewer_image\"]\n",
    "        writer.append_data(frame)\n",
    "        test_ep_len += 1\n",
    "    writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = {\n",
    "#     'robot0_joint_pos_cos': None,\n",
    "#     'robot0_joint_pos_sin': None,\n",
    "#     'robot0_joint_vel': None,\n",
    "#     'robot0_eef_pos': None,\n",
    "#     'robot0_eef_quat': None,\n",
    "#     'robot0_gripper_qpos': None,\n",
    "#     'robot0_gripper_qvel': None,\n",
    "#     'cubeA_pos': None,\n",
    "#     'cubeA_quat': None,\n",
    "#     'cubeB_pos': None,\n",
    "#     'cubeB_quat': None,\n",
    "#     'gripper_to_cubeA': None,\n",
    "#     'gripper_to_cubeB': None,\n",
    "#     'cubeA_to_cubeB': None,\n",
    "# }\n",
    "\n",
    "obs, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "\n",
    "# env.viewer.set_camera(camera_id=0)\n",
    "\n",
    "\n",
    "# Define neutral value\n",
    "neutral = np.zeros(7)\n",
    "\n",
    "# Keep track of done variable to know when to break loop\n",
    "\n",
    "# Prepare for interaction with environment\n",
    "total_steps = params[\"steps_per_epoch\"] * params[\"epochs\"]\n",
    "start_time = time.time()\n",
    "\n",
    "o = torch.tensor([o], device=device)\n",
    "\n",
    "\n",
    "start_time_rec = datetime.now()\n",
    "r_true = 0\n",
    "total_main = 0\n",
    "ep_rew_main = 0\n",
    "reward_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "q.0.weight \t torch.Size([256, 41])\n",
      "q.0.bias \t torch.Size([256])\n",
      "q.2.weight \t torch.Size([256, 256])\n",
      "q.2.bias \t torch.Size([256])\n",
      "q.4.weight \t torch.Size([256, 256])\n",
      "q.4.bias \t torch.Size([256])\n",
      "q.6.weight \t torch.Size([1, 256])\n",
      "q.6.bias \t torch.Size([1])\n",
      "Model's state_dict:\n",
      "pi.0.weight \t torch.Size([256, 35])\n",
      "pi.0.bias \t torch.Size([256])\n",
      "pi.2.weight \t torch.Size([256, 256])\n",
      "pi.2.bias \t torch.Size([256])\n",
      "pi.4.weight \t torch.Size([256, 256])\n",
      "pi.4.bias \t torch.Size([256])\n",
      "pi.6.weight \t torch.Size([6, 256])\n",
      "pi.6.bias \t torch.Size([6])\n",
      "q_optimizer's state_dict:\n",
      "state \t {0: {'step': 1125000, 'square_avg': tensor([[7.5870e-05, 1.6007e-04, 1.2199e-04,  ..., 1.6429e-04, 2.7991e-04,\n",
      "         1.1999e-04],\n",
      "        [7.6613e-05, 3.5789e-05, 7.0021e-05,  ..., 1.1412e-04, 1.0993e-04,\n",
      "         8.5351e-05],\n",
      "        [8.5452e-05, 2.5582e-04, 1.1129e-04,  ..., 2.2757e-04, 2.4231e-04,\n",
      "         2.1153e-04],\n",
      "        ...,\n",
      "        [3.4444e-05, 8.9895e-05, 7.1607e-05,  ..., 1.1859e-04, 1.1286e-04,\n",
      "         7.0732e-05],\n",
      "        [8.3126e-05, 1.1261e-04, 1.2878e-04,  ..., 1.3407e-04, 1.5350e-04,\n",
      "         1.0252e-04],\n",
      "        [4.9352e-05, 4.0609e-05, 5.3715e-05,  ..., 6.4658e-05, 7.5722e-05,\n",
      "         7.5898e-05]], device='cuda:0')}, 1: {'step': 1125000, 'square_avg': tensor([3.0279e-04, 1.5704e-04, 5.5512e-04, 2.6597e-01, 1.0343e-03, 8.2977e-04,\n",
      "        1.2703e-04, 2.3267e-03, 1.0314e-03, 3.0503e-04, 3.6488e-04, 1.4843e-03,\n",
      "        1.4728e-03, 3.1807e-04, 2.9739e-04, 1.4020e-03, 4.5485e-04, 7.3160e-04,\n",
      "        2.0303e-03, 2.0969e-04, 2.5972e-03, 1.4526e-04, 3.5001e-03, 3.0763e-03,\n",
      "        3.4036e-04, 4.2290e-04, 1.7529e-04, 3.8500e-02, 1.2476e-03, 2.0287e-04,\n",
      "        5.4244e-04, 9.1430e-04, 1.4022e-04, 1.1305e-03, 3.5302e-04, 9.8647e-04,\n",
      "        4.9981e-04, 2.2664e-03, 1.2389e-03, 3.2283e-04, 1.0831e-03, 3.9243e-04,\n",
      "        1.6205e-04, 2.2542e-04, 9.3210e-05, 2.5318e-04, 1.0763e-04, 3.1090e-04,\n",
      "        5.4656e-04, 2.5922e-03, 1.6020e-03, 3.2322e-04, 2.8917e-03, 6.0634e-05,\n",
      "        7.9386e-04, 1.7475e-04, 3.1004e-04, 6.1999e-04, 5.5949e-03, 3.6178e-04,\n",
      "        3.4214e-04, 5.1680e-03, 1.4568e-04, 9.4012e-05, 1.9343e-04, 1.7128e-04,\n",
      "        9.1682e-05, 2.4125e-04, 3.7114e-04, 4.1549e-05, 6.2501e-04, 2.0316e-03,\n",
      "        1.7349e-02, 1.1745e-03, 2.1659e-02, 1.3289e-03, 2.0284e-04, 2.8729e-02,\n",
      "        7.8723e-05, 2.0061e-04, 1.3267e-04, 5.4320e-03, 5.2677e-03, 1.3368e-03,\n",
      "        1.3778e-03, 1.1662e-02, 1.1778e-03, 4.3523e-03, 6.9226e-04, 4.6755e-04,\n",
      "        1.7822e-04, 5.2975e-04, 2.2608e-04, 6.4554e-05, 1.2372e-04, 1.8836e-04,\n",
      "        1.4788e-04, 1.2833e-03, 2.3696e-04, 2.6190e-04, 1.6937e-03, 1.1581e-04,\n",
      "        2.5494e-04, 3.1099e-04, 1.7065e-04, 2.1598e-04, 2.6945e-04, 4.5245e-04,\n",
      "        2.7308e-03, 2.8977e-04, 1.1146e-04, 2.7230e-04, 4.8038e-04, 5.4607e-04,\n",
      "        2.0194e-03, 1.9155e-04, 2.6123e-05, 2.5208e-04, 4.2443e-04, 2.4070e-04,\n",
      "        1.5420e-04, 4.6539e-04, 2.9630e-04, 2.6121e-04, 1.7064e-04, 8.2714e-02,\n",
      "        1.6964e-03, 1.7223e-04, 1.0587e-04, 2.6120e-04, 8.6430e-05, 3.9893e-04,\n",
      "        5.1877e-04, 4.8965e-03, 9.0666e-04, 9.2296e-05, 8.2000e-03, 4.6844e-04,\n",
      "        1.7900e-04, 2.4887e-01, 1.3661e-03, 7.6082e-04, 1.1459e-02, 1.3383e-03,\n",
      "        5.0436e-04, 4.8936e-04, 4.6145e-04, 4.6984e-04, 2.0121e-04, 1.8713e-01,\n",
      "        4.5103e-04, 2.5941e-04, 8.1223e-04, 2.3726e-04, 2.9664e-04, 2.9355e-04,\n",
      "        1.9109e-04, 2.0070e-04, 3.1003e-04, 7.3211e-04, 1.8147e-04, 4.0074e-04,\n",
      "        2.6410e-04, 2.6363e-04, 2.3290e-04, 2.2536e-04, 4.7664e-04, 2.2650e-04,\n",
      "        1.6018e-03, 6.3678e-02, 9.7435e-05, 3.2001e-04, 1.2301e-04, 6.8543e-02,\n",
      "        9.4938e-05, 6.4997e-02, 1.7931e-04, 5.0292e-03, 1.3689e-03, 2.3591e-04,\n",
      "        2.9860e-04, 1.0360e-03, 2.6514e-03, 5.2379e-04, 3.0728e-04, 5.9210e-04,\n",
      "        3.4204e-03, 8.7571e-03, 4.3066e-04, 2.3565e-04, 8.8762e-03, 1.1969e-04,\n",
      "        3.1539e-04, 2.6351e-04, 1.8753e-04, 3.6663e-04, 1.9536e-04, 5.9647e-01,\n",
      "        2.6190e-04, 7.6288e-04, 7.1469e-04, 2.3364e-04, 6.5495e-04, 5.4079e-04,\n",
      "        8.7885e-04, 3.5218e-04, 5.6879e-02, 1.5433e-03, 2.4646e-04, 6.5022e-02,\n",
      "        4.8053e-04, 1.0061e-03, 1.8081e-01, 3.8915e-04, 1.5712e-03, 2.2842e-04,\n",
      "        1.2130e-03, 2.3258e-04, 4.6328e-04, 6.0296e-02, 4.5524e-01, 8.9764e-04,\n",
      "        1.1086e-04, 1.0931e-04, 5.8724e-04, 8.7205e-05, 4.3498e-04, 9.8921e-04,\n",
      "        3.7897e-04, 5.5635e-04, 3.4989e-04, 3.1740e-04, 8.3215e-05, 1.4772e-03,\n",
      "        2.7074e-04, 1.2097e-04, 2.3705e-01, 6.7255e-04, 1.3681e-04, 2.8209e-04,\n",
      "        2.2934e-01, 2.9133e-03, 6.5438e-05, 4.3784e-04, 1.2557e-03, 1.0161e-03,\n",
      "        4.9277e-04, 1.3904e-01, 9.8665e-04, 5.5687e-04, 1.1597e-04, 2.7524e-04,\n",
      "        3.8904e-04, 1.7914e-04, 1.8985e-04, 9.7588e-05], device='cuda:0')}, 2: {'step': 1125000, 'square_avg': tensor([[6.8368e-06, 1.3587e-05, 1.2433e-06,  ..., 4.7518e-06, 3.5734e-07,\n",
      "         2.6369e-06],\n",
      "        [8.8029e-06, 3.9166e-06, 1.8822e-05,  ..., 1.4741e-05, 5.2179e-06,\n",
      "         2.7428e-06],\n",
      "        [5.1932e-06, 2.2104e-06, 9.5642e-06,  ..., 2.5852e-06, 4.2269e-07,\n",
      "         8.0635e-07],\n",
      "        ...,\n",
      "        [1.3297e-05, 4.1151e-06, 4.7535e-06,  ..., 1.4685e-05, 1.8945e-06,\n",
      "         4.4646e-06],\n",
      "        [1.0478e-05, 3.5538e-06, 2.5810e-06,  ..., 2.6933e-06, 1.2712e-06,\n",
      "         1.3479e-06],\n",
      "        [2.7600e-06, 2.2237e-07, 2.8158e-06,  ..., 1.2817e-06, 4.1631e-07,\n",
      "         9.3455e-07]], device='cuda:0')}, 3: {'step': 1125000, 'square_avg': tensor([3.5126e-04, 6.5667e-04, 1.2364e-04, 5.3735e-03, 1.4198e-04, 3.4492e-05,\n",
      "        3.6895e-04, 2.7758e-02, 5.2803e-05, 1.9746e-03, 1.0540e-03, 6.6550e-05,\n",
      "        6.4454e-03, 4.1184e-04, 1.9379e-02, 4.6335e-10, 3.3932e-03, 1.6954e-04,\n",
      "        1.1699e-03, 5.6646e-04, 8.5709e-05, 3.7464e-04, 2.1802e-05, 3.3215e-05,\n",
      "        2.5184e-04, 9.3672e-05, 6.5338e-03, 1.8384e-04, 3.4071e-02, 9.9079e-05,\n",
      "        1.7021e-04, 6.8267e-04, 5.2127e-05, 3.9205e-04, 1.5490e-04, 4.8725e-03,\n",
      "        6.6874e-04, 1.6865e-05, 1.5805e-03, 1.4533e-04, 7.0065e-44, 1.4159e-03,\n",
      "        9.6512e-03, 6.3021e-04, 1.5637e-01, 5.4023e-05, 7.0065e-44, 4.5758e-04,\n",
      "        4.2982e-02, 7.0023e-05, 1.1117e-04, 3.8162e-05, 2.0277e-05, 1.1867e-04,\n",
      "        2.9480e-04, 2.6343e-05, 2.5320e-03, 3.0443e-05, 8.5755e-05, 2.9846e-05,\n",
      "        2.8149e-04, 2.1001e-04, 3.5622e-02, 2.1062e-04, 1.0520e-04, 1.0353e-04,\n",
      "        4.6353e-05, 1.3879e-03, 5.7012e-05, 9.7388e-04, 5.8908e-03, 1.5076e-03,\n",
      "        1.4039e-03, 2.2941e-04, 1.2544e-03, 1.8250e-04, 3.5585e-04, 6.3965e-04,\n",
      "        1.1625e-03, 6.0278e-03, 5.8991e-05, 7.5734e-03, 1.7830e-02, 6.8151e-05,\n",
      "        1.7058e-03, 2.7999e-05, 3.6579e-05, 6.8970e-05, 3.6299e-04, 2.6110e-04,\n",
      "        4.3764e-05, 1.4957e-03, 3.4840e-04, 6.8592e-05, 4.1081e-04, 1.6738e-03,\n",
      "        8.9139e-05, 1.3308e-01, 6.9719e-04, 2.8094e-03, 1.0417e-04, 9.6812e-03,\n",
      "        8.9179e-06, 4.6189e-04, 3.6828e-04, 1.1221e-04, 4.9425e-03, 1.0597e-04,\n",
      "        7.8419e-04, 5.4102e-05, 7.0065e-44, 1.5628e-03, 5.9178e-04, 7.4357e-05,\n",
      "        2.1492e-05, 1.9300e-05, 6.8602e-04, 6.2809e-03, 5.7918e-04, 2.9082e-05,\n",
      "        1.4879e-04, 2.5444e-04, 8.1390e-03, 2.7117e-02, 8.1548e-05, 7.9631e-04,\n",
      "        3.7395e-03, 3.8609e-04, 5.3522e-02, 2.2370e-05, 5.5390e-05, 5.7103e-03,\n",
      "        5.3441e-05, 6.8258e-04, 5.0993e-04, 3.6765e-04, 1.4313e-05, 9.3326e-03,\n",
      "        7.4358e-04, 6.1519e-03, 1.3748e-04, 2.0204e-04, 7.3414e-05, 1.7127e-05,\n",
      "        8.7217e-03, 2.5242e-05, 2.9700e-03, 5.8921e-05, 2.6440e-04, 5.5675e-05,\n",
      "        1.2106e-04, 7.7571e-05, 1.8636e-05, 7.8857e-05, 1.0026e-04, 1.3408e-05,\n",
      "        8.5023e-04, 6.0135e-04, 2.0813e-04, 7.5593e-04, 4.1386e-05, 2.8987e-05,\n",
      "        1.0111e-02, 3.7884e-03, 3.0021e-04, 1.3084e-05, 8.9594e-05, 6.1400e-02,\n",
      "        5.1472e-04, 2.1869e-02, 6.4417e-04, 1.1114e-05, 2.5288e-05, 2.1922e-04,\n",
      "        3.4321e-03, 9.4828e-04, 5.6059e-05, 5.0012e-02, 1.1660e-04, 5.2700e-03,\n",
      "        8.4075e-05, 3.1064e-05, 1.3829e-04, 7.4129e-04, 7.4066e-03, 4.3764e-05,\n",
      "        1.6589e-03, 8.7917e-05, 8.3182e-06, 1.4862e-03, 1.0474e-01, 9.8540e-05,\n",
      "        5.5566e-03, 3.4467e-04, 1.7078e-03, 7.0065e-44, 2.1103e-04, 1.0787e-04,\n",
      "        9.3628e-05, 1.6001e-02, 3.6744e-03, 8.5894e-05, 3.6080e-04, 9.3868e-05,\n",
      "        1.2115e-03, 6.5762e-05, 6.8014e-05, 2.0433e-02, 1.8256e-05, 5.8574e-05,\n",
      "        7.0065e-44, 5.7322e-04, 1.1267e-04, 4.2106e-04, 5.7293e-05, 1.6661e-04,\n",
      "        2.8859e-04, 5.1658e-04, 1.7970e-04, 8.6809e-05, 1.8064e-04, 1.2785e-04,\n",
      "        1.3487e-03, 8.6548e-04, 1.0245e-04, 1.8286e-04, 6.2591e-06, 6.4587e-05,\n",
      "        9.7369e-03, 3.0758e-05, 4.2646e-03, 2.5355e-06, 1.0455e-04, 2.0122e-06,\n",
      "        2.1487e-04, 1.3760e-02, 2.2316e-04, 5.6198e-05, 3.8569e-05, 6.5381e-04,\n",
      "        5.2776e-05, 1.6358e-03, 1.9211e-04, 3.2539e-02, 3.3101e-04, 3.8309e-05,\n",
      "        8.9995e-05, 3.3113e-04, 2.0909e-04, 4.4553e-03, 9.9638e-05, 1.6020e-04,\n",
      "        1.4414e-04, 9.0349e-05, 9.6362e-05, 1.5558e-04], device='cuda:0')}, 4: {'step': 1125000, 'square_avg': tensor([[3.5269e-07, 3.5705e-07, 6.2803e-06,  ..., 3.8500e-06, 6.1223e-08,\n",
      "         1.9061e-06],\n",
      "        [6.4495e-05, 1.2637e-05, 7.6923e-05,  ..., 2.9243e-07, 1.6816e-05,\n",
      "         2.3902e-05],\n",
      "        [3.9898e-05, 4.2300e-06, 3.7028e-06,  ..., 6.1153e-06, 3.3884e-06,\n",
      "         1.7167e-06],\n",
      "        ...,\n",
      "        [2.2358e-05, 7.4556e-06, 1.2793e-06,  ..., 1.8081e-05, 5.6996e-07,\n",
      "         2.5179e-06],\n",
      "        [2.6619e-05, 5.0909e-06, 3.1207e-05,  ..., 1.3075e-07, 6.7843e-06,\n",
      "         9.6245e-06],\n",
      "        [9.3774e-06, 1.7726e-06, 1.0975e-05,  ..., 5.3646e-08, 2.3858e-06,\n",
      "         3.3968e-06]], device='cuda:0')}, 5: {'step': 1125000, 'square_avg': tensor([1.9836e-05, 1.6851e-03, 9.9287e-05, 5.3274e-04, 1.2921e-03, 2.4500e-05,\n",
      "        1.5244e-05, 1.0562e-04, 5.0135e-04, 1.5587e-04, 5.6292e-05, 2.7851e-05,\n",
      "        3.8255e-06, 7.3387e-05, 5.8010e-05, 7.8288e-05, 7.8409e-06, 9.7661e-05,\n",
      "        1.8585e-03, 6.6567e-04, 3.0392e-05, 1.1322e-04, 7.1576e-05, 4.0258e-03,\n",
      "        9.4767e-04, 1.0983e-05, 9.9446e-06, 5.5617e-06, 3.6124e-04, 7.5662e-06,\n",
      "        1.9544e-03, 1.5121e-03, 5.3429e-08, 2.6205e-05, 6.6763e-06, 3.8988e-03,\n",
      "        8.3926e-07, 9.1456e-06, 1.2484e-04, 3.7791e-03, 1.6357e-04, 6.0967e-05,\n",
      "        3.4894e-03, 1.8231e-05, 1.5562e-04, 5.5348e-04, 9.7546e-06, 9.6176e-05,\n",
      "        1.6209e-03, 1.3837e-03, 2.5848e-04, 1.7359e-03, 1.2364e-04, 8.0673e-05,\n",
      "        1.7598e-05, 3.4385e-05, 7.4544e-05, 4.7255e-04, 1.4273e-03, 2.8248e-05,\n",
      "        8.2303e-05, 2.6123e-05, 2.2042e-04, 7.3084e-04, 3.3292e-05, 1.4026e-05,\n",
      "        4.0119e-05, 6.4067e-04, 1.9343e-04, 6.0520e-04, 2.4398e-05, 4.5867e-05,\n",
      "        1.0500e-04, 3.4168e-04, 1.5772e-05, 4.1200e-04, 4.9686e-05, 2.5095e-03,\n",
      "        4.6037e-04, 5.8654e-06, 3.9922e-06, 3.5781e-04, 2.4023e-04, 6.4123e-04,\n",
      "        1.2597e-05, 1.7397e-04, 4.5316e-04, 5.4851e-05, 1.4767e-07, 3.3141e-04,\n",
      "        6.0527e-04, 1.7996e-03, 1.6883e-04, 2.9926e-06, 3.0093e-03, 2.7730e-06,\n",
      "        2.7935e-05, 4.8313e-04, 1.7200e-05, 5.8150e-04, 5.0995e-05, 7.5394e-04,\n",
      "        4.4728e-03, 1.6495e-04, 7.2319e-04, 4.0938e-04, 1.5026e-04, 1.3105e-04,\n",
      "        3.7014e-06, 1.0434e-03, 3.6220e-05, 5.0105e-05, 4.6511e-04, 5.9309e-05,\n",
      "        8.6341e-05, 1.8905e-06, 1.8794e-05, 1.5452e-03, 1.7725e-03, 1.8068e-05,\n",
      "        4.5688e-03, 7.6598e-06, 5.3680e-06, 4.2786e-06, 1.0116e-03, 8.0943e-05,\n",
      "        2.5334e-04, 4.5883e-04, 1.2882e-05, 2.9779e-05, 3.7458e-04, 1.5414e-06,\n",
      "        8.7888e-05, 1.5265e-05, 1.4326e-03, 9.4358e-04, 3.5651e-04, 3.5387e-04,\n",
      "        1.3183e-04, 5.5606e-04, 1.4342e-05, 1.5806e-05, 1.2929e-03, 2.2265e-05,\n",
      "        3.1941e-05, 3.6820e-05, 2.5362e-04, 1.3934e-05, 4.1401e-04, 5.0330e-08,\n",
      "        1.1245e-04, 1.1462e-04, 2.1897e-05, 8.4767e-05, 3.9691e-05, 6.0130e-04,\n",
      "        9.7897e-06, 8.0512e-05, 3.0156e-05, 7.7966e-06, 1.0769e-03, 5.3423e-05,\n",
      "        7.2141e-05, 1.2172e-05, 1.6677e-04, 7.8750e-04, 6.8771e-04, 2.7053e-04,\n",
      "        6.6963e-06, 4.1906e-05, 1.8349e-03, 1.2212e-03, 2.9635e-04, 8.9767e-05,\n",
      "        1.5058e-05, 1.4033e-03, 1.0712e-05, 2.4699e-06, 2.0602e-03, 2.0359e-05,\n",
      "        2.2371e-03, 2.0501e-04, 4.4616e-03, 1.2391e-04, 7.7270e-04, 6.1901e-06,\n",
      "        1.0145e-07, 4.3947e-04, 8.7435e-05, 1.2995e-05, 3.5494e-04, 8.2119e-04,\n",
      "        2.0005e-04, 1.9743e-04, 6.1251e-06, 1.2928e-05, 6.1124e-04, 3.9464e-06,\n",
      "        5.7514e-05, 1.3455e-08, 1.0174e-05, 5.8211e-05, 2.6073e-05, 6.2837e-06,\n",
      "        6.4006e-05, 1.9265e-05, 5.4010e-05, 1.2840e-05, 1.5159e-04, 4.8265e-06,\n",
      "        1.0274e-05, 9.7178e-04, 2.1037e-06, 8.2597e-04, 6.2317e-07, 1.1566e-05,\n",
      "        4.0516e-04, 7.7022e-06, 1.9539e-06, 3.3932e-04, 1.2674e-03, 9.3013e-04,\n",
      "        3.2150e-05, 2.0009e-04, 8.0398e-04, 6.6197e-06, 2.3113e-05, 2.6068e-05,\n",
      "        7.7141e-06, 5.8004e-06, 1.3569e-06, 6.7980e-06, 1.0940e-05, 2.2965e-04,\n",
      "        1.0877e-05, 6.5278e-04, 1.9750e-05, 7.1831e-05, 1.1703e-05, 5.3697e-03,\n",
      "        6.6863e-04, 3.1945e-04, 3.4237e-04, 2.6001e-04, 1.3462e-05, 3.4210e-04,\n",
      "        2.8477e-05, 1.1213e-08, 1.9210e-03, 6.4360e-06, 2.0336e-04, 7.1604e-05,\n",
      "        2.2579e-05, 3.1194e-05, 6.8322e-04, 2.3918e-04], device='cuda:0')}, 6: {'step': 1125000, 'square_avg': tensor([[4.8143e-06, 1.2285e+00, 2.2135e-05, 4.4072e-05, 8.8685e-01, 1.4822e-05,\n",
      "         2.5107e-07, 3.0112e-05, 5.7867e-02, 1.4863e-01, 4.8713e-06, 7.9541e-06,\n",
      "         1.5132e-06, 1.1053e-05, 2.0679e-05, 4.3423e-05, 4.2343e-05, 6.9409e-05,\n",
      "         1.5136e+00, 9.2822e-04, 9.7499e-07, 6.0957e-06, 1.8466e-05, 9.5685e-01,\n",
      "         7.4312e-01, 1.8815e-06, 2.0615e-06, 1.0239e-06, 2.0428e-01, 7.4212e-07,\n",
      "         2.3935e-03, 1.2437e-01, 1.1622e-08, 1.4346e-05, 2.6831e-07, 3.5267e-01,\n",
      "         3.3601e-08, 1.5514e-07, 1.7690e-05, 7.6340e-01, 2.1142e-04, 2.9364e-05,\n",
      "         7.1514e-01, 2.9937e-05, 2.1837e-01, 7.3946e-01, 5.8767e-06, 1.0923e-06,\n",
      "         8.9190e-01, 1.6861e-03, 9.7616e-05, 7.2341e-01, 5.2641e-06, 6.2973e-06,\n",
      "         8.9159e-07, 7.1950e-06, 2.5565e-05, 8.6722e-05, 5.0552e-01, 4.2973e-06,\n",
      "         2.0283e-05, 1.8143e-06, 1.6489e-05, 3.3754e-01, 4.0248e-05, 5.4175e-07,\n",
      "         1.2701e-05, 2.0403e-04, 4.2429e-05, 4.9609e-01, 2.2762e-05, 9.2954e-06,\n",
      "         4.3575e-06, 3.6551e-01, 8.4524e-06, 3.9458e-01, 1.8398e-04, 1.1937e+00,\n",
      "         3.5031e-01, 2.5848e-07, 2.9418e-07, 2.2049e-04, 1.8054e-01, 4.6220e-01,\n",
      "         1.7725e-05, 7.2600e-05, 1.6258e-03, 6.9576e-06, 1.4334e-09, 3.2238e-01,\n",
      "         3.6684e-01, 1.2428e+00, 1.7216e-01, 9.7980e-08, 1.4172e+00, 4.3596e-07,\n",
      "         3.3012e-06, 4.2095e-01, 5.4396e-06, 6.4180e-01, 2.8677e-05, 1.0048e+00,\n",
      "         1.0774e+00, 1.6127e-04, 6.1607e-01, 3.8181e-01, 6.8111e-06, 4.9450e-06,\n",
      "         1.2308e-06, 3.7297e-01, 3.4715e-05, 4.5119e-02, 4.5283e-01, 9.4514e-05,\n",
      "         2.6970e-05, 1.1805e-06, 3.1250e-06, 1.2529e+00, 1.1467e-03, 6.5564e-06,\n",
      "         1.0974e+00, 9.4958e-07, 6.2135e-07, 3.2475e-07, 2.5869e-02, 9.0368e-06,\n",
      "         1.1652e-04, 6.5439e-01, 8.5987e-06, 5.9175e-06, 1.6627e-04, 1.3246e-08,\n",
      "         6.6978e-06, 1.2348e-06, 1.0898e+00, 6.3080e-01, 2.0535e-01, 7.1614e-05,\n",
      "         1.7620e-05, 5.6539e-01, 1.4916e-06, 3.5843e-06, 1.2877e+00, 2.5682e-06,\n",
      "         3.4007e-06, 1.9992e-05, 1.3815e-04, 8.6624e-05, 4.6677e-01, 1.4582e-10,\n",
      "         2.1083e-05, 8.4071e-04, 8.4172e-07, 2.2488e-06, 1.1574e-04, 1.8336e-04,\n",
      "         2.5991e-07, 6.4967e-06, 3.4402e-05, 2.1078e-06, 9.9162e-01, 7.8852e-06,\n",
      "         6.5606e-05, 2.9587e-05, 1.2507e-05, 4.5448e-04, 4.3265e-01, 3.1089e-01,\n",
      "         5.8414e-05, 1.2570e-05, 8.2167e-01, 5.0157e-01, 1.1426e-04, 5.1359e-05,\n",
      "         9.7702e-06, 4.4624e-04, 2.3490e-06, 7.8123e-07, 1.2859e+00, 9.1878e-06,\n",
      "         9.2425e-01, 1.6360e-03, 1.0735e+00, 1.3840e-05, 2.7953e-04, 2.1450e-06,\n",
      "         7.4023e-08, 4.2796e-01, 5.8269e-05, 1.5836e-06, 2.4359e-04, 9.1732e-02,\n",
      "         2.0380e-01, 4.0857e-04, 4.3938e-03, 2.2384e-05, 1.3602e-02, 1.5747e-07,\n",
      "         1.6090e-05, 7.4722e-06, 1.5461e-05, 2.5487e-05, 5.3380e-05, 1.2560e-07,\n",
      "         3.9076e-06, 3.0351e-05, 5.0278e-06, 2.1659e-06, 1.2656e-01, 2.4352e-07,\n",
      "         3.3209e-05, 9.1969e-01, 9.6752e-09, 1.0520e-04, 1.2400e-06, 3.1350e-06,\n",
      "         2.8355e-05, 4.1409e-06, 3.0038e-08, 9.9457e-05, 8.5435e-01, 1.6456e-02,\n",
      "         7.5247e-06, 1.8668e-05, 5.5043e-01, 2.6230e-06, 3.8138e-05, 2.0607e-02,\n",
      "         1.5629e-06, 8.1653e-06, 2.1769e-08, 7.0338e-07, 3.2112e-06, 5.2429e-05,\n",
      "         2.6075e-06, 7.6613e-02, 2.0126e-06, 2.5083e-06, 2.1880e-06, 1.2766e+00,\n",
      "         5.3706e-01, 7.5462e-05, 2.2819e-02, 1.8303e-03, 3.0060e-07, 4.4676e-04,\n",
      "         5.7833e-06, 5.9589e-07, 9.3403e-01, 2.2486e-06, 1.8381e-01, 4.7123e-05,\n",
      "         2.3866e-04, 9.0022e-05, 4.5372e-01, 3.0112e-01]], device='cuda:0')}, 7: {'step': 1125000, 'square_avg': tensor([0.0515], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n",
      "pi_optimizer's state_dict:\n",
      "state \t {0: {'step': 1125000, 'square_avg': tensor([[7.3578e-07, 7.2644e-07, 8.6154e-07,  ..., 1.2837e-07, 5.2377e-07,\n",
      "         4.6282e-08],\n",
      "        [1.0604e-06, 1.3495e-06, 1.6987e-06,  ..., 2.1654e-07, 1.2367e-06,\n",
      "         8.9972e-08],\n",
      "        [3.8454e-07, 4.7209e-07, 5.1673e-07,  ..., 6.5803e-08, 3.6209e-07,\n",
      "         4.6634e-08],\n",
      "        ...,\n",
      "        [1.9259e-06, 4.0372e-06, 3.0977e-06,  ..., 3.2573e-07, 1.2289e-06,\n",
      "         1.0253e-07],\n",
      "        [2.2403e-06, 2.2826e-06, 2.9251e-06,  ..., 3.3908e-07, 1.4589e-06,\n",
      "         1.2638e-07],\n",
      "        [1.1608e-06, 1.6662e-06, 1.0963e-06,  ..., 2.5914e-07, 5.8853e-07,\n",
      "         6.2994e-08]], device='cuda:0')}, 1: {'step': 1125000, 'square_avg': tensor([2.0572e-06, 3.1083e-06, 1.4977e-06, 1.3158e-06, 2.9648e-06, 1.3517e-06,\n",
      "        2.8106e-06, 1.2147e-05, 3.3465e-06, 2.6108e-06, 3.2769e-06, 2.5241e-06,\n",
      "        7.3112e-06, 6.4878e-06, 1.1231e-05, 4.6098e-06, 2.9735e-06, 3.8233e-06,\n",
      "        2.6996e-06, 5.4737e-06, 7.7501e-06, 4.1299e-06, 3.2020e-06, 3.8917e-06,\n",
      "        3.9723e-06, 3.1172e-06, 4.4681e-06, 3.0544e-06, 3.4487e-06, 9.0348e-06,\n",
      "        8.1106e-06, 1.0266e-05, 1.9292e-06, 1.6103e-05, 3.7073e-06, 3.3221e-06,\n",
      "        7.5306e-06, 8.1310e-06, 8.6175e-06, 5.0508e-06, 5.4383e-06, 4.2306e-06,\n",
      "        4.9546e-06, 7.5720e-06, 1.9001e-06, 4.5600e-06, 3.5323e-06, 2.7974e-06,\n",
      "        6.2297e-06, 5.3449e-06, 7.5869e-06, 1.4245e-06, 5.8625e-06, 1.3569e-05,\n",
      "        2.0374e-06, 1.9743e-06, 1.5725e-06, 6.3465e-06, 7.7337e-05, 2.7732e-06,\n",
      "        3.7153e-06, 3.6832e-06, 1.5668e-02, 3.6181e-06, 1.0947e-05, 1.1223e-06,\n",
      "        5.8104e-06, 1.6921e-06, 1.1683e-04, 1.1164e-05, 1.1744e-05, 3.3052e-05,\n",
      "        1.1779e-05, 4.1630e-06, 1.6048e-05, 4.4036e-06, 1.7336e-06, 2.7376e-06,\n",
      "        8.2457e-06, 1.3748e-05, 1.5185e-05, 3.3163e-06, 1.1457e-05, 1.9929e-06,\n",
      "        3.2401e-06, 2.0211e-06, 1.6418e-05, 1.1279e-05, 6.4473e-06, 1.1289e-06,\n",
      "        9.3331e-06, 1.0326e-05, 6.7352e-05, 3.9892e-06, 6.0301e-06, 3.0784e-06,\n",
      "        6.7757e-06, 1.0557e-05, 9.5360e-04, 1.4726e-05, 3.8679e-06, 3.2452e-04,\n",
      "        6.1866e-06, 6.2688e-06, 5.9298e-06, 3.4860e-06, 1.1216e-06, 4.8336e-06,\n",
      "        4.5231e-06, 3.5537e-06, 8.8340e-06, 5.0165e-05, 5.6360e-06, 5.9412e-06,\n",
      "        5.2841e-06, 1.5140e-06, 3.6026e-06, 8.4207e-06, 1.2564e-06, 3.1047e-06,\n",
      "        1.0981e-05, 2.3607e-06, 2.1610e-05, 4.8988e-06, 4.0473e-06, 5.9358e-06,\n",
      "        7.9751e-06, 3.1873e-06, 1.5205e-06, 2.4144e-06, 7.8072e-06, 5.2525e-06,\n",
      "        8.5340e-06, 4.1239e-06, 3.2553e-04, 2.7273e-06, 1.6501e-05, 4.9084e-06,\n",
      "        4.5835e-06, 4.0420e-05, 6.1472e-06, 2.0337e-06, 2.7415e-06, 8.6542e-06,\n",
      "        5.5182e-06, 1.0297e-05, 7.0393e-06, 3.6229e-06, 5.3638e-06, 2.6928e-05,\n",
      "        2.5729e-06, 3.2892e-06, 6.1126e-06, 1.5978e-06, 6.0473e-06, 1.9889e-06,\n",
      "        3.2421e-06, 9.0979e-06, 3.9274e-06, 6.4682e-06, 3.0907e-06, 2.1274e-06,\n",
      "        3.0356e-06, 4.0494e-06, 3.3063e-06, 5.8175e-06, 2.1019e-06, 1.1173e-05,\n",
      "        1.0297e-05, 1.5795e-06, 2.0122e-05, 4.0246e-06, 1.4024e-05, 3.7566e-06,\n",
      "        2.9028e-06, 1.5599e-06, 8.6084e-06, 7.1681e-06, 1.4075e-06, 7.3076e-06,\n",
      "        2.4474e-06, 8.8292e-07, 2.8947e-06, 2.6618e-06, 9.2283e-07, 8.0898e-06,\n",
      "        1.6669e-06, 1.0457e-05, 8.9624e-05, 2.1908e-06, 9.1925e-06, 6.2655e-06,\n",
      "        1.0229e-05, 2.0325e-06, 3.6863e-06, 3.5157e-06, 4.7940e-06, 3.3347e-06,\n",
      "        7.8196e-06, 5.4072e-06, 2.7623e-06, 6.9088e-06, 5.7229e-06, 5.5566e-06,\n",
      "        1.9452e-06, 3.3093e-06, 1.3680e-06, 3.0878e-06, 2.1882e-06, 3.6039e-06,\n",
      "        2.2042e-06, 2.1446e-06, 6.3567e-06, 8.6588e-07, 2.0643e-06, 2.9525e-06,\n",
      "        3.0425e-06, 1.4582e-06, 2.4829e-06, 7.4235e-06, 8.2833e-06, 5.1752e-05,\n",
      "        2.2077e-06, 1.4732e-05, 1.1641e-05, 8.1055e-06, 5.1627e-06, 4.6644e-06,\n",
      "        1.1291e-06, 2.8233e-06, 5.4471e-05, 8.8593e-06, 2.9714e-05, 4.8052e-06,\n",
      "        6.7045e-06, 5.4293e-06, 1.8180e-05, 5.4081e-06, 7.2820e-06, 4.7166e-06,\n",
      "        1.1583e-06, 7.8450e-06, 4.0855e-06, 6.6248e-06, 1.7816e-06, 4.3335e-06,\n",
      "        3.3401e-06, 1.1674e-06, 1.6561e-05, 6.9545e-06, 4.4864e-05, 3.9467e-06,\n",
      "        5.1102e-06, 8.2511e-06, 6.2989e-06, 4.0713e-06], device='cuda:0')}, 2: {'step': 1125000, 'square_avg': tensor([[5.5196e-08, 1.5743e-08, 5.3607e-08,  ..., 7.5585e-08, 1.0956e-07,\n",
      "         6.0287e-08],\n",
      "        [6.7671e-08, 1.2485e-07, 2.0990e-07,  ..., 2.2232e-07, 2.6516e-07,\n",
      "         3.8049e-08],\n",
      "        [3.6575e-09, 5.5581e-08, 5.1065e-08,  ..., 7.1496e-08, 8.4205e-08,\n",
      "         5.6859e-08],\n",
      "        ...,\n",
      "        [7.1674e-08, 7.2328e-08, 6.3478e-08,  ..., 2.6930e-07, 2.1933e-07,\n",
      "         1.8741e-07],\n",
      "        [2.5575e-08, 7.1610e-09, 1.6374e-08,  ..., 4.1953e-08, 4.5501e-08,\n",
      "         9.2791e-08],\n",
      "        [1.3943e-07, 1.5045e-07, 1.3229e-07,  ..., 2.8899e-07, 1.4677e-07,\n",
      "         5.6851e-08]], device='cuda:0')}, 3: {'step': 1125000, 'square_avg': tensor([3.3630e-06, 1.5540e-06, 8.6392e-07, 7.4638e-06, 1.1590e-06, 2.8804e-06,\n",
      "        2.4693e-06, 8.6052e-06, 1.5700e-06, 5.5834e-07, 6.5266e-07, 5.8718e-06,\n",
      "        2.8638e-06, 3.9437e-06, 5.1481e-06, 2.5367e-06, 4.5763e-06, 1.7569e-06,\n",
      "        4.1148e-06, 6.8497e-07, 3.0509e-06, 1.4427e-06, 2.8434e-06, 1.3361e-06,\n",
      "        1.7366e-06, 1.6303e-06, 8.7132e-07, 7.9529e-06, 1.2703e-06, 1.5515e-06,\n",
      "        9.8219e-07, 3.3719e-06, 8.9075e-07, 3.1747e-06, 4.2132e-07, 1.7715e-06,\n",
      "        7.7533e-07, 6.0575e-06, 4.1006e-07, 4.8997e-07, 5.8777e-06, 1.4599e-06,\n",
      "        1.5645e-06, 2.6398e-06, 4.1573e-06, 1.8400e-06, 8.7889e-07, 9.8706e-07,\n",
      "        5.7952e-06, 4.9822e-07, 1.2402e-06, 1.1281e-06, 7.6250e-05, 1.4500e-06,\n",
      "        2.2160e-06, 7.2638e-07, 4.1630e-06, 2.0711e-06, 6.8657e-06, 3.4547e-05,\n",
      "        3.2051e-06, 3.5790e-07, 2.1271e-06, 5.4819e-06, 2.8851e-06, 2.5198e-06,\n",
      "        1.7278e-06, 2.0642e-06, 1.1685e-06, 1.5459e-06, 2.8049e-06, 3.1706e-06,\n",
      "        4.9758e-06, 1.5179e-06, 4.6104e-06, 3.9545e-06, 1.5440e-06, 5.3534e-07,\n",
      "        1.8452e-05, 5.0745e-06, 9.4491e-07, 2.7496e-06, 4.3915e-07, 7.5131e-06,\n",
      "        4.3574e-06, 1.8265e-06, 8.2838e-06, 3.8742e-06, 2.3398e-06, 1.1562e-06,\n",
      "        6.1382e-07, 9.6998e-07, 7.5843e-07, 6.5030e-07, 3.4855e-05, 1.1603e-05,\n",
      "        3.4443e-06, 2.9326e-06, 1.1105e-06, 2.5125e-06, 1.8988e-06, 6.5309e-07,\n",
      "        2.5220e-06, 1.3294e-05, 1.8159e-06, 2.7038e-06, 3.7914e-06, 2.5653e-06,\n",
      "        3.6748e-06, 1.0850e-06, 5.5781e-06, 7.8493e-06, 5.5374e-06, 2.6070e-06,\n",
      "        1.0578e-06, 5.4418e-06, 2.0828e-06, 1.7145e-06, 5.5026e-06, 3.1128e-06,\n",
      "        8.5330e-06, 6.5773e-06, 6.4385e-06, 4.9253e-06, 1.6085e-06, 6.6305e-07,\n",
      "        5.4536e-05, 6.8088e-07, 1.4370e-06, 3.0345e-06, 4.1557e-06, 2.7881e-06,\n",
      "        3.4504e-06, 2.4168e-06, 3.5520e-06, 4.3162e-06, 2.9472e-06, 1.6939e-06,\n",
      "        2.3169e-06, 2.5547e-06, 1.0952e-06, 1.3388e-06, 2.1200e-06, 9.2509e-06,\n",
      "        5.2895e-06, 9.1613e-06, 1.3269e-05, 1.4720e-06, 1.1156e-05, 3.8248e-06,\n",
      "        3.2856e-06, 1.9306e-06, 6.9901e-07, 3.9463e-06, 1.5371e-04, 5.1132e-06,\n",
      "        4.6571e-07, 4.0252e-06, 8.6062e-07, 8.9953e-06, 4.5916e-06, 5.7069e-06,\n",
      "        9.5569e-06, 8.8993e-06, 1.8359e-06, 2.5196e-06, 6.2517e-06, 6.2155e-07,\n",
      "        4.7475e-06, 2.5178e-06, 1.3316e-05, 1.2107e-06, 5.7008e-06, 8.9145e-06,\n",
      "        2.9278e-05, 1.1318e-05, 5.5370e-06, 6.4612e-07, 1.7088e-05, 4.1658e-06,\n",
      "        5.1850e-07, 4.5843e-06, 1.0358e-06, 1.9270e-06, 1.7276e-06, 7.0726e-06,\n",
      "        8.0489e-06, 3.8627e-05, 1.9310e-06, 1.7756e-06, 3.3438e-06, 7.1268e-05,\n",
      "        5.0352e-06, 9.1387e-07, 4.2947e-06, 2.6925e-06, 9.1490e-07, 1.5207e-06,\n",
      "        4.8550e-06, 1.3751e-06, 3.0852e-06, 7.8379e-07, 1.4615e-06, 2.2686e-06,\n",
      "        6.7792e-07, 8.1867e-07, 7.4321e-07, 2.5015e-06, 3.2987e-06, 1.0659e-05,\n",
      "        6.3851e-06, 6.7586e-06, 2.5376e-06, 2.9312e-06, 1.1449e-06, 3.6618e-06,\n",
      "        1.9304e-06, 3.1562e-06, 6.3180e-06, 2.2789e-04, 4.8086e-06, 2.3389e-06,\n",
      "        4.2524e-06, 2.1577e-06, 5.7771e-06, 9.3030e-06, 1.6461e-06, 2.1373e-06,\n",
      "        4.3931e-06, 5.0280e-06, 2.6554e-06, 1.9769e-06, 3.4872e-06, 4.9952e-06,\n",
      "        3.9134e-06, 3.9747e-06, 5.5838e-06, 2.3594e-05, 4.2229e-06, 3.5648e-07,\n",
      "        5.2344e-07, 7.3681e-07, 1.0007e-06, 3.6760e-06, 1.5574e-06, 6.3272e-05,\n",
      "        4.3652e-06, 3.6653e-06, 5.3881e-07, 9.8361e-06, 6.7596e-07, 6.0995e-07,\n",
      "        2.0857e-06, 2.3239e-06, 2.6763e-06, 1.0936e-06], device='cuda:0')}, 4: {'step': 1125000, 'square_avg': tensor([[7.8827e-08, 4.7035e-08, 2.2670e-08,  ..., 3.2141e-08, 3.7353e-08,\n",
      "         9.8306e-09],\n",
      "        [7.7775e-08, 1.8391e-07, 4.3450e-08,  ..., 3.3097e-08, 6.3002e-09,\n",
      "         3.3429e-08],\n",
      "        [2.7091e-08, 2.7757e-08, 2.6252e-08,  ..., 5.8167e-08, 2.4747e-08,\n",
      "         6.3396e-09],\n",
      "        ...,\n",
      "        [5.9771e-09, 6.7103e-09, 3.7582e-09,  ..., 2.1610e-08, 1.3579e-09,\n",
      "         1.0799e-09],\n",
      "        [3.8964e-08, 2.0307e-08, 3.5753e-08,  ..., 1.2564e-08, 3.3183e-08,\n",
      "         7.3033e-09],\n",
      "        [6.7221e-08, 3.4895e-08, 1.1300e-08,  ..., 1.2581e-08, 4.3626e-09,\n",
      "         1.2379e-08]], device='cuda:0')}, 5: {'step': 1125000, 'square_avg': tensor([1.9398e-06, 4.0628e-07, 3.9632e-06, 4.2821e-07, 6.3222e-07, 8.0269e-07,\n",
      "        8.5897e-07, 2.6786e-07, 1.0506e-07, 1.5788e-06, 6.2878e-07, 2.7294e-07,\n",
      "        1.0116e-06, 3.7979e-06, 1.2661e-06, 2.7670e-07, 7.0225e-08, 2.1298e-06,\n",
      "        5.2296e-07, 6.9930e-06, 5.0230e-07, 2.7729e-07, 5.1765e-07, 1.6496e-07,\n",
      "        1.5137e-05, 5.7114e-08, 4.8568e-08, 6.3275e-07, 6.9229e-07, 2.4283e-07,\n",
      "        8.2782e-06, 6.0582e-08, 5.8206e-06, 9.2843e-07, 2.5198e-07, 1.2217e-07,\n",
      "        5.7475e-07, 3.0248e-07, 1.0746e-07, 5.3757e-07, 8.3135e-07, 7.8843e-07,\n",
      "        1.9794e-07, 1.6697e-07, 1.1078e-06, 1.1280e-06, 4.7846e-07, 1.2783e-06,\n",
      "        1.6445e-07, 3.2512e-07, 3.2499e-07, 8.0130e-08, 5.7510e-08, 3.3315e-07,\n",
      "        5.1149e-07, 6.7258e-08, 2.0457e-05, 1.7517e-06, 7.0121e-06, 4.1397e-08,\n",
      "        1.2886e-06, 6.6421e-07, 4.3633e-07, 4.0966e-07, 6.0310e-08, 1.8700e-07,\n",
      "        4.1080e-08, 4.6042e-07, 1.4359e-07, 2.0958e-06, 4.3319e-07, 1.6323e-07,\n",
      "        1.4619e-07, 1.1809e-06, 6.5465e-08, 5.7935e-07, 3.0799e-07, 4.8766e-06,\n",
      "        4.9797e-08, 4.1261e-07, 9.9260e-08, 1.3318e-07, 5.0706e-07, 1.6552e-06,\n",
      "        3.2293e-05, 7.3284e-06, 8.4953e-08, 1.3439e-06, 1.9522e-06, 3.5088e-07,\n",
      "        2.0886e-07, 5.9838e-07, 9.1671e-06, 5.4666e-07, 2.2900e-07, 4.3929e-06,\n",
      "        1.1545e-06, 1.6471e-06, 2.4171e-05, 6.7688e-08, 1.6133e-07, 6.6699e-08,\n",
      "        1.1204e-05, 3.0623e-08, 6.4222e-07, 2.1611e-07, 1.6683e-07, 2.9767e-07,\n",
      "        1.5181e-07, 1.5681e-07, 9.0808e-07, 3.3765e-07, 1.0274e-07, 8.8292e-08,\n",
      "        1.6219e-07, 3.9441e-06, 2.3481e-07, 4.8455e-07, 2.2003e-07, 2.2690e-07,\n",
      "        7.5362e-07, 2.3459e-06, 5.1719e-08, 9.9657e-07, 6.5066e-07, 4.0750e-07,\n",
      "        7.2183e-07, 3.8021e-07, 2.6140e-07, 7.4481e-08, 7.5656e-08, 1.3000e-07,\n",
      "        4.2011e-06, 4.2891e-08, 7.7668e-08, 6.7562e-07, 3.0775e-07, 3.7897e-07,\n",
      "        3.0196e-07, 3.0419e-07, 3.3320e-07, 1.3620e-06, 2.7213e-06, 1.6127e-07,\n",
      "        5.5281e-07, 3.4746e-06, 2.8997e-07, 5.1831e-06, 8.1711e-08, 4.5344e-07,\n",
      "        8.6841e-08, 1.6577e-07, 4.9446e-08, 6.7570e-07, 1.7768e-08, 9.6991e-08,\n",
      "        3.6653e-07, 2.1952e-06, 7.0681e-06, 1.0374e-05, 4.0189e-06, 4.4118e-08,\n",
      "        5.7042e-07, 1.5385e-07, 2.5605e-06, 1.3091e-07, 1.3489e-07, 1.5459e-07,\n",
      "        2.7823e-07, 1.7224e-07, 1.1698e-05, 8.8810e-08, 4.8877e-07, 2.3758e-07,\n",
      "        2.1072e-06, 6.7211e-08, 4.9628e-07, 7.0065e-44, 3.7221e-06, 7.7425e-07,\n",
      "        2.5616e-08, 4.8243e-06, 1.8480e-07, 3.0996e-07, 2.7095e-06, 5.4564e-08,\n",
      "        1.2112e-06, 5.8322e-07, 4.2426e-07, 8.4226e-07, 1.9398e-07, 6.5618e-07,\n",
      "        5.8635e-08, 3.0319e-06, 1.8217e-07, 2.8328e-07, 2.9672e-07, 3.7283e-07,\n",
      "        2.0848e-06, 1.7333e-05, 1.7702e-07, 8.4004e-07, 4.1407e-06, 2.4737e-07,\n",
      "        2.5914e-07, 3.4864e-07, 1.3427e-06, 3.2267e-07, 4.3456e-08, 2.2325e-07,\n",
      "        1.9126e-07, 8.8918e-07, 6.2452e-07, 7.4813e-07, 4.4364e-06, 1.7853e-07,\n",
      "        2.4908e-08, 1.3588e-07, 3.6537e-07, 2.3951e-07, 4.7265e-07, 9.0084e-07,\n",
      "        2.1976e-07, 3.2189e-07, 3.0959e-07, 5.4013e-07, 3.1060e-07, 5.3829e-08,\n",
      "        2.1056e-07, 1.5046e-06, 4.0327e-07, 1.8698e-05, 9.1447e-06, 1.5108e-06,\n",
      "        7.3269e-07, 3.8154e-07, 1.8881e-07, 8.4616e-06, 2.2431e-07, 1.5731e-06,\n",
      "        5.2522e-07, 4.3791e-08, 1.0928e-07, 6.0942e-07, 8.3665e-06, 3.0731e-07,\n",
      "        3.5371e-06, 1.0817e-07, 5.2717e-07, 1.3732e-06, 1.1655e-05, 1.4958e-06,\n",
      "        2.9063e-07, 1.9121e-07, 2.0554e-07, 1.8076e-07], device='cuda:0')}, 6: {'step': 1125000, 'square_avg': tensor([[3.3212e-05, 2.9549e-06, 6.3972e-05,  ..., 4.4950e-06, 1.5235e-07,\n",
      "         5.1732e-06],\n",
      "        [5.6338e-06, 8.2496e-07, 1.2375e-05,  ..., 1.4249e-06, 1.1542e-07,\n",
      "         1.2011e-06],\n",
      "        [1.3198e-06, 2.0161e-07, 2.5314e-06,  ..., 3.1208e-07, 3.1944e-08,\n",
      "         2.2257e-07],\n",
      "        [1.5357e-07, 6.3329e-08, 1.9852e-07,  ..., 1.5960e-07, 3.0569e-08,\n",
      "         6.1146e-08],\n",
      "        [9.7972e-08, 5.7316e-08, 1.4177e-07,  ..., 6.8272e-08, 1.2704e-08,\n",
      "         4.2220e-08],\n",
      "        [9.0818e-08, 5.8194e-08, 9.5223e-08,  ..., 9.8381e-08, 2.2918e-08,\n",
      "         4.6888e-08]], device='cuda:0')}, 7: {'step': 1125000, 'square_avg': tensor([7.8508e-05, 1.6942e-05, 3.2568e-06, 2.4042e-07, 1.4939e-07, 1.0396e-07],\n",
      "       device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model_q = ac.q\n",
    "model_pi = ac.pi\n",
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"model_nn/model_nn_2022-02-19T08-58-32.608033376.pt\")\n",
    "model_q.load_state_dict(checkpoint['model of ac.q'])\n",
    "model_pi.load_state_dict(checkpoint['model of ac.pi'])\n",
    "q_optimizer.load_state_dict(checkpoint['q_optimizer_state_dict'])\n",
    "pi_optimizer.load_state_dict(checkpoint['pi_optimizer_state_dict'])\n",
    "\n",
    "\n",
    "model = ac.q\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "model = ac.pi\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"q_optimizer's state_dict:\")\n",
    "for var_name in q_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", q_optimizer.state_dict()[var_name])\n",
    "\n",
    "print(\"pi_optimizer's state_dict:\")\n",
    "for var_name in pi_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", pi_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'render'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30356/1508720019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m376\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvideo_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m376\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30356/1612261252.py\u001b[0m in \u001b[0;36mtest_agent\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_test_episodes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ep_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ep_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'robot0_proprio-state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object-state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cosmic_rays_X/X_Robot/robosuite/robosuite/environments/base.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mRenders\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscreen\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_pixel_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'render'"
     ]
    }
   ],
   "source": [
    "test_agent(376)\n",
    "video_agent(376)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a48a149bc7a8dee0435672efcae6f64e48d62311a35302b209b3ac517d7f9c6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
