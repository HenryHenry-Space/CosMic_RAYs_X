{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import gym\n",
    "from PIL import Image\n",
    "# from pyvirtualdisplay import Display\n",
    "# Display().start()\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim import RMSprop\n",
    "import gym\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# # sys.path.append('set PATH=C:/Users/c3296143/.mujoco/mujoco200/bin;%PATH%')\n",
    "# # sys.path.append('set PATH=C://Users//c3296143//.mujoco//mujoco200//bin;%PATH%')\n",
    "# # sys.path.append('C:/Users/c3296143/.mujoco/mujoco200/bin')\n",
    "# # sys.path.append('C://Users//c3296143//.mujoco//mujoco200//bin')\n",
    "# # os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + 'C:/Users/c3296143/root/.mujoco/mujoco200/bin'\n",
    "# # old = os.environ.get(\"LD_LIBRARY_PATH\")\n",
    "# old = os.environ.get(\"PATH\")\n",
    "# # os.environ[\"PATH\"] = 'C:\\> set PATH=%PATH%;C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# # os.environ[\"PATH\"] = 'set PATH=C:/Users/c3296143/.mujoco/mujoco200/bin;%PATH%'\n",
    "\n",
    "# if old:\n",
    "#     os.environ[\"PATH\"] = old + \";\" +'C:\\\\Users\\\\c3296143\\\\.mujoco\\\\mujoco200\\\\bin'\n",
    "# #     os.environ[\"LD_LIBRARY_PATH\"] = old + \":\" + 'C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# # else:\n",
    "# #     os.environ[\"LD_LIBRARY_PATH\"] = 'C:/Users/c3296143/.mujoco/mujoco200/bin'\n",
    "# else:\n",
    "#     os.environ[\"PATH\"] = 'C:\\\\Users\\\\c3296143\\\\.mujoco\\\\mujoco200\\\\bin'\n",
    "\n",
    "# print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.controllers import load_controller_config\n",
    "from robosuite.controllers.controller_factory import reset_controllers\n",
    "from robosuite.utils import observables\n",
    "from robosuite.utils.input_utils import *\n",
    "from robosuite.robots import Bimanual\n",
    "import imageio\n",
    "import numpy as np\n",
    "import robosuite.utils.macros as macros\n",
    "macros.IMAGE_CONVENTION = \"opencv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/xhnfirst/DDPG-robosuite/e/DDPGROB-317\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "nep_log = neptune.init(\n",
    "    project=\"xhnfirst/DDPG-robosuite\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NTg5MDI2OS01MTVmLTQ2YjUtODA1Yy02ZWQyNDgxZDcwN2UifQ==\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'env_name': 'EElab_test7',\n",
    "    \"robots\": \"UR5e\"\n",
    "}\n",
    "controller_name = \"JOINT_VELOCITY\"\n",
    "options[\"controller_configs\"] = suite.load_controller_config(default_controller=controller_name)\n",
    "\n",
    "env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=False,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types=None,\n",
    "    renderer = 'mujoco',\n",
    "\n",
    ")\n",
    "\n",
    "test_env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=False,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types=None,\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "\n",
    "video_env = suite.make(\n",
    "    **options,\n",
    "    gripper_types=None,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=True,\n",
    "    use_object_obs=True, \n",
    "    camera_names='Labviewer',\n",
    "    camera_heights=512,\n",
    "    camera_widths=512,\n",
    "    # control_freq=200,\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "frame = []\n",
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class MLPActor(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation, act_limit):\n",
    "        super().__init__()\n",
    "        pi_sizes = [obs_dim] + list(hidden_sizes) + [act_dim]\n",
    "        self.pi = mlp(pi_sizes, activation, nn.Tanh)\n",
    "        self.act_limit = act_limit\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Return output from network scaled to action space limits.\n",
    "        return self.act_limit * self.pi(obs)\n",
    "\n",
    "class MLPQFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        q = self.q(torch.cat([obs, act], dim=-1))\n",
    "        return torch.squeeze(q, -1) # Critical to ensure q has right shape.\n",
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_sizes=(256,256),\n",
    "                 activation=nn.ReLU, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        obs_dim = 35\n",
    "        act_dim = 6\n",
    "        act_limit = 1\n",
    "\n",
    "        # build policy and value functions\n",
    "        self.pi = MLPActor(obs_dim, act_dim, hidden_sizes, activation, act_limit).to(device)\n",
    "        self.q = MLPQFunction(obs_dim, act_dim, hidden_sizes, activation).to(device)\n",
    "\n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            return self.pi(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('obs', 'act', 'rew', 'next_obs', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"hid\": 256,\n",
    "    \"l\": 3,\n",
    "    \"seed\": 0,\n",
    "    \"steps_per_epoch\": 3000,\n",
    "    \"steps_video\": 30000,\n",
    "    \"epochs\": 1000,\n",
    "    \"replay_size\": int(1e8),\n",
    "    \"gamma\": 0.98,\n",
    "    \"polyak\": 0.995,\n",
    "    \"pi_lr\": 1e-4,\n",
    "    \"q_lr\": 1e-4,\n",
    "    \"batch_size\": 1000,\n",
    "    \"start_steps\": 10000, \n",
    "    \"update_after\": 5000,\n",
    "    \"update_every\": 100,\n",
    "    \"act_noise\": 0.01,\n",
    "    \"num_test_episodes\": 5,\n",
    "    \"max_ep_len\": 400,\n",
    "    \"max_video_len\": 400,\n",
    "    \"save_model_len\": 10000,\n",
    "    # \"obs_dim\": 47,\n",
    "    # \"act_dim\": 7,\n",
    "    # \"act_limit\": 1\n",
    "}\n",
    "\n",
    "ac_kwargs=dict(hidden_sizes=[params[\"hid\"]]*params[\"l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim =  35\n",
      "act_dim =  6\n",
      "act_limit =  1\n"
     ]
    }
   ],
   "source": [
    "nep_log[\"parameters\"] = params\n",
    "\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "np.random.seed(params[\"seed\"])\n",
    "\n",
    "obs_dim = 35\n",
    "print('obs_dim = ', obs_dim)\n",
    "act_dim = 6\n",
    "print('act_dim = ', act_dim)\n",
    "# Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "act_limit = 1\n",
    "print('act_limit = ', act_limit)\n",
    "# Create actor-critic module and target networks\n",
    "ac = MLPActorCritic(**ac_kwargs)\n",
    "ac_targ = deepcopy(ac)\n",
    "\n",
    "# Freeze target networks with respect to optimizers (only update via polyak averaging)\n",
    "for p in ac_targ.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "memory = ReplayMemory(params[\"replay_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function for computing DDPG Q-loss\n",
    "def compute_loss_q(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "    a = torch.cat(data.act).float()\n",
    "    r = torch.cat(data.rew).float()\n",
    "    o2 =torch.cat(data.next_obs).float()\n",
    "    d = torch.cat(data.done).float()\n",
    "\n",
    "    q = ac.q(o,a)\n",
    "\n",
    "\n",
    "    # Bellman backup for Q function\n",
    "    with torch.no_grad():\n",
    "        q_pi_targ = ac_targ.q(o2, ac_targ.pi(o2))\n",
    "        backup = r + params[\"gamma\"] * (1 - d) * q_pi_targ\n",
    "\n",
    "    # MSE loss against Bellman backup\n",
    "    loss_q = ((q - backup)**2).mean()\n",
    "\n",
    "    return loss_q\n",
    "\n",
    "# Set up function for computing DDPG pi loss\n",
    "def compute_loss_pi(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "\n",
    "    q_pi = ac.q(o, ac.pi(o))\n",
    "\n",
    "    return -q_pi.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "def update(data):\n",
    "    # First run one gradient descent step for Q.\n",
    "\n",
    "\n",
    "    q_optimizer.zero_grad()\n",
    "    loss_q = compute_loss_q(data)\n",
    "\n",
    "    loss_q.backward()\n",
    "\n",
    "    q_optimizer.step()\n",
    "\n",
    "\n",
    "    # Freeze Q-network so you don't waste computational effort \n",
    "    # computing gradients for it during the policy learning step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Next run one gradient descent step for pi.\n",
    "    pi_optimizer.zero_grad()\n",
    "    loss_pi = compute_loss_pi(data)\n",
    "    loss_pi.backward()\n",
    "    pi_optimizer.step()\n",
    "\n",
    "    # Unfreeze Q-network so you can optimize it at next DDPG step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "    # Finally, update target networks by polyak averaging.\n",
    "    with torch.no_grad():\n",
    "        for p, p_targ in zip(ac.parameters(), ac_targ.parameters()):\n",
    "            # NB: We use an in-place operations \"mul_\", \"add_\" to update target\n",
    "            # params, as opposed to \"mul\" and \"add\", which would make new tensors.\n",
    "            p_targ.data.mul_(params[\"polyak\"])\n",
    "            p_targ.data.add_((1 - params[\"polyak\"]) * p.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_action(o, noise_scale):\n",
    "    a = ac.act(torch.as_tensor(o, dtype=torch.float32))\n",
    "    a += noise_scale * torch.randn(act_dim).to(device)\n",
    "    return torch.clip(a, -act_limit, act_limit)\n",
    "\n",
    "def test_agent(epoch):\n",
    "    test_main = 0\n",
    "    test_step = 0\n",
    "    for j in range(params[\"num_test_episodes\"]):\n",
    "        obs, d, test_ep_ret, test_ep_len = test_env.reset(), False, 0, 0\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        while not(d or (test_ep_len == params[\"max_ep_len\"])):\n",
    "            a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "            obs, r, d, _ = test_env.step(a_cpu[0])\n",
    "            o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "            o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "            test_ep_ret += r\n",
    "            test_ep_len += 1\n",
    "        test_ep_main = test_ep_ret/test_ep_len\n",
    "        test_step +=1\n",
    "        test_main += test_ep_main\n",
    "    print('test_rew_main = ', float(test_main/test_step))\n",
    "    nep_log[\"test/reward\"].log(test_main/test_step)\n",
    "    \n",
    "# def video_agent(epoch):\n",
    "#     obs, d, test_ep_len = video_env.reset(), False, 0\n",
    "#     o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "#     o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "#     now = datetime.now()\n",
    "#     current_time = str(now.isoformat())\n",
    "#     writer = imageio.get_writer(\n",
    "#         \"/home/xhnfly/Cosmic_rays_X/X_Robot/robosuite/robosuite/demos/video/DDPG_re_touch_2_15_300/DDPG_UR5_%s_ep_%d.mp4\" % (current_time, epoch), fps=100)\n",
    "#     frame = obs[\"Labviewer_image\"]\n",
    "#     writer.append_data(frame)\n",
    "\n",
    "#     while not(d or (test_ep_len == params[\"max_video_len\"])):\n",
    "#         a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "#         obs, _, d, _ = video_env.step(a_cpu[0])\n",
    "#         o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "#         o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "#         frame = obs[\"Labviewer_image\"]\n",
    "#         writer.append_data(frame)\n",
    "#         test_ep_len += 1\n",
    "#     writer.close()\n",
    "#     nep_log['video'] = neptune.types.File('/home/xhnfly/Cosmic_rays_X/X_Robot/robosuite/robosuite/demos/video/DDPG_re_touch_2_15_300/DDPG_UR5_%s_ep_%d.mp4' % (current_time, epoch))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = {\n",
    "#     'robot0_joint_pos_cos': None,\n",
    "#     'robot0_joint_pos_sin': None,\n",
    "#     'robot0_joint_vel': None,\n",
    "#     'robot0_eef_pos': None,\n",
    "#     'robot0_eef_quat': None,\n",
    "#     'robot0_gripper_qpos': None,\n",
    "#     'robot0_gripper_qvel': None,\n",
    "#     'cubeA_pos': None,\n",
    "#     'cubeA_quat': None,\n",
    "#     'cubeB_pos': None,\n",
    "#     'cubeB_quat': None,\n",
    "#     'gripper_to_cubeA': None,\n",
    "#     'gripper_to_cubeB': None,\n",
    "#     'cubeA_to_cubeB': None,\n",
    "# }\n",
    "\n",
    "obs, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "\n",
    "# env.viewer.set_camera(camera_id=0)\n",
    "\n",
    "\n",
    "# Define neutral value\n",
    "neutral = np.zeros(7)\n",
    "\n",
    "# Keep track of done variable to know when to break loop\n",
    "\n",
    "# Prepare for interaction with environment\n",
    "total_steps = params[\"steps_per_epoch\"] * params[\"epochs\"]\n",
    "start_time = time.time()\n",
    "\n",
    "o = torch.tensor([o], device=device)\n",
    "\n",
    "\n",
    "start_time_rec = datetime.now()\n",
    "r_true = 0\n",
    "total_main = 0\n",
    "ep_rew_main = 0\n",
    "reward_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000000 [00:00<?, ?it/s]/tmp/ipykernel_19395/3014330126.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  a = torch.tensor([np.random.uniform(low, high)], dtype=torch.float32, device=device)\n",
      "  0%|          | 2995/3000000 [00:42<12:57:24, 64.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00149902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3011/3000000 [01:00<366:52:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  6.062539512042274e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5991/3000000 [02:23<11:44:23, 70.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00782962]\n",
      "test_rew_main =  -0.4014979049788976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8989/3000000 [04:47<11:51:48, 70.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00781175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9000/3000000 [05:02<319:22:22,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  -0.46641806685172105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11997/3000000 [07:20<12:04:01, 68.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.05748241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12000/3000000 [07:37<575:21:37,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  6.910326037468105e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14998/3000000 [09:54<13:33:13, 61.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00190134]\n",
      "test_rew_main =  -0.025662126172124385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17995/3000000 [12:19<13:04:24, 63.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.06136732]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18000/3000000 [12:36<534:58:11,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  -0.07252561546523188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20995/3000000 [14:49<10:56:12, 75.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.01988536]\n",
      "test_rew_main =  0.0006079356460147812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23998/3000000 [21:20<26:57:34, 30.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00154555]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24000/3000000 [22:10<3685:37:22,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  -0.007886163515349206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26997/3000000 [29:13<32:57:26, 25.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.02654098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27000/3000000 [29:53<2719:28:39,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  0.0033493216191698297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29999/3000000 [31:36<9:10:30, 89.92it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00987738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30000/3000000 [31:49<321:28:42,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  -0.02132250273282767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30289/3000000 [31:58<11:04:08, 74.53it/s] Experiencing connection interruptions. Will try to reestablish communication with Neptune. Internal exception was: RequestsFutureAdapterConnectionError\n",
      "  1%|          | 32995/3000000 [33:33<11:50:00, 69.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.00398365]\n",
      "test_rew_main =  0.006376238933899952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33998/3000000 [34:20<11:33:03, 71.33it/s] Communication with Neptune restored!\n",
      "  1%|          | 35989/3000000 [35:37<12:39:48, 65.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.00777329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 36000/3000000 [35:51<297:31:49,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  -0.006486002676456265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 38999/3000000 [37:54<10:15:22, 80.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.0115581]\n",
      "test_rew_main =  -0.022298308119217826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 41993/3000000 [39:45<10:08:00, 81.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.02076839]\n",
      "test_rew_main =  0.01674474324498725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 44998/3000000 [41:31<10:41:43, 76.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.02733349]\n",
      "test_rew_main =  0.01665698721714745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 47993/3000000 [43:16<10:43:43, 76.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.0177067]\n",
      "test_rew_main =  0.015493461484430957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50991/3000000 [44:49<11:59:03, 68.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [-0.01789364]\n",
      "test_rew_main =  0.006711957873374662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 53992/3000000 [46:37<14:23:09, 56.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.01680809]\n",
      "test_rew_main =  0.025118988275667314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 56988/3000000 [48:05<11:26:18, 71.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.02050557]\n",
      "test_rew_main =  -0.011542111095612246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 59998/3000000 [49:50<10:02:27, 81.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.02825565]\n",
      "test_rew_main =  0.004969707633432673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 62993/3000000 [51:45<11:26:54, 71.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.0265515]\n",
      "test_rew_main =  0.037138968988265034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 65996/3000000 [53:54<9:47:08, 83.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.02163435]\n",
      "test_rew_main =  -0.03325140698469312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 68988/3000000 [55:45<10:20:20, 78.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.02026672]\n",
      "test_rew_main =  0.013932830644572403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 71983/3000000 [57:25<10:40:01, 76.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.00446512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 72000/3000000 [57:33<128:30:17,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  0.02602742288685626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 74998/3000000 [58:55<13:30:08, 60.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.04746314]\n",
      "test_rew_main =  0.07947234897356541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 77985/3000000 [1:00:20<10:23:35, 78.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.05204229]\n",
      "test_rew_main =  0.0825941032747705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 80984/3000000 [1:01:48<10:12:21, 79.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.05719421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 81000/3000000 [1:01:56<125:39:45,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  0.11703970372534715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 83986/3000000 [1:03:23<10:19:08, 78.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.087241]\n",
      "test_rew_main =  -0.02289598649718868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 86993/3000000 [1:04:47<10:50:09, 74.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.10573151]\n",
      "test_rew_main =  0.287108579277163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 89987/3000000 [1:06:17<10:04:15, 80.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.16951658]\n",
      "test_rew_main =  0.17870457505088386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 92996/3000000 [1:07:48<14:06:32, 57.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.17989478]\n",
      "test_rew_main =  0.14341347222610826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 95995/3000000 [1:09:13<9:21:43, 86.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.15017161]\n",
      "test_rew_main =  0.19446716497329491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 98987/3000000 [1:10:43<10:25:38, 77.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.1066742]\n",
      "test_rew_main =  0.18379156856241902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101986/3000000 [1:12:07<11:09:45, 72.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.19207588]\n",
      "test_rew_main =  0.15010327583061533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 104998/3000000 [1:13:42<8:28:05, 94.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.11373873]\n",
      "test_rew_main =  0.2081835884314973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 107989/3000000 [1:15:06<9:40:23, 83.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.20017278]\n",
      "test_rew_main =  0.16338688335914958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 110981/3000000 [1:16:40<10:59:51, 72.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.16870387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 111000/3000000 [1:16:48<110:10:21,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rew_main =  0.08126946683483105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 113987/3000000 [1:18:05<11:26:58, 70.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.12551837]\n",
      "test_rew_main =  0.31020141992563827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 116996/3000000 [1:19:41<9:30:54, 84.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.16553403]\n",
      "test_rew_main =  0.17627734939199485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 119994/3000000 [1:21:12<10:36:18, 75.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rew_main =  [0.14975141]\n",
      "test_rew_main =  0.24267858875147233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 121477/3000000 [1:22:22<32:32:07, 24.58it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19395/3014330126.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Store experience to replay buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mnep_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train/o\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mnep_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train/a\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mnep_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train/r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/neptune/new/handler.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, value, step, timestamp, wait, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/neptune/new/attributes/series/series.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, value, step, timestamp, wait, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_to_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_to_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/neptune/new/attributes/series/string_series.py\u001b[0m in \u001b[0;36m_data_to_value\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStringSeriesVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_value_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/neptune/new/types/series/string_series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`values` is not a collection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ValueVisitor[Ret]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/neptune/new/types/series/string_series.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`values` is not a collection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ValueVisitor[Ret]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cosmic_rays_x_py38_env/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;31m# Check if scientific representation should be used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_max\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnonzero_finite_min\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0mnonzero_finite_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.e8\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0mnonzero_finite_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.e-4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 474624 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    }
   ],
   "source": [
    "# Main loop: collect experience in env and update/log each epoch\n",
    "low, high = env.action_spec\n",
    "\n",
    "for t in tqdm(range(total_steps)):\n",
    "    \n",
    "    # Until start_steps have elapsed, randomly sample actions\n",
    "    # from a uniform distribution for better exploration. Afterwards, \n",
    "    # use the learned policy (with some noise, via act_noise). \n",
    "    if t > params[\"start_steps\"]:\n",
    "        a = get_action(o, params[\"act_noise\"])      # Tensor\n",
    "    else:\n",
    "        a = torch.tensor([np.random.uniform(low, high)], dtype=torch.float32, device=device)\n",
    "        \n",
    "    a_cpu = a.cpu().data.numpy()\n",
    "    # Step the env\n",
    "    obs2, r, d, _ = env.step(a_cpu[0])\n",
    "    \n",
    "    o2 = list(obs2['robot0_proprio-state']) + list(obs2['object-state'])\n",
    "    # print('len(o2) = ', len(o2))\n",
    "    dist = np.linalg.norm(list(obs2['gripper_to_cubeA']))\n",
    "    # print('dist = ', dist)\n",
    "    velo = np.linalg.norm(list(obs2['robot0_joint_vel']))\n",
    "    # print('velo = ', velo)\n",
    "    # if dist<=0.08:\n",
    "    #     if velo<=0.01:\n",
    "    #         r += 0.25\n",
    "    #     r += 0.05\n",
    "    ep_len += 1\n",
    "    total_main += r\n",
    "\n",
    "\n",
    "    # Ignore the \"done\" signal if it comes from hitting the time\n",
    "    # horizon (that is, when it's an artificial terminal signal\n",
    "    # that isn't based on the agent's state)\n",
    "    d = False if ep_len==params[\"max_ep_len\"] else d\n",
    "\n",
    "    o2 = torch.tensor([o2], dtype=torch.float32, device=device)\n",
    "    r = torch.tensor([r], dtype=torch.float32, device=device)\n",
    "    d = torch.tensor([d], dtype=torch.float32, device=device)\n",
    "\n",
    "    # Store experience to replay buffer\n",
    "    memory.push(o, a, r, o2, d)\n",
    "    nep_log[\"train/o\"].log(o)\n",
    "    nep_log[\"train/a\"].log(a)\n",
    "    nep_log[\"train/r\"].log(r)\n",
    "    nep_log[\"train/o2\"].log(o2)\n",
    "    nep_log[\"train/d\"].log(d)\n",
    "\n",
    "    # Super critical, easy to overlook step: make sure to update \n",
    "    # most recent observation!\n",
    "    o=o2\n",
    "    ep_ret += r\n",
    "    \n",
    "    \n",
    "    # End of trajectory handling\n",
    "    if d or (ep_len == params[\"max_ep_len\"]):\n",
    "        ep_rew = ep_ret/ep_len\n",
    "        ep_rew_main += ep_rew\n",
    "        obs, ep_ret, ep_len = env.reset(), 0, 0\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], device=device)\n",
    "\n",
    "\n",
    "    # Update handling\n",
    "    if t >= params[\"update_after\"] and t % params[\"update_every\"] == 0:\n",
    "        for i in range(params[\"update_every\"]):\n",
    "\n",
    "            transitions = memory.sample(params[\"batch_size\"])\n",
    "            # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "            # detailed explanation). This converts batch-array of Transitions\n",
    "            # to Transition of batch-arrays.\n",
    "            batch = Transition(*zip(*transitions))\n",
    "            update(data=batch)\n",
    "\n",
    "    # End of epoch handling\n",
    "    if (t+1) % params[\"steps_per_epoch\"] == 0:\n",
    "        epoch = (t+1) // params[\"steps_per_epoch\"]\n",
    "        train_reward = ep_rew_main/(params[\"steps_per_epoch\"]/params[\"max_ep_len\"])\n",
    "        nep_log[\"train/reward\"].log(train_reward)\n",
    "        print('train_rew_main = ', train_reward.cpu().data.numpy())\n",
    "        ep_rew_main = 0\n",
    "        # Test the performance of the deterministic version of the agent.\n",
    "        test_agent(epoch)\n",
    "        \n",
    "\n",
    "    # if (t+1) % params[\"steps_video\"] == 0:\n",
    "    #     epoch = (t+1) // params[\"steps_per_epoch\"]\n",
    "    #     now = datetime.now()\n",
    "    #     current_time = str(now.isoformat())\n",
    "    #     print('current_time = ', current_time)\n",
    "    #     video_agent(epoch)\n",
    "    #     now = datetime.now()\n",
    "    #     current_time = str(now.isoformat())\n",
    "    #     print('current_time = ', current_time)\n",
    "\n",
    "    if (t+1) % params[\"save_model_len\"] == 0:\n",
    "        epoch = (t+1) // params[\"steps_per_epoch\"]\n",
    "        now = datetime.now()\n",
    "        current_time = str(now.isoformat())\n",
    "        torch.save({\n",
    "                    'model of ac.q': ac.q.state_dict(),\n",
    "                    'model of ac.pi': ac.pi.state_dict(),\n",
    "                    'q_optimizer_state_dict': q_optimizer.state_dict(),\n",
    "                    'pi_optimizer_state_dict': pi_optimizer.state_dict(),\n",
    "\n",
    "                    }, \"model_nn/model_nn_%s%d.pt\" % (current_time.replace(\":\",\"-\"), epoch))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ac.q\n",
    "print(\"Model_q's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "model = ac.pi\n",
    "print(\"Model_pi's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pi_optimizer's state_dict:\")\n",
    "for var_name in pi_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", pi_optimizer.state_dict()[var_name])\n",
    "\n",
    "print(\"q_optimizer's state_dict:\")\n",
    "for var_name in q_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", q_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = str(now.isoformat())\n",
    "\n",
    "\n",
    "\n",
    "torch.save({\n",
    "            'model of ac.q': ac.q.state_dict(),\n",
    "            'model of ac.pi': ac.pi.state_dict(),\n",
    "            'q_optimizer_state_dict': q_optimizer.state_dict(),\n",
    "            'pi_optimizer_state_dict': pi_optimizer.state_dict(),\n",
    "\n",
    "            }, \"model_nn/model_nn_%s%d.pt\" % (current_time.replace(\":\",\"-\"), epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nep_log.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a48a149bc7a8dee0435672efcae6f64e48d62311a35302b209b3ac517d7f9c6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
