{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "import gym\n",
    "from PIL import Image\n",
    "# from pyvirtualdisplay import Display\n",
    "# Display().start()\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim import RMSprop\n",
    "import gym\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.controllers import load_controller_config\n",
    "from robosuite.controllers.controller_factory import reset_controllers\n",
    "from robosuite.utils import observables\n",
    "from robosuite.utils.input_utils import *\n",
    "from robosuite.robots import Bimanual\n",
    "import imageio\n",
    "import numpy as np\n",
    "import robosuite.utils.macros as macros\n",
    "macros.IMAGE_CONVENTION = \"opencv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'env_name': 'EElab_test_gri_2',\n",
    "    \"robots\": \"UR5e\"\n",
    "}\n",
    "controller_name = \"JOINT_VELOCITY\"\n",
    "options[\"controller_configs\"] = suite.load_controller_config(default_controller=controller_name)\n",
    "\n",
    "env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types='Robotiq140Gripper',\n",
    "    renderer = 'mujoco',\n",
    "\n",
    ")\n",
    "\n",
    "test_env = suite.make(\n",
    "    **options,\n",
    "    has_renderer=True,\n",
    "    has_offscreen_renderer=False,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=False,\n",
    "    gripper_types='Robotiq140Gripper',\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "\n",
    "video_env = suite.make(\n",
    "    **options,\n",
    "    gripper_types='Robotiq140Gripper',\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=True,\n",
    "    use_object_obs=True, \n",
    "    camera_names='Labviewer',\n",
    "    camera_heights=512,\n",
    "    camera_widths=512,\n",
    "    # control_freq=200,\n",
    "    renderer = 'mujoco',\n",
    ")\n",
    "\n",
    "frame = []\n",
    "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class MLPActor(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation, act_limit):\n",
    "        super().__init__()\n",
    "        pi_sizes = [obs_dim] + list(hidden_sizes) + [act_dim]\n",
    "        self.pi = mlp(pi_sizes, activation, nn.Tanh)\n",
    "        self.act_limit = act_limit\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Return output from network scaled to action space limits.\n",
    "        return self.act_limit * self.pi(obs)\n",
    "\n",
    "class MLPQFunction(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        q = self.q(torch.cat([obs, act], dim=-1))\n",
    "        return torch.squeeze(q, -1) # Critical to ensure q has right shape.\n",
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_sizes=(256,256),\n",
    "                 activation=nn.ReLU, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        obs_dim = 47\n",
    "        act_dim = 7\n",
    "        act_limit = 1\n",
    "\n",
    "        # build policy and value functions\n",
    "        self.pi = MLPActor(obs_dim, act_dim, hidden_sizes, activation, act_limit).to(device)\n",
    "        self.q = MLPQFunction(obs_dim, act_dim, hidden_sizes, activation).to(device)\n",
    "\n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            return self.pi(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('obs', 'act', 'rew', 'next_obs', 'done'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"hid\": 256,\n",
    "    \"l\": 3,\n",
    "    \"seed\": 0,\n",
    "    \"steps_per_epoch\": 3000,\n",
    "    \"steps_video\": 30000,\n",
    "    \"epochs\": 1000,\n",
    "    \"replay_size\": int(1e8),\n",
    "    \"gamma\": 0.99,\n",
    "    \"polyak\": 0.995,\n",
    "    \"pi_lr\": 1e-4,\n",
    "    \"q_lr\": 1e-4,\n",
    "    \"batch_size\": 1000,\n",
    "    \"start_steps\": 10000, \n",
    "    \"update_after\": 5000,\n",
    "    \"update_every\": 100,\n",
    "    \"act_noise\": 0.01,\n",
    "    \"num_test_episodes\": 5,\n",
    "    \"max_ep_len\": 1000,\n",
    "    \"max_video_len\": 300,\n",
    "    \"save_model_len\": 300,\n",
    "    # \"obs_dim\": 47,\n",
    "    # \"act_dim\": 7,\n",
    "    # \"act_limit\": 1\n",
    "}\n",
    "\n",
    "ac_kwargs=dict(hidden_sizes=[params[\"hid\"]]*params[\"l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim =  47\n",
      "act_dim =  7\n",
      "act_limit =  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "np.random.seed(params[\"seed\"])\n",
    "\n",
    "obs_dim = 47\n",
    "print('obs_dim = ', obs_dim)\n",
    "act_dim = 7\n",
    "print('act_dim = ', act_dim)\n",
    "# Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "act_limit = 1\n",
    "print('act_limit = ', act_limit)\n",
    "# Create actor-critic module and target networks\n",
    "ac = MLPActorCritic(**ac_kwargs)\n",
    "ac_targ = deepcopy(ac)\n",
    "\n",
    "# Freeze target networks with respect to optimizers (only update via polyak averaging)\n",
    "for p in ac_targ.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "memory = ReplayMemory(params[\"replay_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function for computing DDPG Q-loss\n",
    "def compute_loss_q(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "    a = torch.cat(data.act).float()\n",
    "    r = torch.cat(data.rew).float()\n",
    "    o2 =torch.cat(data.next_obs).float()\n",
    "    d = torch.cat(data.done).float()\n",
    "\n",
    "    q = ac.q(o,a)\n",
    "\n",
    "\n",
    "    # Bellman backup for Q function\n",
    "    with torch.no_grad():\n",
    "        q_pi_targ = ac_targ.q(o2, ac_targ.pi(o2))\n",
    "        backup = r + params[\"gamma\"] * (1 - d) * q_pi_targ\n",
    "\n",
    "    # MSE loss against Bellman backup\n",
    "    loss_q = ((q - backup)**2).mean()\n",
    "\n",
    "    return loss_q\n",
    "\n",
    "# Set up function for computing DDPG pi loss\n",
    "def compute_loss_pi(data):\n",
    "\n",
    "    o = torch.cat(data.obs).float()\n",
    "\n",
    "    q_pi = ac.q(o, ac.pi(o))\n",
    "\n",
    "    return -q_pi.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "def update(data):\n",
    "    # First run one gradient descent step for Q.\n",
    "\n",
    "\n",
    "    q_optimizer.zero_grad()\n",
    "    loss_q = compute_loss_q(data)\n",
    "\n",
    "    loss_q.backward()\n",
    "\n",
    "    q_optimizer.step()\n",
    "\n",
    "\n",
    "    # Freeze Q-network so you don't waste computational effort \n",
    "    # computing gradients for it during the policy learning step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Next run one gradient descent step for pi.\n",
    "    pi_optimizer.zero_grad()\n",
    "    loss_pi = compute_loss_pi(data)\n",
    "    loss_pi.backward()\n",
    "    pi_optimizer.step()\n",
    "\n",
    "    # Unfreeze Q-network so you can optimize it at next DDPG step.\n",
    "    for p in ac.q.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "    # Finally, update target networks by polyak averaging.\n",
    "    with torch.no_grad():\n",
    "        for p, p_targ in zip(ac.parameters(), ac_targ.parameters()):\n",
    "            # NB: We use an in-place operations \"mul_\", \"add_\" to update target\n",
    "            # params, as opposed to \"mul\" and \"add\", which would make new tensors.\n",
    "            p_targ.data.mul_(params[\"polyak\"])\n",
    "            p_targ.data.add_((1 - params[\"polyak\"]) * p.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_action(o, noise_scale):\n",
    "    a = ac.act(torch.as_tensor(o, dtype=torch.float32))\n",
    "    a += noise_scale * torch.randn(act_dim).to(device)\n",
    "    return torch.clip(a, -act_limit, act_limit)\n",
    "\n",
    "def test_agent(epoch):\n",
    "    test_main = 0\n",
    "    test_step = 0\n",
    "    for j in range(params[\"num_test_episodes\"]):\n",
    "        obs, d, test_ep_ret, test_ep_len = test_env.reset(), False, 0, 0\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        while not(d or (test_ep_len == params[\"max_ep_len\"])):\n",
    "            a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "            obs, r, d, _ = test_env.step(a_cpu[0])\n",
    "            o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "            o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "            test_ep_ret += r\n",
    "            test_ep_len += 1\n",
    "        test_ep_main = test_ep_ret/test_ep_len\n",
    "        test_step +=1\n",
    "        test_main += test_ep_main\n",
    "    print('test_rew_main = ', float(test_main/test_step))\n",
    "    \n",
    "def video_agent(epoch):\n",
    "    obs, d, test_ep_len = video_env.reset(), False, 0\n",
    "    o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "    print(obs)\n",
    "    row1 = obs['robot0_joint_pos_cos']\n",
    "    row2 = obs['robot0_joint_pos_sin']\n",
    "\n",
    "    # open the file in the write mode\n",
    "    file1 = open('controll_data_cos.csv', 'w')\n",
    "    file2 = open('controll_data_sin.csv', 'w')\n",
    "\n",
    "    # create the csv writer\n",
    "    writer_data1 = csv.writer(file1)\n",
    "    writer_data2 = csv.writer(file2)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    writer_data1.writerow(row1)\n",
    "    writer_data2.writerow(row2)\n",
    "    \n",
    "    # file1 = open(\"controll_data.txt\", \"w\")\n",
    "    # file1.writelines(w)\n",
    "\n",
    "    o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "    now = datetime.now()\n",
    "    current_time = str(now.isoformat())\n",
    "    writer = imageio.get_writer(\n",
    "        \"/home/xhnfly/Cosmic_rays_X/X_Robot/robosuite/robosuite/demos/video/DDPG_UR5_%s_ep_%d.mp4\" % (current_time, epoch), fps=20)\n",
    "    frame = obs[\"Labviewer_image\"]\n",
    "    writer.append_data(frame)\n",
    "\n",
    "    while not(d or (test_ep_len == params[\"max_video_len\"])):\n",
    "        a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "        obs, _, d, _ = video_env.step(a_cpu[0])\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        row1 = obs['robot0_joint_pos_cos']\n",
    "        row2 = obs['robot0_joint_pos_sin']\n",
    "        # file1.writelines(w)\n",
    "            # write a row to the csv file\n",
    "        # writer_data = csv.writer(file1)\n",
    "        writer_data1.writerow(row1)\n",
    "        writer_data2.writerow(row2)\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        frame = obs[\"Labviewer_image\"]\n",
    "        writer.append_data(frame)\n",
    "        test_ep_len += 1\n",
    "    writer.close()\n",
    "    file1.close()\n",
    "    file2.close()\n",
    "\n",
    "\n",
    "\n",
    "def demo_agent(epoch):\n",
    "    test_main = 0\n",
    "    test_step = 0\n",
    "    obs, d, test_ep_ret, test_ep_len = test_env.reset(), False, 0, 0\n",
    "    test_env.render()\n",
    "    o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "    o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "    \n",
    "    while not(d or (test_ep_len == params[\"max_ep_len\"])):\n",
    "        a_cpu = get_action(o, 0).cpu().data.numpy()\n",
    "        obs, r, d, _ = test_env.step(a_cpu[0])\n",
    "        test_env.render()\n",
    "        # time.sleep(3)\n",
    "        o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "        o = torch.tensor([o], dtype=torch.float32, device=device)\n",
    "        test_ep_ret += r\n",
    "        test_ep_len += 1\n",
    "    test_env.close()\n",
    "    test_ep_main = test_ep_ret/test_ep_len\n",
    "    test_step +=1\n",
    "    print('test_rew_main = ', float(test_ep_main/test_step))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = {\n",
    "#     'robot0_joint_pos_cos': None,\n",
    "#     'robot0_joint_pos_sin': None,\n",
    "#     'robot0_joint_vel': None,\n",
    "#     'robot0_eef_pos': None,\n",
    "#     'robot0_eef_quat': None,\n",
    "#     'robot0_gripper_qpos': None,\n",
    "#     'robot0_gripper_qvel': None,\n",
    "#     'cubeA_pos': None,\n",
    "#     'cubeA_quat': None,\n",
    "#     'cubeB_pos': None,\n",
    "#     'cubeB_quat': None,\n",
    "#     'gripper_to_cubeA': None,\n",
    "#     'gripper_to_cubeB': None,\n",
    "#     'cubeA_to_cubeB': None,\n",
    "# }\n",
    "\n",
    "obs, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "o = list(obs['robot0_proprio-state']) + list(obs['object-state'])\n",
    "\n",
    "# env.viewer.set_camera(camera_id=0)\n",
    "\n",
    "\n",
    "# Define neutral value\n",
    "neutral = np.zeros(7)\n",
    "\n",
    "# Keep track of done variable to know when to break loop\n",
    "\n",
    "# Prepare for interaction with environment\n",
    "total_steps = params[\"steps_per_epoch\"] * params[\"epochs\"]\n",
    "start_time = time.time()\n",
    "\n",
    "o = torch.tensor([o], device=device)\n",
    "\n",
    "\n",
    "start_time_rec = datetime.now()\n",
    "r_true = 0\n",
    "total_main = 0\n",
    "ep_rew_main = 0\n",
    "reward_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ac = MLPActorCritic(env.observation_space, env.action_space, **ac_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "q.0.weight \t torch.Size([256, 54])\n",
      "q.0.bias \t torch.Size([256])\n",
      "q.2.weight \t torch.Size([256, 256])\n",
      "q.2.bias \t torch.Size([256])\n",
      "q.4.weight \t torch.Size([256, 256])\n",
      "q.4.bias \t torch.Size([256])\n",
      "q.6.weight \t torch.Size([1, 256])\n",
      "q.6.bias \t torch.Size([1])\n",
      "Model's state_dict:\n",
      "pi.0.weight \t torch.Size([256, 47])\n",
      "pi.0.bias \t torch.Size([256])\n",
      "pi.2.weight \t torch.Size([256, 256])\n",
      "pi.2.bias \t torch.Size([256])\n",
      "pi.4.weight \t torch.Size([256, 256])\n",
      "pi.4.bias \t torch.Size([256])\n",
      "pi.6.weight \t torch.Size([7, 256])\n",
      "pi.6.bias \t torch.Size([7])\n",
      "q_optimizer's state_dict:\n",
      "state \t {0: {'step': 735000, 'square_avg': tensor([[1.1763e-04, 3.4725e-05, 5.5390e-05,  ..., 9.2819e-05, 6.5889e-05,\n",
      "         1.6093e-04],\n",
      "        [3.2714e-04, 3.3715e-04, 6.9351e-05,  ..., 1.5772e-04, 1.4216e-04,\n",
      "         6.5974e-04],\n",
      "        [9.3491e-05, 4.5635e-05, 1.0348e-04,  ..., 1.1768e-04, 1.1719e-04,\n",
      "         2.7867e-04],\n",
      "        ...,\n",
      "        [9.6930e-03, 2.7740e-03, 1.7803e-03,  ..., 6.9050e-04, 8.2794e-04,\n",
      "         2.1006e-02],\n",
      "        [1.4464e-04, 2.2252e-05, 5.2988e-05,  ..., 1.1953e-04, 6.7256e-05,\n",
      "         1.1904e-04],\n",
      "        [6.9184e-05, 1.2846e-04, 3.2593e-04,  ..., 8.0448e-05, 8.2046e-05,\n",
      "         1.4955e-04]], device='cuda:0')}, 1: {'step': 735000, 'square_avg': tensor([2.4259e-04, 1.0076e-03, 2.4815e-04, 6.7539e-04, 2.1282e-04, 1.1050e-03,\n",
      "        1.0025e-04, 3.6820e-04, 5.2520e-04, 1.4578e-04, 1.9775e-04, 3.4423e-04,\n",
      "        3.1829e-04, 1.7008e-05, 1.4643e-04, 7.1841e-05, 7.4897e-02, 3.1358e-04,\n",
      "        2.5732e-04, 1.8533e-04, 1.2782e-03, 5.7988e-04, 1.6827e-01, 1.0385e-03,\n",
      "        2.7212e-04, 2.4627e-04, 8.2596e-04, 2.0770e-04, 1.8070e-04, 1.1038e-04,\n",
      "        2.4289e-02, 2.6729e-05, 1.7522e-04, 6.3447e-04, 2.2172e-03, 2.5736e-04,\n",
      "        1.4420e-04, 3.5417e-04, 4.1664e-04, 9.9540e-05, 2.2141e-04, 1.6129e-03,\n",
      "        1.0630e-04, 5.1942e-02, 2.0868e-01, 1.4381e-04, 3.6228e-04, 2.6296e-04,\n",
      "        2.2745e-04, 4.8043e-04, 7.4436e-02, 1.1132e-04, 4.3197e-04, 1.1732e-04,\n",
      "        5.7115e-04, 1.6014e-04, 9.6007e-05, 2.0307e-04, 6.8921e-05, 2.1473e-04,\n",
      "        5.5137e-03, 1.5062e-04, 3.9741e-04, 2.0816e-05, 2.9837e-02, 2.4140e-04,\n",
      "        3.7412e-04, 9.9112e-05, 2.8360e-04, 4.1156e-04, 3.6866e-04, 1.1990e-04,\n",
      "        6.2946e-04, 3.0611e-04, 2.2693e-04, 8.9631e-04, 2.6927e-04, 3.4517e-02,\n",
      "        9.2141e-05, 3.6132e-04, 7.8342e-05, 2.5764e-04, 1.9359e-01, 8.4057e-03,\n",
      "        1.7029e-04, 3.3378e-01, 1.8817e-04, 7.5328e-05, 1.9149e-04, 1.2847e-01,\n",
      "        1.7849e-04, 3.5462e-04, 2.2968e-04, 1.9201e-04, 1.3058e-03, 3.8429e-04,\n",
      "        6.7406e-02, 1.6210e-04, 9.2720e-02, 1.5600e-05, 2.5493e-04, 9.5623e-05,\n",
      "        5.6681e-03, 1.3778e-02, 2.3874e-04, 9.3835e-02, 2.5229e-03, 1.8396e-04,\n",
      "        1.3502e-04, 1.4421e-03, 2.1770e-04, 5.1137e-04, 3.1844e-04, 8.3164e-04,\n",
      "        1.6998e-04, 3.6293e-05, 1.8923e-01, 2.2523e-04, 3.2410e-04, 3.3468e-04,\n",
      "        2.1753e-04, 2.6660e-04, 1.0849e-04, 1.9281e-01, 3.3625e-03, 1.6947e-04,\n",
      "        9.3430e-02, 3.0595e-05, 5.3178e-04, 2.7028e-04, 1.6807e-04, 3.9926e-04,\n",
      "        3.6326e-04, 3.6272e-02, 2.7517e-04, 1.1263e-03, 6.8660e-04, 8.9782e-04,\n",
      "        3.7931e-04, 5.8867e-04, 3.4000e-02, 3.4595e-02, 2.2432e-04, 4.4117e-04,\n",
      "        2.8140e-02, 5.7036e-04, 1.7640e-04, 2.3835e-04, 4.2193e-04, 3.7949e-04,\n",
      "        2.1664e-04, 1.5469e-01, 1.9350e-04, 5.9726e-02, 1.2494e-02, 3.0045e-04,\n",
      "        6.6317e-04, 3.2274e-03, 4.2748e-05, 2.4078e-04, 2.2088e-04, 5.9207e-05,\n",
      "        9.8975e-05, 4.4165e-04, 1.7350e-03, 4.8032e-04, 5.1592e-04, 9.4016e-05,\n",
      "        1.7225e-04, 4.1272e-04, 2.9253e-04, 3.4953e-04, 7.0954e-05, 6.3687e-04,\n",
      "        9.7046e-05, 6.4357e-02, 1.0311e-03, 2.6582e-04, 1.2366e-03, 1.3741e-04,\n",
      "        9.5615e-04, 1.1657e-04, 4.0430e-04, 6.5504e-02, 1.0847e-04, 8.9662e-04,\n",
      "        4.9100e-05, 1.9122e-04, 2.3193e-04, 2.9521e-04, 2.2971e-04, 2.1336e-04,\n",
      "        8.1602e-05, 3.4790e-04, 1.1105e-04, 1.1320e-02, 9.6846e-05, 2.0777e-04,\n",
      "        1.4878e-01, 2.4637e-02, 2.2834e-04, 4.4920e-04, 1.3470e-04, 1.4567e-04,\n",
      "        3.0496e-04, 2.2646e-04, 2.6091e-04, 1.9541e-04, 2.1989e-04, 1.2725e-04,\n",
      "        3.7771e-04, 6.1198e-04, 1.6503e-02, 1.3604e-04, 5.5855e-04, 1.5004e-04,\n",
      "        1.5222e-04, 1.2479e-04, 1.6685e-04, 2.3735e-04, 1.0528e-01, 4.7427e-04,\n",
      "        7.6797e-05, 1.4202e-04, 2.1231e-04, 6.0631e-05, 2.4367e-04, 1.6263e-04,\n",
      "        5.6002e-04, 1.3418e-05, 2.9972e-04, 1.7763e-03, 7.8794e-04, 1.6904e-03,\n",
      "        8.7372e-04, 9.4175e-05, 2.4897e-04, 8.5358e-04, 1.6412e-03, 6.3805e-04,\n",
      "        1.8867e-04, 1.2322e-04, 2.0581e-04, 2.6272e-04, 1.9918e-04, 1.0985e-04,\n",
      "        6.3185e-04, 2.0132e-04, 2.4078e-04, 6.9029e-04, 4.1613e-04, 1.2417e-01,\n",
      "        1.8564e-04, 2.7917e-02, 1.7953e-04, 1.6479e-04], device='cuda:0')}, 2: {'step': 735000, 'square_avg': tensor([[7.2876e-08, 4.3788e-06, 4.0791e-07,  ..., 2.2675e-04, 1.1472e-05,\n",
      "         8.9521e-07],\n",
      "        [9.4821e-06, 2.1225e-05, 1.5724e-05,  ..., 2.3833e-06, 1.2946e-07,\n",
      "         1.0633e-05],\n",
      "        [1.7786e-05, 2.0185e-05, 1.6553e-05,  ..., 1.1570e-04, 6.2525e-06,\n",
      "         5.0794e-06],\n",
      "        ...,\n",
      "        [1.2027e-05, 5.6298e-06, 6.9367e-06,  ..., 2.0586e-05, 8.0352e-06,\n",
      "         4.3968e-06],\n",
      "        [5.5902e-05, 2.4415e-05, 5.7037e-05,  ..., 4.0231e-05, 4.8321e-06,\n",
      "         2.9214e-06],\n",
      "        [1.9857e-05, 2.7137e-05, 5.6896e-05,  ..., 3.1520e-02, 5.9596e-04,\n",
      "         1.0403e-04]], device='cuda:0')}, 3: {'step': 735000, 'square_avg': tensor([7.2399e-04, 4.5693e-05, 2.2383e-04, 9.0925e-04, 6.1996e-05, 8.2315e-05,\n",
      "        4.1450e-04, 2.6533e-05, 3.2983e-04, 7.9161e-04, 2.0974e-04, 6.0132e-04,\n",
      "        1.9935e-04, 3.0676e-05, 4.7899e-05, 5.0943e-05, 6.4387e-05, 4.4574e-03,\n",
      "        1.3028e-04, 8.5368e-05, 5.8036e-05, 9.2396e-05, 2.3985e-05, 1.6473e-05,\n",
      "        3.6196e-04, 8.2011e-05, 3.9500e-05, 8.8961e-04, 1.7641e-05, 4.4704e-05,\n",
      "        1.0248e-04, 9.2853e-05, 1.2651e-04, 1.3695e-01, 3.5685e-04, 5.5869e-05,\n",
      "        4.1622e-05, 5.6245e-05, 7.0211e-05, 1.4385e-04, 3.6078e-06, 8.2738e-05,\n",
      "        1.3038e-04, 8.0602e-05, 1.1441e-04, 2.3163e-05, 3.8418e-05, 3.5904e-05,\n",
      "        1.3303e-04, 1.3434e-05, 6.2893e-05, 1.4950e-04, 8.1260e-05, 1.1481e-03,\n",
      "        1.6314e-04, 4.2692e-05, 7.9437e-05, 3.5485e-04, 6.2962e-05, 1.1307e-04,\n",
      "        4.8418e-04, 1.0173e-03, 1.3376e-05, 2.2917e-04, 5.0249e-05, 3.6473e-04,\n",
      "        4.8303e-05, 8.4669e-03, 1.0785e-04, 3.4615e-02, 1.7963e-04, 1.9351e-04,\n",
      "        1.0172e-04, 2.0077e-04, 1.3191e-05, 6.3975e-05, 2.0199e-02, 8.7463e-05,\n",
      "        3.0286e-05, 5.6590e-05, 8.4189e-05, 2.0447e-04, 6.1088e-02, 3.0212e-05,\n",
      "        3.6812e-05, 7.8863e-03, 4.2372e-05, 6.8856e-04, 6.1283e-05, 4.2803e-04,\n",
      "        5.3116e-05, 1.9597e-05, 1.2484e-04, 2.5911e-04, 4.5918e-05, 4.1095e-04,\n",
      "        1.7989e-05, 1.3635e-05, 2.7029e-04, 9.2881e-06, 4.8934e-03, 3.8831e-05,\n",
      "        9.5200e-05, 1.4724e-02, 3.6615e-05, 4.2987e-05, 9.9401e-02, 1.2250e-04,\n",
      "        5.1566e-03, 8.0539e-06, 3.7045e-05, 2.1450e-03, 4.5382e-05, 1.6902e-04,\n",
      "        1.4479e-03, 8.9740e-03, 2.8809e-04, 1.9160e-03, 8.8049e-05, 1.8561e-05,\n",
      "        1.6723e-04, 5.7573e-05, 1.3009e-04, 1.2859e-04, 1.5033e-04, 1.4408e-04,\n",
      "        4.9979e-04, 2.1917e-04, 2.1448e-05, 3.7312e-05, 4.6426e-04, 7.0922e-05,\n",
      "        1.4975e-04, 4.8953e-05, 5.8728e-05, 3.2640e-04, 2.3433e-04, 1.8601e-04,\n",
      "        1.4029e-04, 7.2120e-05, 1.9178e-05, 9.4916e-05, 1.6085e-05, 1.6170e-05,\n",
      "        1.0122e-04, 2.2100e-05, 5.9688e-04, 2.0187e-04, 4.8919e-05, 5.1421e-04,\n",
      "        4.5371e-02, 1.4878e-05, 1.6753e-04, 2.1612e-03, 1.1156e-04, 5.0064e-05,\n",
      "        3.5065e-03, 3.1608e-05, 4.7502e-03, 7.3330e-05, 2.9059e-05, 1.6553e-04,\n",
      "        7.2752e-05, 6.4868e-03, 6.2756e-05, 2.1260e-05, 5.0959e-05, 5.5392e-05,\n",
      "        1.9075e-04, 4.1642e-04, 6.6200e-05, 4.3005e-05, 1.4871e-04, 1.6099e-03,\n",
      "        2.4113e-05, 6.5797e-04, 3.4825e-03, 1.6634e-04, 2.1763e-04, 1.0026e-01,\n",
      "        3.1594e-04, 5.5603e-05, 2.8514e-05, 4.5851e-05, 5.7370e-02, 4.2382e-04,\n",
      "        2.3160e-04, 6.2209e-04, 4.9925e-05, 2.6636e-05, 9.1733e-05, 4.5086e-05,\n",
      "        1.1403e-04, 3.1225e-05, 3.4249e-05, 1.0010e-03, 1.7372e-01, 1.2142e-04,\n",
      "        3.0926e-05, 7.4076e-04, 3.7930e-04, 6.8413e-02, 3.9878e-05, 3.7393e-05,\n",
      "        5.7214e-05, 1.4273e-05, 6.1768e-04, 2.9387e-04, 4.9877e-04, 1.1936e-04,\n",
      "        4.3790e-05, 3.4748e-05, 6.1555e-04, 3.6531e-05, 6.4846e-04, 3.9080e-04,\n",
      "        1.4772e-05, 5.1658e-05, 6.6978e-05, 1.7837e-04, 1.3124e-02, 7.3014e-05,\n",
      "        8.0089e-04, 1.0648e-02, 1.4572e-04, 1.6510e-05, 7.0065e-44, 2.4853e-04,\n",
      "        7.3716e-03, 1.0434e-03, 5.9136e-05, 2.0924e-05, 2.8200e-05, 3.4032e-04,\n",
      "        2.7181e-05, 2.9274e-05, 2.1455e-05, 5.8859e-03, 4.7709e-05, 5.1053e-04,\n",
      "        1.9908e-02, 1.7914e-04, 1.8327e-05, 4.9535e-05, 2.8275e-05, 2.5213e-04,\n",
      "        2.7316e-05, 1.8207e-04, 6.1352e-05, 2.5720e-02, 2.3433e-02, 1.0835e-05,\n",
      "        9.8556e-05, 1.0030e-04, 4.7149e-04, 1.1331e-01], device='cuda:0')}, 4: {'step': 735000, 'square_avg': tensor([[1.5898e-04, 5.7638e-06, 3.3494e-05,  ..., 8.6989e-06, 9.9562e-08,\n",
      "         4.7137e-03],\n",
      "        [2.4368e-05, 7.8257e-06, 7.1859e-05,  ..., 9.6182e-06, 7.6528e-07,\n",
      "         2.9572e-03],\n",
      "        [7.9068e-05, 1.1866e-07, 5.1702e-06,  ..., 2.0628e-06, 2.0706e-09,\n",
      "         2.3330e-03],\n",
      "        ...,\n",
      "        [9.6920e-06, 4.0370e-07, 9.3900e-06,  ..., 2.7969e-06, 3.6235e-08,\n",
      "         3.9429e-04],\n",
      "        [2.1962e-08, 7.1183e-06, 8.1063e-06,  ..., 1.0197e-06, 2.7361e-09,\n",
      "         4.1366e-07],\n",
      "        [1.8822e-03, 2.5639e-05, 2.4563e-04,  ..., 5.3264e-05, 6.0409e-07,\n",
      "         2.4721e-02]], device='cuda:0')}, 5: {'step': 735000, 'square_avg': tensor([7.0404e-04, 6.0920e-04, 2.9282e-04, 9.6628e-05, 1.2154e-05, 4.9701e-05,\n",
      "        4.8888e-05, 5.8829e-07, 1.1151e-05, 1.4523e-03, 3.9268e-05, 8.9407e-03,\n",
      "        2.1611e-03, 1.6556e-03, 7.0055e-04, 8.2067e-05, 3.7763e-05, 4.5033e-05,\n",
      "        2.4090e-04, 6.6020e-04, 7.6704e-06, 7.6859e-04, 1.2025e-04, 2.0646e-05,\n",
      "        2.2579e-04, 4.1273e-03, 3.6572e-05, 4.7039e-04, 1.5791e-03, 3.9552e-06,\n",
      "        2.2406e-04, 5.7218e-04, 7.3129e-04, 2.7969e-03, 3.9899e-06, 1.0534e-04,\n",
      "        3.3937e-05, 1.1763e-03, 9.6046e-06, 6.6346e-06, 9.2413e-06, 8.8805e-04,\n",
      "        1.4695e-02, 5.0848e-06, 1.4023e-04, 1.4145e-04, 1.2746e-03, 5.0432e-04,\n",
      "        9.1951e-06, 3.9017e-04, 1.6898e-04, 4.8971e-05, 5.6784e-07, 1.8611e-05,\n",
      "        8.2653e-05, 1.2248e-05, 1.0297e-05, 1.3569e-03, 7.3825e-04, 1.0671e-05,\n",
      "        1.1178e-04, 2.1555e-05, 5.2744e-06, 1.3799e-03, 2.1701e-05, 1.0091e-03,\n",
      "        5.0117e-05, 4.2481e-05, 2.4898e-03, 1.3850e-03, 1.0508e-04, 3.2283e-04,\n",
      "        4.3486e-05, 1.2540e-05, 4.9402e-04, 2.7636e-04, 3.1225e-03, 8.8617e-04,\n",
      "        1.3283e-05, 2.3199e-03, 2.6400e-04, 9.4780e-05, 1.0163e-04, 5.4675e-03,\n",
      "        2.0070e-04, 8.3807e-04, 6.0909e-04, 4.3121e-07, 1.1101e-05, 4.4206e-04,\n",
      "        9.6268e-06, 5.1844e-06, 6.1626e-05, 1.6440e-05, 3.8620e-03, 7.5978e-05,\n",
      "        4.6297e-04, 1.5027e-03, 4.0680e-04, 7.6468e-04, 2.9041e-05, 1.2899e-03,\n",
      "        1.5517e-05, 1.9500e-06, 2.7306e-03, 6.3245e-05, 1.0273e-03, 7.2410e-06,\n",
      "        1.4533e-05, 2.1166e-04, 1.0905e-05, 3.0319e-04, 1.0992e-04, 3.3023e-03,\n",
      "        3.2330e-04, 3.0604e-06, 5.8064e-03, 1.7505e-04, 1.6274e-05, 1.1119e-03,\n",
      "        2.3564e-04, 3.8784e-05, 3.0550e-04, 2.4015e-04, 2.8329e-04, 2.3697e-05,\n",
      "        9.1327e-04, 2.7039e-06, 1.5329e-05, 5.7474e-04, 5.2641e-04, 1.2985e-03,\n",
      "        1.6588e-05, 1.8132e-06, 2.6441e-04, 1.6483e-05, 9.6682e-06, 1.7302e-04,\n",
      "        2.7323e-04, 2.6355e-04, 3.3941e-04, 7.5455e-04, 5.7541e-03, 2.5275e-03,\n",
      "        2.4619e-03, 1.3156e-05, 5.8384e-03, 1.2655e-03, 1.6022e-05, 7.9136e-04,\n",
      "        1.0880e-03, 5.5605e-06, 9.8478e-04, 1.8627e-03, 2.1353e-06, 9.4662e-05,\n",
      "        8.1062e-04, 1.0079e-05, 3.9056e-04, 1.0582e-04, 1.1395e-05, 1.1296e-04,\n",
      "        4.9374e-05, 1.1695e-05, 3.9299e-03, 4.1294e-06, 1.0497e-04, 8.1540e-04,\n",
      "        3.5554e-06, 2.0601e-03, 8.2887e-04, 1.0730e-04, 1.0849e-03, 4.3596e-06,\n",
      "        2.4245e-05, 1.0139e-06, 1.5929e-05, 4.9543e-03, 1.2217e-04, 1.7193e-05,\n",
      "        1.4187e-05, 2.6730e-04, 1.5412e-04, 1.3829e-06, 3.2395e-06, 1.0970e-04,\n",
      "        8.3738e-04, 7.0065e-44, 7.3974e-04, 5.6449e-05, 9.2210e-05, 4.6569e-07,\n",
      "        5.5492e-05, 6.1350e-04, 9.3828e-05, 1.2662e-05, 7.0065e-44, 2.0331e-03,\n",
      "        2.5264e-04, 3.8735e-05, 6.3850e-05, 5.7924e-04, 3.0737e-06, 5.6127e-04,\n",
      "        4.3103e-04, 6.6678e-06, 4.8002e-04, 3.1889e-05, 1.6513e-04, 2.7484e-03,\n",
      "        2.8163e-04, 7.3272e-04, 7.6234e-06, 3.0536e-04, 6.2015e-04, 2.2327e-04,\n",
      "        6.1922e-06, 5.3747e-05, 1.5893e-06, 8.2632e-04, 5.0292e-05, 4.4008e-05,\n",
      "        5.9983e-07, 1.4982e-03, 1.6926e-04, 5.2287e-04, 9.0787e-04, 1.5675e-03,\n",
      "        3.6746e-05, 7.7477e-05, 2.8888e-03, 6.6493e-05, 4.7738e-05, 3.9968e-03,\n",
      "        1.1345e-03, 1.1783e-04, 8.0895e-05, 7.0065e-44, 8.3953e-04, 1.9612e-05,\n",
      "        3.4619e-04, 9.8795e-04, 3.0364e-04, 8.4902e-04, 1.0785e-02, 1.1227e-03,\n",
      "        1.4525e-05, 6.3880e-04, 1.5017e-04, 3.5499e-05, 5.5641e-04, 1.4300e-03,\n",
      "        1.3333e-07, 7.1459e-05, 3.3522e-06, 3.7374e-03], device='cuda:0')}, 6: {'step': 735000, 'square_avg': tensor([[1.1569e+00, 1.0193e-04, 2.9241e-01, 4.3800e-05, 8.2091e-06, 7.5401e-05,\n",
      "         5.4551e-05, 2.8433e-07, 3.0526e-06, 1.5092e-04, 1.4297e-05, 1.2254e+00,\n",
      "         9.8238e-01, 4.2763e-02, 1.0882e+00, 1.3716e-01, 2.0548e-05, 1.3437e-04,\n",
      "         2.7503e-01, 7.9811e-02, 8.1783e-06, 4.7875e-04, 6.8553e-06, 3.9685e-06,\n",
      "         4.0774e-01, 1.6594e+00, 2.8600e-04, 6.6657e-03, 1.7071e+00, 2.7679e-06,\n",
      "         2.6544e-05, 3.7626e-02, 1.0823e+00, 1.1606e+00, 9.5273e-06, 2.8266e-05,\n",
      "         8.2887e-06, 8.1998e-01, 4.7479e-06, 9.0756e-07, 1.5362e-06, 1.9503e+00,\n",
      "         1.5494e+00, 2.9835e-06, 6.5368e-05, 1.9387e-05, 2.9040e-04, 1.4197e-02,\n",
      "         4.1094e-05, 5.2706e-01, 5.1851e-05, 7.4959e-05, 6.6879e-09, 1.2883e-04,\n",
      "         5.2354e-04, 1.5832e-05, 8.1978e-07, 4.1380e-04, 5.9502e-01, 4.0517e-06,\n",
      "         2.9585e-04, 3.8996e-06, 2.3038e-07, 1.0864e+00, 3.0545e-05, 1.5428e+00,\n",
      "         1.0297e-01, 7.5880e-02, 7.8287e-04, 4.8655e-04, 3.3686e-04, 7.2467e-01,\n",
      "         2.5583e-05, 3.3868e-04, 9.2458e-05, 4.5634e-05, 6.3486e-01, 1.3598e-04,\n",
      "         1.1478e-06, 6.0380e-04, 6.4478e-01, 7.4334e-05, 5.2645e-04, 1.2910e+00,\n",
      "         1.6554e-03, 4.6952e-01, 9.8872e-01, 2.9548e-06, 5.0280e-06, 6.2819e-01,\n",
      "         2.1336e-06, 4.1652e-06, 3.3996e-06, 5.3798e-06, 1.6765e+00, 1.1605e-04,\n",
      "         8.0129e-01, 6.2114e-02, 7.1712e-01, 1.1673e+00, 1.8430e-05, 2.2744e-04,\n",
      "         4.1433e-06, 2.9718e-07, 1.1361e+00, 7.5874e-04, 4.4742e-04, 1.7201e-05,\n",
      "         1.7175e-06, 8.9831e-04, 6.3058e-07, 1.4728e-03, 2.1763e-01, 1.3469e+00,\n",
      "         4.9284e-01, 4.6837e-06, 1.8811e+00, 4.8056e-04, 1.3082e-05, 1.2831e-04,\n",
      "         3.5767e-04, 1.9877e-05, 7.3475e-01, 8.7005e-03, 8.1952e-04, 5.1115e-06,\n",
      "         1.4506e+00, 1.4126e-07, 4.4856e-06, 1.2082e+00, 9.2355e-01, 9.2497e-04,\n",
      "         5.7571e-06, 2.8262e-06, 3.2216e-04, 1.5783e-06, 2.2017e-07, 4.5701e-04,\n",
      "         7.0598e-01, 2.6495e-04, 8.0062e-01, 9.4597e-01, 1.2381e+00, 1.6778e+00,\n",
      "         4.4573e-01, 3.8117e-05, 1.1861e+00, 1.1901e-04, 6.1668e-06, 1.4172e+00,\n",
      "         2.0108e-03, 1.9560e-06, 3.0893e-04, 5.2426e-01, 2.9178e-07, 1.6041e-01,\n",
      "         1.5581e+00, 2.2669e-05, 4.6885e-01, 3.8050e-06, 9.8634e-06, 4.5859e-05,\n",
      "         4.0624e-04, 1.4635e-05, 1.4075e+00, 2.8161e-07, 1.0430e-04, 3.2166e-01,\n",
      "         8.2555e-07, 1.6626e+00, 1.4625e+00, 4.3648e-05, 2.1350e-04, 2.1308e-07,\n",
      "         9.2044e-06, 1.9129e-08, 2.2684e-06, 1.5573e+00, 4.8346e-04, 8.1234e-06,\n",
      "         4.4862e-06, 2.2393e-02, 4.1150e-03, 2.4977e-07, 1.4042e-06, 6.2358e-05,\n",
      "         1.5741e+00, 7.0065e-44, 1.0393e+00, 2.0251e-05, 2.1160e-03, 8.0777e-09,\n",
      "         2.4105e-05, 1.2685e+00, 1.8912e-01, 6.5551e-06, 7.0065e-44, 1.3080e+00,\n",
      "         9.7498e-04, 3.7154e-05, 5.0948e-05, 1.1434e+00, 4.0612e-07, 3.2713e-03,\n",
      "         1.3939e-03, 3.3430e-07, 9.0442e-01, 1.8482e-06, 1.0660e-05, 4.0236e-01,\n",
      "         1.4090e-03, 1.4412e+00, 2.9370e-06, 3.6915e-04, 1.1407e+00, 5.0088e-05,\n",
      "         2.3709e-06, 9.5557e-06, 1.0054e-07, 1.4278e+00, 4.6707e-04, 1.2559e-05,\n",
      "         7.3810e-08, 5.1808e-05, 7.3233e-04, 7.7825e-01, 1.4162e+00, 1.5101e+00,\n",
      "         9.8131e-06, 7.3907e-04, 8.0991e-04, 1.3631e-04, 5.6213e-05, 2.7331e-01,\n",
      "         1.2952e+00, 4.8543e-04, 1.1467e-05, 7.0065e-44, 1.0149e+00, 3.0790e-06,\n",
      "         7.7155e-01, 1.1200e-04, 4.8075e-05, 1.2932e+00, 8.7920e-01, 1.6612e+00,\n",
      "         1.4912e-06, 1.1163e+00, 3.2278e-01, 3.1505e-05, 1.3460e-04, 5.6531e-01,\n",
      "         2.7227e-09, 1.2199e-05, 1.1276e-06, 1.7339e-02]], device='cuda:0')}, 7: {'step': 735000, 'square_avg': tensor([0.0813], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n",
      "pi_optimizer's state_dict:\n",
      "state \t {0: {'step': 735000, 'square_avg': tensor([[2.6383e-06, 2.3517e-06, 1.1521e-06,  ..., 2.7330e-07, 7.4821e-07,\n",
      "         1.1147e-07],\n",
      "        [2.7618e-05, 7.4658e-06, 1.0773e-05,  ..., 9.5332e-08, 6.1566e-07,\n",
      "         6.6100e-08],\n",
      "        [9.5240e-07, 6.5805e-07, 7.2090e-07,  ..., 2.5285e-07, 5.1997e-07,\n",
      "         1.0398e-07],\n",
      "        ...,\n",
      "        [4.3650e-06, 1.8589e-06, 2.5473e-06,  ..., 2.6909e-07, 3.7203e-07,\n",
      "         6.8748e-08],\n",
      "        [2.8832e-06, 1.2831e-06, 1.8503e-06,  ..., 2.4282e-07, 6.2729e-07,\n",
      "         1.1836e-07],\n",
      "        [2.4661e-06, 4.4223e-06, 1.4417e-06,  ..., 3.3177e-07, 7.2411e-07,\n",
      "         1.5641e-07]], device='cuda:0')}, 1: {'step': 735000, 'square_avg': tensor([7.6418e-06, 8.6607e-05, 2.5239e-06, 5.7343e-05, 2.1551e-05, 1.3362e-05,\n",
      "        3.9480e-05, 9.4460e-06, 2.0213e-06, 9.9391e-06, 8.8147e-06, 1.8461e-06,\n",
      "        9.4059e-07, 1.4228e-05, 4.3206e-06, 1.5652e-05, 5.8122e-06, 2.5210e-05,\n",
      "        2.4233e-05, 3.1952e-06, 1.3248e-06, 4.2040e-06, 1.9000e-06, 3.1496e-06,\n",
      "        8.1555e-05, 6.4339e-06, 1.5112e-05, 7.0786e-06, 1.6287e-05, 8.5581e-05,\n",
      "        3.9888e-06, 1.2032e-06, 9.9529e-06, 1.6200e-04, 1.0114e-06, 5.1143e-06,\n",
      "        6.2707e-06, 1.6317e-05, 1.8768e-06, 1.7963e-05, 8.9491e-06, 1.9129e-06,\n",
      "        1.7743e-05, 3.7563e-06, 2.3917e-05, 1.1511e-04, 2.7779e-06, 4.2678e-05,\n",
      "        2.1902e-05, 1.4382e-05, 1.3980e-05, 9.4403e-06, 8.8288e-06, 1.0081e-05,\n",
      "        1.8130e-06, 7.4201e-06, 7.5939e-06, 2.7061e-05, 1.4338e-05, 1.6978e-06,\n",
      "        3.1987e-06, 7.9107e-05, 3.1907e-04, 5.2241e-06, 3.7268e-05, 3.2832e-05,\n",
      "        1.1670e-05, 1.7501e-05, 4.1644e-06, 1.0096e-05, 3.9046e-05, 2.0790e-05,\n",
      "        2.5970e-06, 6.5857e-05, 2.1206e-05, 1.8695e-06, 5.0845e-05, 2.3539e-05,\n",
      "        1.1106e-04, 5.3317e-06, 5.0699e-04, 4.9292e-06, 3.6122e-06, 9.4314e-07,\n",
      "        4.1881e-06, 7.6211e-06, 2.6933e-04, 1.1723e-04, 9.9574e-05, 5.4918e-06,\n",
      "        1.2436e-03, 3.2968e-06, 1.7262e-05, 1.5040e-06, 2.4789e-06, 8.2720e-06,\n",
      "        5.1717e-06, 9.7575e-06, 3.6669e-06, 1.3156e-05, 6.8398e-06, 6.1758e-06,\n",
      "        7.7998e-07, 5.7143e-06, 1.2566e-04, 1.1064e-05, 1.1325e-05, 8.0212e-06,\n",
      "        2.8204e-06, 1.1143e-05, 1.6726e-05, 7.4500e-06, 2.5899e-04, 1.4022e-06,\n",
      "        1.3880e-05, 2.1759e-06, 1.2274e-03, 6.5411e-06, 1.9072e-05, 4.6768e-05,\n",
      "        1.2416e-05, 8.0834e-04, 2.8644e-06, 2.5744e-06, 4.0940e-05, 3.5351e-06,\n",
      "        5.0302e-06, 2.1130e-05, 2.3685e-06, 1.6605e-05, 4.1708e-06, 2.5822e-06,\n",
      "        1.7401e-06, 3.4963e-05, 3.7107e-06, 1.3396e-05, 1.7447e-05, 1.0076e-05,\n",
      "        1.0225e-05, 5.5119e-06, 1.3106e-05, 8.5541e-06, 5.7040e-03, 8.3207e-06,\n",
      "        4.1047e-06, 1.2690e-05, 1.9874e-06, 6.8832e-06, 1.4707e-05, 1.6112e-04,\n",
      "        4.9002e-06, 7.1153e-05, 3.9632e-06, 8.4591e-06, 1.1550e-05, 1.9363e-04,\n",
      "        1.8010e-04, 9.9684e-06, 1.2826e-05, 1.2790e-05, 3.8202e-05, 1.8151e-04,\n",
      "        5.3974e-06, 1.1815e-06, 1.8296e-06, 9.5780e-06, 1.5172e-05, 1.0066e-05,\n",
      "        2.5468e-06, 5.0275e-06, 1.2264e-05, 5.2568e-05, 2.2579e-03, 7.3434e-06,\n",
      "        1.8311e-05, 7.1980e-06, 5.6479e-06, 1.5034e-05, 1.3130e-05, 1.2993e-06,\n",
      "        2.5078e-06, 3.9218e-06, 3.2210e-06, 9.1328e-06, 1.4271e-05, 3.3525e-05,\n",
      "        1.4992e-04, 1.3962e-04, 2.1283e-05, 6.4570e-05, 1.0132e-06, 4.4403e-06,\n",
      "        1.1630e-04, 1.8778e-05, 3.6370e-06, 2.1540e-04, 4.9780e-05, 1.0369e-05,\n",
      "        2.3258e-06, 1.1432e-04, 3.5407e-06, 3.3090e-04, 9.5137e-05, 8.2712e-06,\n",
      "        1.5967e-06, 9.1579e-06, 2.3673e-06, 2.6051e-05, 1.5098e-05, 5.5855e-06,\n",
      "        1.2760e-05, 4.6008e-06, 1.9035e-05, 9.4874e-06, 1.1037e-05, 2.5540e-06,\n",
      "        9.1110e-06, 1.9449e-06, 6.8095e-06, 1.4544e-05, 1.4505e-05, 1.8781e-05,\n",
      "        1.5360e-05, 3.5275e-06, 7.0738e-06, 3.5006e-06, 1.8326e-05, 2.3590e-06,\n",
      "        4.3837e-06, 9.7365e-05, 2.0745e-05, 1.9890e-05, 2.4970e-05, 9.6474e-06,\n",
      "        5.7684e-06, 4.7063e-06, 2.0499e-05, 3.7882e-06, 4.8393e-06, 1.1392e-05,\n",
      "        5.8680e-06, 1.3335e-06, 1.9256e-05, 9.8477e-06, 2.7689e-05, 7.2772e-06,\n",
      "        1.2302e-05, 1.1439e-04, 1.6584e-05, 1.4473e-05, 4.2670e-05, 1.6956e-05,\n",
      "        4.5539e-06, 1.3662e-05, 7.6469e-06, 1.0353e-05], device='cuda:0')}, 2: {'step': 735000, 'square_avg': tensor([[3.4842e-08, 9.5088e-08, 3.1613e-08,  ..., 4.6664e-08, 3.8378e-07,\n",
      "         7.6993e-08],\n",
      "        [3.2873e-08, 2.8232e-07, 3.9752e-08,  ..., 1.7783e-07, 1.4256e-06,\n",
      "         1.8690e-07],\n",
      "        [2.3473e-07, 5.6380e-07, 3.1113e-08,  ..., 3.0406e-07, 2.9952e-06,\n",
      "         2.4937e-07],\n",
      "        ...,\n",
      "        [4.0178e-07, 8.2505e-08, 1.5509e-08,  ..., 5.1811e-08, 3.7077e-07,\n",
      "         9.2443e-08],\n",
      "        [1.3924e-07, 1.6466e-07, 2.6374e-08,  ..., 5.0200e-08, 5.1369e-07,\n",
      "         7.3201e-08],\n",
      "        [1.7059e-07, 1.8959e-07, 4.1339e-08,  ..., 1.1993e-07, 9.6144e-07,\n",
      "         1.4222e-07]], device='cuda:0')}, 3: {'step': 735000, 'square_avg': tensor([2.1306e-06, 4.8026e-06, 9.1369e-06, 6.2793e-06, 6.7642e-06, 3.0140e-06,\n",
      "        2.5291e-05, 4.6174e-05, 7.9759e-06, 1.8243e-05, 8.3016e-05, 1.2295e-05,\n",
      "        1.1175e-05, 1.7310e-05, 8.8843e-06, 7.3632e-06, 1.9799e-06, 1.9061e-06,\n",
      "        1.4879e-06, 3.3043e-06, 1.8152e-06, 6.9012e-05, 9.3068e-06, 2.1210e-05,\n",
      "        1.5512e-05, 3.7983e-06, 1.6943e-05, 1.4030e-06, 3.1294e-06, 1.4925e-05,\n",
      "        1.2849e-04, 7.9293e-06, 1.4116e-05, 7.5389e-07, 2.9253e-06, 3.6775e-05,\n",
      "        4.8847e-06, 2.7163e-05, 9.0444e-06, 2.6642e-05, 5.9594e-06, 2.0158e-05,\n",
      "        1.3206e-06, 1.0985e-04, 4.8777e-06, 6.8470e-06, 1.7720e-05, 8.2058e-06,\n",
      "        3.1575e-06, 1.2084e-05, 6.7630e-07, 1.1501e-06, 9.8569e-06, 1.3487e-05,\n",
      "        3.6644e-05, 2.6177e-04, 7.9377e-06, 1.5700e-06, 1.0424e-06, 4.5664e-06,\n",
      "        3.5336e-06, 1.8657e-06, 3.8683e-06, 3.0119e-05, 1.0039e-05, 1.5567e-06,\n",
      "        2.7066e-05, 2.2938e-06, 1.7414e-06, 3.6400e-06, 1.6358e-05, 5.9235e-06,\n",
      "        7.3643e-06, 6.5082e-06, 4.8565e-06, 5.3756e-06, 4.0241e-06, 1.0788e-06,\n",
      "        6.8813e-06, 1.7414e-05, 9.1954e-06, 1.0890e-05, 5.0706e-07, 6.7980e-07,\n",
      "        5.2221e-07, 8.0053e-06, 2.7810e-06, 1.0585e-05, 3.4649e-07, 9.8256e-07,\n",
      "        1.5958e-05, 4.7868e-06, 1.1612e-05, 7.0054e-07, 3.8613e-06, 4.3295e-06,\n",
      "        4.8853e-06, 2.7107e-06, 9.8505e-06, 6.2290e-06, 4.9210e-06, 4.2411e-04,\n",
      "        5.4966e-05, 2.0689e-05, 1.6225e-05, 2.2148e-06, 5.2413e-06, 1.3474e-06,\n",
      "        1.2347e-05, 1.1150e-05, 7.7854e-06, 9.4999e-07, 3.2640e-05, 5.9692e-06,\n",
      "        3.8920e-06, 1.1076e-05, 1.9630e-06, 2.9449e-05, 2.6529e-06, 8.1776e-06,\n",
      "        1.0680e-05, 1.2868e-05, 1.4200e-04, 5.5347e-07, 9.1957e-07, 8.1981e-06,\n",
      "        6.4673e-06, 8.4281e-05, 1.2146e-04, 1.5156e-05, 5.7656e-06, 1.6748e-05,\n",
      "        1.0698e-06, 5.3928e-07, 3.0504e-06, 1.2354e-06, 9.2719e-07, 1.7920e-06,\n",
      "        1.5924e-05, 5.4652e-07, 6.3864e-06, 8.6007e-06, 5.1991e-07, 3.3883e-06,\n",
      "        3.6418e-06, 4.4886e-06, 2.1682e-06, 7.6795e-06, 1.4507e-05, 8.9149e-06,\n",
      "        3.8446e-05, 4.7515e-05, 3.1139e-06, 3.0965e-06, 4.7790e-06, 5.9023e-06,\n",
      "        3.8284e-06, 1.5405e-05, 9.7779e-07, 2.6870e-05, 1.3914e-06, 1.1455e-05,\n",
      "        6.5733e-06, 1.5372e-05, 2.1947e-05, 1.3413e-06, 2.1215e-05, 1.0447e-05,\n",
      "        5.8544e-05, 1.4828e-06, 7.5755e-06, 1.1669e-06, 2.2599e-06, 2.0079e-05,\n",
      "        2.2113e-05, 9.4617e-06, 7.2755e-06, 1.4739e-05, 3.1974e-06, 2.2656e-05,\n",
      "        2.3326e-06, 5.0890e-06, 1.7642e-05, 1.6419e-06, 2.7650e-06, 3.8944e-06,\n",
      "        1.8942e-05, 4.7673e-06, 4.2939e-07, 5.7715e-07, 4.9265e-06, 4.6935e-06,\n",
      "        1.5862e-05, 3.5971e-06, 1.4708e-05, 1.3597e-06, 3.5779e-05, 3.6365e-06,\n",
      "        5.3950e-06, 1.7233e-05, 6.9064e-06, 3.1433e-06, 3.3157e-06, 4.2911e-06,\n",
      "        3.2037e-06, 7.9605e-06, 8.0212e-06, 4.6891e-06, 5.5052e-07, 1.2215e-06,\n",
      "        3.2301e-06, 1.7286e-05, 2.3240e-05, 5.5910e-07, 1.7268e-05, 1.1676e-05,\n",
      "        4.4592e-07, 4.6194e-06, 2.7319e-05, 1.1581e-05, 9.0746e-07, 1.6889e-05,\n",
      "        5.4442e-06, 7.7364e-07, 4.4847e-05, 5.3760e-06, 2.8897e-05, 2.4740e-06,\n",
      "        3.1898e-06, 8.4643e-06, 6.1255e-06, 8.2406e-06, 6.9582e-07, 4.3008e-07,\n",
      "        2.1548e-05, 4.8620e-06, 2.8755e-06, 2.0120e-06, 4.2901e-06, 6.4593e-06,\n",
      "        3.0732e-06, 2.8995e-05, 1.2275e-05, 1.0999e-05, 2.4144e-06, 2.1041e-05,\n",
      "        7.2891e-07, 1.4764e-06, 2.8292e-05, 2.0479e-07, 7.7588e-06, 3.3624e-06,\n",
      "        8.5788e-07, 3.3353e-06, 6.1315e-06, 5.3393e-06], device='cuda:0')}, 4: {'step': 735000, 'square_avg': tensor([[2.0822e-08, 1.3005e-08, 6.8322e-10,  ..., 9.0373e-08, 8.3697e-08,\n",
      "         3.7472e-09],\n",
      "        [3.7315e-08, 3.2818e-08, 9.2155e-08,  ..., 4.5414e-07, 3.6805e-08,\n",
      "         2.2633e-07],\n",
      "        [1.0210e-08, 7.6233e-08, 5.8883e-07,  ..., 2.7642e-07, 7.6535e-09,\n",
      "         5.3184e-08],\n",
      "        ...,\n",
      "        [3.1416e-09, 2.1653e-08, 9.6433e-10,  ..., 5.7825e-07, 3.0286e-07,\n",
      "         2.4022e-08],\n",
      "        [2.0680e-08, 8.1124e-08, 1.4899e-08,  ..., 6.8805e-07, 1.3287e-07,\n",
      "         9.5038e-09],\n",
      "        [1.4118e-07, 2.3073e-07, 1.0101e-06,  ..., 1.3539e-07, 3.6146e-08,\n",
      "         2.4041e-07]], device='cuda:0')}, 5: {'step': 735000, 'square_avg': tensor([1.1339e-06, 2.0459e-06, 3.2087e-06, 9.1640e-07, 1.4340e-06, 5.5897e-06,\n",
      "        1.7153e-06, 3.1504e-07, 2.0330e-06, 9.7808e-07, 1.0666e-06, 3.0703e-06,\n",
      "        1.3792e-06, 2.5728e-06, 2.8378e-06, 4.1081e-06, 2.3384e-06, 8.3078e-06,\n",
      "        2.7040e-06, 1.2608e-07, 1.1967e-06, 4.6356e-06, 6.6125e-06, 2.1999e-07,\n",
      "        3.0463e-06, 2.2963e-06, 1.7174e-07, 5.3400e-08, 2.3491e-06, 2.3776e-07,\n",
      "        1.3232e-05, 2.0057e-07, 2.0762e-06, 1.4040e-05, 9.9613e-07, 1.1991e-06,\n",
      "        9.9403e-06, 1.1033e-06, 1.8325e-07, 1.3037e-06, 2.1979e-06, 8.9819e-06,\n",
      "        8.7699e-08, 2.4389e-08, 2.9775e-07, 4.7264e-07, 9.6022e-07, 5.2698e-07,\n",
      "        1.7076e-06, 2.0299e-06, 1.7313e-07, 2.5827e-07, 3.3657e-06, 2.1404e-08,\n",
      "        5.6066e-07, 3.4731e-07, 1.8584e-07, 2.4459e-06, 1.4142e-07, 2.7600e-06,\n",
      "        2.8230e-06, 2.3331e-06, 4.8822e-07, 1.9533e-06, 5.1958e-06, 5.3433e-07,\n",
      "        3.1877e-07, 4.4884e-06, 1.3229e-05, 3.8841e-06, 5.0888e-07, 1.0293e-06,\n",
      "        2.4121e-07, 7.0322e-07, 7.3247e-06, 5.1694e-06, 3.5661e-07, 2.5748e-06,\n",
      "        7.0847e-06, 4.2224e-07, 6.0790e-07, 6.1216e-07, 4.4575e-06, 7.0991e-08,\n",
      "        2.4068e-06, 4.2815e-06, 8.5874e-06, 1.0988e-06, 4.2301e-08, 6.7061e-06,\n",
      "        4.1412e-06, 4.1859e-07, 5.2754e-06, 1.8252e-06, 3.4498e-06, 2.3435e-07,\n",
      "        9.9458e-06, 4.6438e-07, 5.4043e-06, 5.8651e-06, 1.7874e-06, 2.0820e-08,\n",
      "        2.2222e-07, 6.3752e-06, 2.5248e-06, 2.7223e-07, 1.5231e-07, 1.0197e-05,\n",
      "        3.6702e-07, 5.1949e-06, 2.1264e-06, 3.2333e-06, 7.0071e-07, 1.8193e-05,\n",
      "        4.5632e-05, 2.6066e-07, 5.3605e-08, 2.4151e-06, 2.1574e-05, 9.2986e-07,\n",
      "        2.4143e-05, 4.8402e-06, 1.4986e-06, 9.1288e-06, 1.5637e-06, 1.7965e-06,\n",
      "        4.9178e-07, 4.7264e-06, 4.3777e-06, 2.6562e-06, 5.9449e-06, 1.0257e-05,\n",
      "        4.2255e-06, 1.4289e-07, 1.5852e-06, 5.5905e-07, 1.6106e-06, 1.3004e-06,\n",
      "        1.0977e-06, 1.3366e-05, 1.7145e-05, 3.8232e-06, 8.7567e-07, 5.5654e-07,\n",
      "        1.7048e-07, 1.4910e-06, 5.1550e-06, 2.6004e-06, 5.3113e-06, 2.0628e-05,\n",
      "        2.4396e-06, 1.9666e-06, 7.2128e-06, 2.5958e-07, 1.9302e-07, 1.0114e-07,\n",
      "        2.9273e-05, 9.0757e-07, 5.9925e-08, 1.7221e-07, 7.8451e-07, 2.6745e-06,\n",
      "        6.1998e-07, 3.2060e-06, 5.1550e-06, 1.1945e-06, 3.3542e-06, 1.3600e-06,\n",
      "        6.9134e-06, 4.0912e-06, 1.3913e-06, 8.2120e-06, 7.4752e-06, 2.1378e-07,\n",
      "        1.1589e-06, 1.4556e-06, 2.4693e-06, 1.4039e-06, 1.4550e-06, 1.1050e-05,\n",
      "        3.0596e-06, 1.9426e-06, 4.0642e-06, 7.1911e-06, 5.5513e-07, 1.0757e-05,\n",
      "        3.6736e-06, 4.0176e-06, 6.3728e-06, 2.8533e-06, 2.3367e-07, 2.9101e-06,\n",
      "        2.6640e-06, 1.8561e-06, 6.8052e-06, 1.3871e-06, 8.0118e-07, 1.8066e-06,\n",
      "        3.7180e-06, 5.6820e-06, 3.3482e-07, 1.2536e-07, 2.5707e-06, 4.5006e-07,\n",
      "        7.9616e-06, 2.9347e-06, 5.7338e-06, 6.5746e-07, 7.0542e-06, 1.2191e-05,\n",
      "        2.4955e-07, 1.4082e-06, 1.7480e-07, 8.0801e-08, 4.3843e-06, 2.9799e-07,\n",
      "        5.1856e-07, 3.1594e-06, 9.0754e-06, 6.2679e-07, 7.8479e-07, 4.8739e-07,\n",
      "        1.9881e-06, 4.4798e-06, 3.6135e-06, 2.1941e-06, 3.2379e-05, 7.8466e-06,\n",
      "        8.5659e-06, 1.2853e-06, 2.4574e-06, 8.5714e-06, 9.1482e-07, 1.4436e-05,\n",
      "        2.8562e-07, 2.1829e-06, 1.0908e-05, 2.6996e-07, 9.5398e-07, 1.1735e-06,\n",
      "        1.1700e-07, 3.0319e-06, 7.8816e-07, 3.9543e-06, 8.0183e-06, 2.3953e-06,\n",
      "        2.3872e-07, 2.2883e-06, 9.2690e-07, 1.3831e-07, 4.3856e-06, 1.3755e-06,\n",
      "        3.6763e-05, 4.3028e-06, 2.7146e-06, 2.8847e-06], device='cuda:0')}, 6: {'step': 735000, 'square_avg': tensor([[2.0544e-06, 2.6964e-06, 1.8768e-05,  ..., 3.1467e-05, 1.7567e-05,\n",
      "         3.7055e-05],\n",
      "        [2.5578e-07, 4.6092e-07, 3.8298e-06,  ..., 4.7276e-06, 3.3195e-06,\n",
      "         6.3016e-06],\n",
      "        [1.4842e-07, 2.3407e-07, 8.7666e-07,  ..., 1.3534e-06, 8.0101e-07,\n",
      "         2.2006e-06],\n",
      "        ...,\n",
      "        [1.3497e-08, 5.8098e-08, 8.3377e-08,  ..., 1.0749e-07, 1.3787e-07,\n",
      "         1.4342e-07],\n",
      "        [6.2836e-09, 6.4062e-08, 9.2480e-08,  ..., 6.3821e-08, 9.4822e-08,\n",
      "         7.9684e-08],\n",
      "        [2.0683e-09, 4.8087e-08, 4.0476e-08,  ..., 1.1530e-08, 4.7564e-08,\n",
      "         4.9513e-08]], device='cuda:0')}, 7: {'step': 735000, 'square_avg': tensor([2.5657e-04, 3.7275e-05, 9.5572e-06, 3.2904e-07, 5.7166e-07, 2.8971e-07,\n",
      "        2.9063e-08], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.0001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model_q = ac.q\n",
    "model_pi = ac.pi\n",
    "pi_optimizer = RMSprop(ac.pi.parameters(), lr=params[\"pi_lr\"])\n",
    "q_optimizer = RMSprop(ac.q.parameters(), lr=params[\"q_lr\"])\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"/media/xhnfly/2BE2-6A99/model_nn_ces013/model_nn/model_nn_2022-03-06T14-14-44.587014246.pt\")\n",
    "model_q.load_state_dict(checkpoint['model of ac.q'])\n",
    "model_pi.load_state_dict(checkpoint['model of ac.pi'])\n",
    "q_optimizer.load_state_dict(checkpoint['q_optimizer_state_dict'])\n",
    "pi_optimizer.load_state_dict(checkpoint['pi_optimizer_state_dict'])\n",
    "\n",
    "\n",
    "model = ac.q\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "model = ac.pi\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"q_optimizer's state_dict:\")\n",
    "for var_name in q_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", q_optimizer.state_dict()[var_name])\n",
    "\n",
    "print(\"pi_optimizer's state_dict:\")\n",
    "for var_name in pi_optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", pi_optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('robot0_joint_pos_cos', array([ 0.91345719, -0.14210476, -0.79492862, -0.63855632, -0.02283334,\n",
      "       -0.38203708])), ('robot0_joint_pos_sin', array([-0.40693484, -0.98985162,  0.60670297, -0.76957509, -0.99973929,\n",
      "       -0.92414699])), ('robot0_joint_vel', array([0., 0., 0., 0., 0., 0.])), ('robot0_eef_pos', array([ 0.34869241, -0.72821485,  0.90436881])), ('robot0_eef_quat', array([-0.99897446,  0.01305752,  0.04293371,  0.00601911])), ('robot0_gripper_qpos', array([ 0.012,  0.065,  0.065, -0.012,  0.065,  0.065])), ('robot0_gripper_qvel', array([0., 0., 0., 0., 0., 0.])), ('Labviewer_image', array([[[147, 158, 184],\n",
      "        [147, 158, 184],\n",
      "        [147, 158, 184],\n",
      "        ...,\n",
      "        [146, 158, 184],\n",
      "        [146, 158, 184],\n",
      "        [146, 158, 184]],\n",
      "\n",
      "       [[146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        ...,\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183]],\n",
      "\n",
      "       [[146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        ...,\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183],\n",
      "        [146, 158, 183]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[154, 160, 158],\n",
      "        [152, 158, 156],\n",
      "        [146, 152, 150],\n",
      "        ...,\n",
      "        [150, 156, 156],\n",
      "        [154, 160, 160],\n",
      "        [152, 159, 159]],\n",
      "\n",
      "       [[151, 157, 156],\n",
      "        [147, 153, 152],\n",
      "        [139, 145, 144],\n",
      "        ...,\n",
      "        [149, 155, 155],\n",
      "        [152, 158, 158],\n",
      "        [153, 159, 159]],\n",
      "\n",
      "       [[146, 152, 152],\n",
      "        [140, 146, 146],\n",
      "        [133, 139, 139],\n",
      "        ...,\n",
      "        [152, 158, 158],\n",
      "        [152, 158, 158],\n",
      "        [152, 158, 158]]], dtype=uint8)), ('cubeA_pos', array([ 0.11221167, -0.15269023,  1.24      ])), ('cubeA_quat', array([ 0.        ,  0.        ,  0.90493267, -0.42555477])), ('gripper_to_cubeA', array([-0.23648074,  0.57552462,  0.33563119])), ('robot0_proprio-state', array([ 0.91345719, -0.14210476, -0.79492862, -0.63855632, -0.02283334,\n",
      "       -0.38203708, -0.40693484, -0.98985162,  0.60670297, -0.76957509,\n",
      "       -0.99973929, -0.92414699,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.34869241, -0.72821485,\n",
      "        0.90436881, -0.99897446,  0.01305752,  0.04293371,  0.00601911,\n",
      "        0.012     ,  0.065     ,  0.065     , -0.012     ,  0.065     ,\n",
      "        0.065     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ])), ('object-state', array([ 0.11221167, -0.15269023,  1.24      ,  0.        ,  0.        ,\n",
      "        0.90493267, -0.42555477, -0.23648074,  0.57552462,  0.33563119]))])\n"
     ]
    }
   ],
   "source": [
    "video_agent(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('robot0_joint_pos_cos', array([ 0.91345719, -0.14210476, -0.79492862, -0.63855632, -0.02283334, -0.38203708])), \n",
    "# ('robot0_joint_pos_sin', array([-0.40693484, -0.98985162,  0.60670297, -0.76957509, -0.99973929, -0.92414699])), \n",
    "# ('robot0_joint_vel', array([0., 0., 0., 0., 0., 0.])),\n",
    "# ('robot0_eef_pos', array([ 0.36645901, -0.73094287,  1.11108881]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import numpy as np\n",
    "# jpos = math.acos(np.array[ 0.91345719, -0.14210476, -0.79492862, -0.63855632, -0.02283334, -0.38203708])\n",
    "# print(jpos)\n",
    "\n",
    "# for (i = 0,j = array.length; i < j; i += chunk) {\n",
    "#     temporary = array.slice(i, i + chunk);\n",
    "#     // do whatever\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_agent(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a48a149bc7a8dee0435672efcae6f64e48d62311a35302b209b3ac517d7f9c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cosmic_rays_x_py38_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
